{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent Playing QisCoin v1\n",
    "\n",
    "In this notebook we run a more challenging version of **QisCoin** (*qiscoin-v1*) in which a quantum circuit with six random gates is generated. This corresponds to the normal game played in medium-difficulty mode. As before, we instantiate and run a random agent and few RL agents from the stable-baselines library and we observe their results. \n",
    "\n",
    "For a more detailed explanation of the code in this notebook, refer to the notebook [AI Agent v0](https://github.com/avalds/QisCoin/blob/master/4-%20AI%20Agent%20v0.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "\n",
    "We start importing the main required libraries: OpenAI *gym* to run the game; *qiscoin* importing the **QisCoin** game; and *IPython.display* to print out our circuits.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import qiscoin\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the game\n",
    "We create the game enviroment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('qiscoin-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we test the game running a single iteration of the game where the AI agent takes a random guess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 594.776x144.48 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is guessing that the outcome will be 1\n",
      "The guess is correct!\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "display(env.render())\n",
    "\n",
    "for _ in range(1):\n",
    "    guess = env.action_space.sample()\n",
    "    print(\"AI is guessing that the outcome will be {0}\".format(guess))\n",
    "    obs, reward, done, info = env.step(guess)\n",
    "    if(reward==1):\n",
    "        print(\"The guess is correct!\")\n",
    "    else:\n",
    "        print(\"The guess is wrong!\")\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Reinforcement Learning Agent\n",
    "\n",
    "As before, we train a couple of reinforcement learning agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a PPO2 Agent\n",
    "\n",
    "We train a PPO2 agent over 10000 games of **QisCoin** and save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/input.py:42: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/policies.py:562: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/distributions.py:323: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/distributions.py:324: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:193: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:201: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:209: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:243: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:245: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017399086 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.37         |\n",
      "| fps                | 82            |\n",
      "| n_updates          | 1             |\n",
      "| policy_entropy     | 0.6929884     |\n",
      "| policy_loss        | -0.0048534484 |\n",
      "| serial_timesteps   | 128           |\n",
      "| time_elapsed       | 2.38e-06      |\n",
      "| total_timesteps    | 128           |\n",
      "| value_loss         | 0.68267035    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00016464177 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.182        |\n",
      "| fps                | 94            |\n",
      "| n_updates          | 2             |\n",
      "| policy_entropy     | 0.692031      |\n",
      "| policy_loss        | -0.0036979602 |\n",
      "| serial_timesteps   | 256           |\n",
      "| time_elapsed       | 1.55          |\n",
      "| total_timesteps    | 256           |\n",
      "| value_loss         | 0.5542969     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00020036445 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0456       |\n",
      "| fps                | 88            |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 0.6899929     |\n",
      "| policy_loss        | -0.0045718513 |\n",
      "| serial_timesteps   | 384           |\n",
      "| time_elapsed       | 2.9           |\n",
      "| total_timesteps    | 384           |\n",
      "| value_loss         | 0.5045209     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00034439267 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0258       |\n",
      "| fps                | 87            |\n",
      "| n_updates          | 4             |\n",
      "| policy_entropy     | 0.68667364    |\n",
      "| policy_loss        | -0.0051844725 |\n",
      "| serial_timesteps   | 512           |\n",
      "| time_elapsed       | 4.35          |\n",
      "| total_timesteps    | 512           |\n",
      "| value_loss         | 0.49315876    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0006210282 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.00478      |\n",
      "| fps                | 91           |\n",
      "| n_updates          | 5            |\n",
      "| policy_entropy     | 0.67887175   |\n",
      "| policy_loss        | -0.008723568 |\n",
      "| serial_timesteps   | 640          |\n",
      "| time_elapsed       | 5.81         |\n",
      "| total_timesteps    | 640          |\n",
      "| value_loss         | 0.5040957    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0010579986 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.00263      |\n",
      "| fps                | 99           |\n",
      "| n_updates          | 6            |\n",
      "| policy_entropy     | 0.6657534    |\n",
      "| policy_loss        | -0.009737169 |\n",
      "| serial_timesteps   | 768          |\n",
      "| time_elapsed       | 7.21         |\n",
      "| total_timesteps    | 768          |\n",
      "| value_loss         | 0.49201712   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.002118812  |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0481      |\n",
      "| fps                | 89           |\n",
      "| n_updates          | 7            |\n",
      "| policy_entropy     | 0.63703525   |\n",
      "| policy_loss        | -0.019053804 |\n",
      "| serial_timesteps   | 896          |\n",
      "| time_elapsed       | 8.5          |\n",
      "| total_timesteps    | 896          |\n",
      "| value_loss         | 0.5186907    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0035576064 |\n",
      "| clipfrac           | 0.02734375   |\n",
      "| explained_variance | 0.00923      |\n",
      "| fps                | 107          |\n",
      "| n_updates          | 8            |\n",
      "| policy_entropy     | 0.5900249    |\n",
      "| policy_loss        | -0.022915768 |\n",
      "| serial_timesteps   | 1024         |\n",
      "| time_elapsed       | 9.93         |\n",
      "| total_timesteps    | 1024         |\n",
      "| value_loss         | 0.49127012   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.003105043  |\n",
      "| clipfrac           | 0.015625     |\n",
      "| explained_variance | -0.0474      |\n",
      "| fps                | 96           |\n",
      "| n_updates          | 9            |\n",
      "| policy_entropy     | 0.5415727    |\n",
      "| policy_loss        | -0.015924321 |\n",
      "| serial_timesteps   | 1152         |\n",
      "| time_elapsed       | 11.1         |\n",
      "| total_timesteps    | 1152         |\n",
      "| value_loss         | 0.49632597   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.0029837075 |\n",
      "| clipfrac           | 0.02734375   |\n",
      "| explained_variance | -0.00219     |\n",
      "| fps                | 87           |\n",
      "| n_updates          | 10           |\n",
      "| policy_entropy     | 0.47016636   |\n",
      "| policy_loss        | -0.013958797 |\n",
      "| serial_timesteps   | 1280         |\n",
      "| time_elapsed       | 12.5         |\n",
      "| total_timesteps    | 1280         |\n",
      "| value_loss         | 0.49243155   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0017618027 |\n",
      "| clipfrac           | 0.009765625  |\n",
      "| explained_variance | -0.0314      |\n",
      "| fps                | 87           |\n",
      "| n_updates          | 11           |\n",
      "| policy_entropy     | 0.39865232   |\n",
      "| policy_loss        | -0.005708985 |\n",
      "| serial_timesteps   | 1408         |\n",
      "| time_elapsed       | 13.9         |\n",
      "| total_timesteps    | 1408         |\n",
      "| value_loss         | 0.4978867    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0007321984  |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| explained_variance | -0.0211       |\n",
      "| fps                | 92            |\n",
      "| n_updates          | 12            |\n",
      "| policy_entropy     | 0.36515397    |\n",
      "| policy_loss        | -0.0051023355 |\n",
      "| serial_timesteps   | 1536          |\n",
      "| time_elapsed       | 15.4          |\n",
      "| total_timesteps    | 1536          |\n",
      "| value_loss         | 0.46625102    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0014107203 |\n",
      "| clipfrac           | 0.0234375    |\n",
      "| explained_variance | -0.0148      |\n",
      "| fps                | 81           |\n",
      "| n_updates          | 13           |\n",
      "| policy_entropy     | 0.32203147   |\n",
      "| policy_loss        | -0.011948096 |\n",
      "| serial_timesteps   | 1664         |\n",
      "| time_elapsed       | 16.8         |\n",
      "| total_timesteps    | 1664         |\n",
      "| value_loss         | 0.46071172   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0010790679  |\n",
      "| clipfrac           | 0.009765625   |\n",
      "| explained_variance | 0.00291       |\n",
      "| fps                | 88            |\n",
      "| n_updates          | 14            |\n",
      "| policy_entropy     | 0.2722692     |\n",
      "| policy_loss        | -0.0051791305 |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 18.3          |\n",
      "| total_timesteps    | 1792          |\n",
      "| value_loss         | 0.47703737    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0011060329 |\n",
      "| clipfrac           | 0.015625     |\n",
      "| explained_variance | -0.00913     |\n",
      "| fps                | 82           |\n",
      "| n_updates          | 15           |\n",
      "| policy_entropy     | 0.23529118   |\n",
      "| policy_loss        | -0.010607503 |\n",
      "| serial_timesteps   | 1920         |\n",
      "| time_elapsed       | 19.8         |\n",
      "| total_timesteps    | 1920         |\n",
      "| value_loss         | 0.4482839    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00015821503 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00742      |\n",
      "| fps                | 68            |\n",
      "| n_updates          | 16            |\n",
      "| policy_entropy     | 0.19618666    |\n",
      "| policy_loss        | -0.000560718  |\n",
      "| serial_timesteps   | 2048          |\n",
      "| time_elapsed       | 21.3          |\n",
      "| total_timesteps    | 2048          |\n",
      "| value_loss         | 0.51532865    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00032554107 |\n",
      "| clipfrac           | 0.005859375   |\n",
      "| explained_variance | -0.0352       |\n",
      "| fps                | 62            |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 0.17622718    |\n",
      "| policy_loss        | -0.0024972737 |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 23.2          |\n",
      "| total_timesteps    | 2176          |\n",
      "| value_loss         | 0.4728325     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0001543719  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00458       |\n",
      "| fps                | 63            |\n",
      "| n_updates          | 18            |\n",
      "| policy_entropy     | 0.1457641     |\n",
      "| policy_loss        | -0.0012370775 |\n",
      "| serial_timesteps   | 2304          |\n",
      "| time_elapsed       | 25.2          |\n",
      "| total_timesteps    | 2304          |\n",
      "| value_loss         | 0.4509802     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0001734397  |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | -0.0797       |\n",
      "| fps                | 68            |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 0.12714756    |\n",
      "| policy_loss        | -0.0030470188 |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 27.3          |\n",
      "| total_timesteps    | 2432          |\n",
      "| value_loss         | 0.46589705    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000113219125 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.00288       |\n",
      "| fps                | 66             |\n",
      "| n_updates          | 20             |\n",
      "| policy_entropy     | 0.107451975    |\n",
      "| policy_loss        | -0.0017466254  |\n",
      "| serial_timesteps   | 2560           |\n",
      "| time_elapsed       | 29.1           |\n",
      "| total_timesteps    | 2560           |\n",
      "| value_loss         | 0.46827573     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.8647864e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0409       |\n",
      "| fps                | 75            |\n",
      "| n_updates          | 21            |\n",
      "| policy_entropy     | 0.0970667     |\n",
      "| policy_loss        | -0.0002894611 |\n",
      "| serial_timesteps   | 2688          |\n",
      "| time_elapsed       | 31.1          |\n",
      "| total_timesteps    | 2688          |\n",
      "| value_loss         | 0.4385974     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.382875e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00596       |\n",
      "| fps                | 68            |\n",
      "| n_updates          | 22            |\n",
      "| policy_entropy     | 0.088034935   |\n",
      "| policy_loss        | -0.0013376982 |\n",
      "| serial_timesteps   | 2816          |\n",
      "| time_elapsed       | 32.8          |\n",
      "| total_timesteps    | 2816          |\n",
      "| value_loss         | 0.5027834     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.648388e-07  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0405       |\n",
      "| fps                | 78            |\n",
      "| n_updates          | 23            |\n",
      "| policy_entropy     | 0.075479195   |\n",
      "| policy_loss        | -6.900099e-05 |\n",
      "| serial_timesteps   | 2944          |\n",
      "| time_elapsed       | 34.6          |\n",
      "| total_timesteps    | 2944          |\n",
      "| value_loss         | 0.49032456    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.44842015e-05 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0125        |\n",
      "| fps                | 68             |\n",
      "| n_updates          | 24             |\n",
      "| policy_entropy     | 0.07778746     |\n",
      "| policy_loss        | -0.00016139017 |\n",
      "| serial_timesteps   | 3072           |\n",
      "| time_elapsed       | 36.3           |\n",
      "| total_timesteps    | 3072           |\n",
      "| value_loss         | 0.47548383     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017273652 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00666      |\n",
      "| fps                | 73            |\n",
      "| n_updates          | 25            |\n",
      "| policy_entropy     | 0.07951763    |\n",
      "| policy_loss        | -0.0029303893 |\n",
      "| serial_timesteps   | 3200          |\n",
      "| time_elapsed       | 38.1          |\n",
      "| total_timesteps    | 3200          |\n",
      "| value_loss         | 0.44723135    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.082924e-07  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0727       |\n",
      "| fps                | 90            |\n",
      "| n_updates          | 26            |\n",
      "| policy_entropy     | 0.06500944    |\n",
      "| policy_loss        | -2.251356e-06 |\n",
      "| serial_timesteps   | 3328          |\n",
      "| time_elapsed       | 39.9          |\n",
      "| total_timesteps    | 3328          |\n",
      "| value_loss         | 0.47533074    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| approxkl           | 1.9561309e-08  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0342        |\n",
      "| fps                | 82             |\n",
      "| n_updates          | 27             |\n",
      "| policy_entropy     | 0.06286241     |\n",
      "| policy_loss        | -1.8223014e-05 |\n",
      "| serial_timesteps   | 3456           |\n",
      "| time_elapsed       | 41.3           |\n",
      "| total_timesteps    | 3456           |\n",
      "| value_loss         | 0.44987378     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 8.0478624e-10  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.00277       |\n",
      "| fps                | 73             |\n",
      "| n_updates          | 28             |\n",
      "| policy_entropy     | 0.061565623    |\n",
      "| policy_loss        | -3.0500814e-07 |\n",
      "| serial_timesteps   | 3584           |\n",
      "| time_elapsed       | 42.9           |\n",
      "| total_timesteps    | 3584           |\n",
      "| value_loss         | 0.46718693     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.9634214e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0292       |\n",
      "| fps                | 83            |\n",
      "| n_updates          | 29            |\n",
      "| policy_entropy     | 0.060466755   |\n",
      "| policy_loss        | -0.0010191873 |\n",
      "| serial_timesteps   | 3712          |\n",
      "| time_elapsed       | 44.6          |\n",
      "| total_timesteps    | 3712          |\n",
      "| value_loss         | 0.45448264    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.2105054e-08 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0454       |\n",
      "| fps                | 72            |\n",
      "| n_updates          | 30            |\n",
      "| policy_entropy     | 0.05646386    |\n",
      "| policy_loss        | 5.754805e-05  |\n",
      "| serial_timesteps   | 3840          |\n",
      "| time_elapsed       | 46.1          |\n",
      "| total_timesteps    | 3840          |\n",
      "| value_loss         | 0.48749632    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.002879e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0157       |\n",
      "| fps                | 84            |\n",
      "| n_updates          | 31            |\n",
      "| policy_entropy     | 0.05360852    |\n",
      "| policy_loss        | -0.0011783016 |\n",
      "| serial_timesteps   | 3968          |\n",
      "| time_elapsed       | 47.9          |\n",
      "| total_timesteps    | 3968          |\n",
      "| value_loss         | 0.46090174    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.227375e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0388       |\n",
      "| fps                | 80            |\n",
      "| n_updates          | 32            |\n",
      "| policy_entropy     | 0.04586958    |\n",
      "| policy_loss        | -0.0004808883 |\n",
      "| serial_timesteps   | 4096          |\n",
      "| time_elapsed       | 49.4          |\n",
      "| total_timesteps    | 4096          |\n",
      "| value_loss         | 0.45761245    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.7977682e-08 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0265       |\n",
      "| fps                | 80            |\n",
      "| n_updates          | 33            |\n",
      "| policy_entropy     | 0.04238561    |\n",
      "| policy_loss        | -8.773641e-06 |\n",
      "| serial_timesteps   | 4224          |\n",
      "| time_elapsed       | 51            |\n",
      "| total_timesteps    | 4224          |\n",
      "| value_loss         | 0.4976166     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.6052238e-10 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0167       |\n",
      "| fps                | 75            |\n",
      "| n_updates          | 34            |\n",
      "| policy_entropy     | 0.041842718   |\n",
      "| policy_loss        | 4.212605e-06  |\n",
      "| serial_timesteps   | 4352          |\n",
      "| time_elapsed       | 52.6          |\n",
      "| total_timesteps    | 4352          |\n",
      "| value_loss         | 0.44981387    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.380385e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0146        |\n",
      "| fps                | 83             |\n",
      "| n_updates          | 35             |\n",
      "| policy_entropy     | 0.044086818    |\n",
      "| policy_loss        | -0.00024254387 |\n",
      "| serial_timesteps   | 4480           |\n",
      "| time_elapsed       | 54.3           |\n",
      "| total_timesteps    | 4480           |\n",
      "| value_loss         | 0.43132845     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.5705162e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0322         |\n",
      "| fps                | 95             |\n",
      "| n_updates          | 36             |\n",
      "| policy_entropy     | 0.04499931     |\n",
      "| policy_loss        | -0.00025631604 |\n",
      "| serial_timesteps   | 4608           |\n",
      "| time_elapsed       | 55.8           |\n",
      "| total_timesteps    | 4608           |\n",
      "| value_loss         | 0.46284574     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.6604923e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0913        |\n",
      "| fps                | 83             |\n",
      "| n_updates          | 37             |\n",
      "| policy_entropy     | 0.04188012     |\n",
      "| policy_loss        | -9.0964604e-05 |\n",
      "| serial_timesteps   | 4736           |\n",
      "| time_elapsed       | 57.2           |\n",
      "| total_timesteps    | 4736           |\n",
      "| value_loss         | 0.47226602     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.9152062e-08 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.000845      |\n",
      "| fps                | 67            |\n",
      "| n_updates          | 38            |\n",
      "| policy_entropy     | 0.04313705    |\n",
      "| policy_loss        | 1.6965787e-05 |\n",
      "| serial_timesteps   | 4864          |\n",
      "| time_elapsed       | 58.7          |\n",
      "| total_timesteps    | 4864          |\n",
      "| value_loss         | 0.4342162     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.7691002e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0219         |\n",
      "| fps                | 87             |\n",
      "| n_updates          | 39             |\n",
      "| policy_entropy     | 0.04390106     |\n",
      "| policy_loss        | -0.00016796135 |\n",
      "| serial_timesteps   | 4992           |\n",
      "| time_elapsed       | 60.6           |\n",
      "| total_timesteps    | 4992           |\n",
      "| value_loss         | 0.4866521      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.8358363e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0456        |\n",
      "| fps                | 75             |\n",
      "| n_updates          | 40             |\n",
      "| policy_entropy     | 0.04201275     |\n",
      "| policy_loss        | -0.00015729229 |\n",
      "| serial_timesteps   | 5120           |\n",
      "| time_elapsed       | 62.1           |\n",
      "| total_timesteps    | 5120           |\n",
      "| value_loss         | 0.4993288      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.028209e-07   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0168        |\n",
      "| fps                | 78             |\n",
      "| n_updates          | 41             |\n",
      "| policy_entropy     | 0.04577239     |\n",
      "| policy_loss        | -2.4981913e-05 |\n",
      "| serial_timesteps   | 5248           |\n",
      "| time_elapsed       | 63.8           |\n",
      "| total_timesteps    | 5248           |\n",
      "| value_loss         | 0.477748       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.8411549e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.00177       |\n",
      "| fps                | 80             |\n",
      "| n_updates          | 42             |\n",
      "| policy_entropy     | 0.044670325    |\n",
      "| policy_loss        | -0.00062704843 |\n",
      "| serial_timesteps   | 5376           |\n",
      "| time_elapsed       | 65.4           |\n",
      "| total_timesteps    | 5376           |\n",
      "| value_loss         | 0.45206136     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| approxkl           | 6.5896835e-08  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.00259        |\n",
      "| fps                | 71             |\n",
      "| n_updates          | 43             |\n",
      "| policy_entropy     | 0.039635237    |\n",
      "| policy_loss        | -1.7508864e-06 |\n",
      "| serial_timesteps   | 5504           |\n",
      "| time_elapsed       | 67             |\n",
      "| total_timesteps    | 5504           |\n",
      "| value_loss         | 0.47599286     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.8081136e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0472       |\n",
      "| fps                | 95            |\n",
      "| n_updates          | 44            |\n",
      "| policy_entropy     | 0.038292553   |\n",
      "| policy_loss        | -0.0006501548 |\n",
      "| serial_timesteps   | 5632          |\n",
      "| time_elapsed       | 68.8          |\n",
      "| total_timesteps    | 5632          |\n",
      "| value_loss         | 0.48483366    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.242751e-08   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0184        |\n",
      "| fps                | 84             |\n",
      "| n_updates          | 45             |\n",
      "| policy_entropy     | 0.035230108    |\n",
      "| policy_loss        | -1.0130927e-05 |\n",
      "| serial_timesteps   | 5760           |\n",
      "| time_elapsed       | 70.2           |\n",
      "| total_timesteps    | 5760           |\n",
      "| value_loss         | 0.47014475     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.4418842e-09  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0581        |\n",
      "| fps                | 72             |\n",
      "| n_updates          | 46             |\n",
      "| policy_entropy     | 0.033419564    |\n",
      "| policy_loss        | -3.9521838e-06 |\n",
      "| serial_timesteps   | 5888           |\n",
      "| time_elapsed       | 71.7           |\n",
      "| total_timesteps    | 5888           |\n",
      "| value_loss         | 0.48654673     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.0777532e-10  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.014         |\n",
      "| fps                | 77             |\n",
      "| n_updates          | 47             |\n",
      "| policy_entropy     | 0.034658916    |\n",
      "| policy_loss        | -3.4691766e-07 |\n",
      "| serial_timesteps   | 6016           |\n",
      "| time_elapsed       | 73.4           |\n",
      "| total_timesteps    | 6016           |\n",
      "| value_loss         | 0.49076104     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00020223355 |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| explained_variance | -0.0382       |\n",
      "| fps                | 75            |\n",
      "| n_updates          | 48            |\n",
      "| policy_entropy     | 0.030921103   |\n",
      "| policy_loss        | -0.0020038318 |\n",
      "| serial_timesteps   | 6144          |\n",
      "| time_elapsed       | 75.1          |\n",
      "| total_timesteps    | 6144          |\n",
      "| value_loss         | 0.48244408    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.9604143e-08 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.013         |\n",
      "| fps                | 81            |\n",
      "| n_updates          | 49            |\n",
      "| policy_entropy     | 0.027065039   |\n",
      "| policy_loss        | 8.037547e-06  |\n",
      "| serial_timesteps   | 6272          |\n",
      "| time_elapsed       | 76.8          |\n",
      "| total_timesteps    | 6272          |\n",
      "| value_loss         | 0.4708664     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.024276e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0506         |\n",
      "| fps                | 78             |\n",
      "| n_updates          | 50             |\n",
      "| policy_entropy     | 0.026404712    |\n",
      "| policy_loss        | -0.00016097771 |\n",
      "| serial_timesteps   | 6400           |\n",
      "| time_elapsed       | 78.4           |\n",
      "| total_timesteps    | 6400           |\n",
      "| value_loss         | 0.43628708     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.9188555e-08 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0546       |\n",
      "| fps                | 86            |\n",
      "| n_updates          | 51            |\n",
      "| policy_entropy     | 0.028257726   |\n",
      "| policy_loss        | 7.243012e-06  |\n",
      "| serial_timesteps   | 6528          |\n",
      "| time_elapsed       | 80            |\n",
      "| total_timesteps    | 6528          |\n",
      "| value_loss         | 0.5097225     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.897868e-10  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0619       |\n",
      "| fps                | 79            |\n",
      "| n_updates          | 52            |\n",
      "| policy_entropy     | 0.028351814   |\n",
      "| policy_loss        | -4.108064e-06 |\n",
      "| serial_timesteps   | 6656          |\n",
      "| time_elapsed       | 81.5          |\n",
      "| total_timesteps    | 6656          |\n",
      "| value_loss         | 0.4674773     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.0503224e-10 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0294       |\n",
      "| fps                | 69            |\n",
      "| n_updates          | 53            |\n",
      "| policy_entropy     | 0.02905576    |\n",
      "| policy_loss        | -2.079003e-06 |\n",
      "| serial_timesteps   | 6784          |\n",
      "| time_elapsed       | 83.1          |\n",
      "| total_timesteps    | 6784          |\n",
      "| value_loss         | 0.44940022    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.054038e-10   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0281        |\n",
      "| fps                | 74             |\n",
      "| n_updates          | 54             |\n",
      "| policy_entropy     | 0.029709464    |\n",
      "| policy_loss        | -4.1746534e-07 |\n",
      "| serial_timesteps   | 6912           |\n",
      "| time_elapsed       | 84.9           |\n",
      "| total_timesteps    | 6912           |\n",
      "| value_loss         | 0.43046206     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.934376e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0104        |\n",
      "| fps                | 81             |\n",
      "| n_updates          | 55             |\n",
      "| policy_entropy     | 0.02921966     |\n",
      "| policy_loss        | -0.00071954436 |\n",
      "| serial_timesteps   | 7040           |\n",
      "| time_elapsed       | 86.6           |\n",
      "| total_timesteps    | 7040           |\n",
      "| value_loss         | 0.47215813     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.6752383e-08  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0257         |\n",
      "| fps                | 85             |\n",
      "| n_updates          | 56             |\n",
      "| policy_entropy     | 0.02506286     |\n",
      "| policy_loss        | -1.2232631e-05 |\n",
      "| serial_timesteps   | 7168           |\n",
      "| time_elapsed       | 88.2           |\n",
      "| total_timesteps    | 7168           |\n",
      "| value_loss         | 0.45199946     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 7.211121e-10 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0344      |\n",
      "| fps                | 92           |\n",
      "| n_updates          | 57           |\n",
      "| policy_entropy     | 0.023874184  |\n",
      "| policy_loss        | 3.340072e-06 |\n",
      "| serial_timesteps   | 7296         |\n",
      "| time_elapsed       | 89.7         |\n",
      "| total_timesteps    | 7296         |\n",
      "| value_loss         | 0.49368924   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.5393636e-11  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.000379      |\n",
      "| fps                | 74             |\n",
      "| n_updates          | 58             |\n",
      "| policy_entropy     | 0.024315642    |\n",
      "| policy_loss        | -1.5622936e-07 |\n",
      "| serial_timesteps   | 7424           |\n",
      "| time_elapsed       | 91.1           |\n",
      "| total_timesteps    | 7424           |\n",
      "| value_loss         | 0.45700333     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| approxkl           | 8.566875e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.00896       |\n",
      "| fps                | 87             |\n",
      "| n_updates          | 59             |\n",
      "| policy_entropy     | 0.024827905    |\n",
      "| policy_loss        | -0.00016358262 |\n",
      "| serial_timesteps   | 7552           |\n",
      "| time_elapsed       | 92.8           |\n",
      "| total_timesteps    | 7552           |\n",
      "| value_loss         | 0.4371919      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.5891875e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0266        |\n",
      "| fps                | 88             |\n",
      "| n_updates          | 60             |\n",
      "| policy_entropy     | 0.027256342    |\n",
      "| policy_loss        | -0.00038973405 |\n",
      "| serial_timesteps   | 7680           |\n",
      "| time_elapsed       | 94.3           |\n",
      "| total_timesteps    | 7680           |\n",
      "| value_loss         | 0.45466033     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.3989593e-08 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0115        |\n",
      "| fps                | 73            |\n",
      "| n_updates          | 61            |\n",
      "| policy_entropy     | 0.031838324   |\n",
      "| policy_loss        | 1.3443641e-06 |\n",
      "| serial_timesteps   | 7808          |\n",
      "| time_elapsed       | 95.7          |\n",
      "| total_timesteps    | 7808          |\n",
      "| value_loss         | 0.44280338    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.1984992e-09 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.000476     |\n",
      "| fps                | 76            |\n",
      "| n_updates          | 62            |\n",
      "| policy_entropy     | 0.032056168   |\n",
      "| policy_loss        | 1.1292286e-07 |\n",
      "| serial_timesteps   | 7936          |\n",
      "| time_elapsed       | 97.5          |\n",
      "| total_timesteps    | 7936          |\n",
      "| value_loss         | 0.41313988    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.609546e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0104         |\n",
      "| fps                | 86             |\n",
      "| n_updates          | 63             |\n",
      "| policy_entropy     | 0.030537304    |\n",
      "| policy_loss        | -0.00016585004 |\n",
      "| serial_timesteps   | 8064           |\n",
      "| time_elapsed       | 99.2           |\n",
      "| total_timesteps    | 8064           |\n",
      "| value_loss         | 0.43505284     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00020905792 |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| explained_variance | -0.017        |\n",
      "| fps                | 78            |\n",
      "| n_updates          | 64            |\n",
      "| policy_entropy     | 0.027084967   |\n",
      "| policy_loss        | -0.00245661   |\n",
      "| serial_timesteps   | 8192          |\n",
      "| time_elapsed       | 101           |\n",
      "| total_timesteps    | 8192          |\n",
      "| value_loss         | 0.46484658    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.240192e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00083       |\n",
      "| fps                | 77            |\n",
      "| n_updates          | 65            |\n",
      "| policy_entropy     | 0.021687549   |\n",
      "| policy_loss        | -0.0006338492 |\n",
      "| serial_timesteps   | 8320          |\n",
      "| time_elapsed       | 102           |\n",
      "| total_timesteps    | 8320          |\n",
      "| value_loss         | 0.46627003    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.488737e-09  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00395      |\n",
      "| fps                | 79            |\n",
      "| n_updates          | 66            |\n",
      "| policy_entropy     | 0.020318283   |\n",
      "| policy_loss        | -7.462222e-07 |\n",
      "| serial_timesteps   | 8448          |\n",
      "| time_elapsed       | 104           |\n",
      "| total_timesteps    | 8448          |\n",
      "| value_loss         | 0.401761      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.8385567e-10 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.000757      |\n",
      "| fps                | 84            |\n",
      "| n_updates          | 67            |\n",
      "| policy_entropy     | 0.019643812   |\n",
      "| policy_loss        | 2.0326115e-07 |\n",
      "| serial_timesteps   | 8576          |\n",
      "| time_elapsed       | 106           |\n",
      "| total_timesteps    | 8576          |\n",
      "| value_loss         | 0.43510723    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.3735902e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0594       |\n",
      "| fps                | 79            |\n",
      "| n_updates          | 68            |\n",
      "| policy_entropy     | 0.018952634   |\n",
      "| policy_loss        | -0.0006711938 |\n",
      "| serial_timesteps   | 8704          |\n",
      "| time_elapsed       | 107           |\n",
      "| total_timesteps    | 8704          |\n",
      "| value_loss         | 0.43132758    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.5949825e-09 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0188       |\n",
      "| fps                | 76            |\n",
      "| n_updates          | 69            |\n",
      "| policy_entropy     | 0.017150017   |\n",
      "| policy_loss        | -1.156819e-06 |\n",
      "| serial_timesteps   | 8832          |\n",
      "| time_elapsed       | 109           |\n",
      "| total_timesteps    | 8832          |\n",
      "| value_loss         | 0.41993782    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.3929154e-11 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0153       |\n",
      "| fps                | 73            |\n",
      "| n_updates          | 70            |\n",
      "| policy_entropy     | 0.016973406   |\n",
      "| policy_loss        | 1.6056001e-06 |\n",
      "| serial_timesteps   | 8960          |\n",
      "| time_elapsed       | 110           |\n",
      "| total_timesteps    | 8960          |\n",
      "| value_loss         | 0.45677447    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.3141262e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0111        |\n",
      "| fps                | 68            |\n",
      "| n_updates          | 71            |\n",
      "| policy_entropy     | 0.015868107   |\n",
      "| policy_loss        | -0.0007722307 |\n",
      "| serial_timesteps   | 9088          |\n",
      "| time_elapsed       | 112           |\n",
      "| total_timesteps    | 9088          |\n",
      "| value_loss         | 0.4894391     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 8.751937e-09   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0376        |\n",
      "| fps                | 78             |\n",
      "| n_updates          | 72             |\n",
      "| policy_entropy     | 0.01413667     |\n",
      "| policy_loss        | -1.1620577e-06 |\n",
      "| serial_timesteps   | 9216           |\n",
      "| time_elapsed       | 114            |\n",
      "| total_timesteps    | 9216           |\n",
      "| value_loss         | 0.43715206     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.9550642e-10 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00301      |\n",
      "| fps                | 86            |\n",
      "| n_updates          | 73            |\n",
      "| policy_entropy     | 0.013631428   |\n",
      "| policy_loss        | 1.3888348e-07 |\n",
      "| serial_timesteps   | 9344          |\n",
      "| time_elapsed       | 116           |\n",
      "| total_timesteps    | 9344          |\n",
      "| value_loss         | 0.4695225     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.066573e-12  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00113      |\n",
      "| fps                | 75            |\n",
      "| n_updates          | 74            |\n",
      "| policy_entropy     | 0.013185225   |\n",
      "| policy_loss        | -6.821938e-08 |\n",
      "| serial_timesteps   | 9472          |\n",
      "| time_elapsed       | 117           |\n",
      "| total_timesteps    | 9472          |\n",
      "| value_loss         | 0.45748562    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.3085596e-12 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00393      |\n",
      "| fps                | 81            |\n",
      "| n_updates          | 75            |\n",
      "| policy_entropy     | 0.013746563   |\n",
      "| policy_loss        | 1.1641532e-08 |\n",
      "| serial_timesteps   | 9600          |\n",
      "| time_elapsed       | 119           |\n",
      "| total_timesteps    | 9600          |\n",
      "| value_loss         | 0.4387453     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 1.0163126e-11 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00642      |\n",
      "| fps                | 78            |\n",
      "| n_updates          | 76            |\n",
      "| policy_entropy     | 0.013726097   |\n",
      "| policy_loss        | -7.415656e-08 |\n",
      "| serial_timesteps   | 9728          |\n",
      "| time_elapsed       | 120           |\n",
      "| total_timesteps    | 9728          |\n",
      "| value_loss         | 0.4595647     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.290533e-12  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0102        |\n",
      "| fps                | 74            |\n",
      "| n_updates          | 77            |\n",
      "| policy_entropy     | 0.013550932   |\n",
      "| policy_loss        | -4.656613e-09 |\n",
      "| serial_timesteps   | 9856          |\n",
      "| time_elapsed       | 122           |\n",
      "| total_timesteps    | 9856          |\n",
      "| value_loss         | 0.4008711     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.4578264e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.00703       |\n",
      "| fps                | 85             |\n",
      "| n_updates          | 78             |\n",
      "| policy_entropy     | 0.013173193    |\n",
      "| policy_loss        | -0.00030561874 |\n",
      "| serial_timesteps   | 9984           |\n",
      "| time_elapsed       | 124            |\n",
      "| total_timesteps    | 9984           |\n",
      "| value_loss         | 0.47318247     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7f66dd67a7d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = DummyVecEnv([lambda: env])\n",
    "PPO2model = PPO2(MlpPolicy, env, verbose=1)\n",
    "PPO2model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO2model.save('models/PPO2-qiscoin-v1-10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an A2C agent\n",
    "We train a A2C agent over 10000 games of **QisCoin** and save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:312: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:312: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:159: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "| explained_variance | -0.35    |\n",
      "| fps                | 25       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.35     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.149   |\n",
      "| fps                | 88       |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.13     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.211   |\n",
      "| fps                | 89       |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 0.692    |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.25     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.199   |\n",
      "| fps                | 88       |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 0.69     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.31     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.709   |\n",
      "| fps                | 82       |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 0.686    |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.38     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.159    |\n",
      "| fps                | 79       |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 0.675    |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.818    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.075    |\n",
      "| fps                | 79       |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 0.653    |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.911    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.128   |\n",
      "| fps                | 79       |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 0.613    |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.27     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.156   |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 0.49     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.3      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.13    |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 0.335    |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 0.765    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0652  |\n",
      "| fps                | 76       |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 0.221    |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.716    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 74       |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 0.147    |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 0.265    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.445   |\n",
      "| fps                | 74       |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 0.165    |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.976    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.15     |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 0.174    |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 0.674    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0178  |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 0.104    |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.02     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 0.0807   |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.506    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0565  |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 0.0615   |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 1.04     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.203   |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 0.0397   |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.16     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 0.0265   |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.508    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.0372   |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 0.0368   |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.34     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 74       |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 0.0266   |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.512    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.a2c.a2c.A2C at 0x7f66dc0f4a10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2Cmodel = A2C(MlpPolicy, env, verbose=1)\n",
    "A2Cmodel.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2Cmodel.save('models/A2C-qiscoin-v1-10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an ACER agent\n",
    "We train a ACER agent over 10000 games of **QisCoin** and save the trained model.\n",
    "\n",
    "More information on the A2C agent: https://stable-baselines.readthedocs.io/en/v2.3.0/modules/acer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import ACER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/acer/acer_simple.py:363: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.\n",
      "\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.274    |\n",
      "| avg_norm_g          | 2        |\n",
      "| avg_norm_grads_f    | 1.77     |\n",
      "| avg_norm_k          | 1.41     |\n",
      "| avg_norm_k_dot_g    | 2        |\n",
      "| entropy             | 14.6     |\n",
      "| explained_variance  | -0.00138 |\n",
      "| fps                 | 0        |\n",
      "| loss                | 0.0379   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.0668  |\n",
      "| loss_policy         | -0.0668  |\n",
      "| loss_q              | 0.501    |\n",
      "| mean_episode_length | 1        |\n",
      "| mean_episode_reward | -0.1     |\n",
      "| norm_grads          | 0.883    |\n",
      "| norm_grads_policy   | 0.748    |\n",
      "| norm_grads_q        | 0.47     |\n",
      "| total_timesteps     | 0        |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.318    |\n",
      "| avg_norm_g          | 2.03     |\n",
      "| avg_norm_grads_f    | 1.76     |\n",
      "| avg_norm_k          | 1.44     |\n",
      "| avg_norm_k_dot_g    | 2.07     |\n",
      "| entropy             | 14.1     |\n",
      "| explained_variance  | 0.0138   |\n",
      "| fps                 | 74       |\n",
      "| loss                | -0.0113  |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.118   |\n",
      "| loss_policy         | -0.118   |\n",
      "| loss_q              | 0.496    |\n",
      "| mean_episode_length | 1        |\n",
      "| mean_episode_reward | -0.1     |\n",
      "| norm_grads          | 0.866    |\n",
      "| norm_grads_policy   | 0.709    |\n",
      "| norm_grads_q        | 0.498    |\n",
      "| total_timesteps     | 2000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.05     |\n",
      "| avg_norm_g          | 1.58     |\n",
      "| avg_norm_grads_f    | 1.54     |\n",
      "| avg_norm_k          | 1.85     |\n",
      "| avg_norm_k_dot_g    | 1.79     |\n",
      "| entropy             | 5.54     |\n",
      "| explained_variance  | -0.096   |\n",
      "| fps                 | 72       |\n",
      "| loss                | 0.318    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.0575   |\n",
      "| loss_policy         | 0.0575   |\n",
      "| loss_q              | 0.632    |\n",
      "| mean_episode_length | 1        |\n",
      "| mean_episode_reward | 0.05     |\n",
      "| norm_grads          | 0.756    |\n",
      "| norm_grads_policy   | 0.353    |\n",
      "| norm_grads_q        | 0.669    |\n",
      "| total_timesteps     | 4000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0263   |\n",
      "| avg_norm_g          | 0.922    |\n",
      "| avg_norm_grads_f    | 0.898    |\n",
      "| avg_norm_k          | 1.99     |\n",
      "| avg_norm_k_dot_g    | 0.917    |\n",
      "| entropy             | 0.879    |\n",
      "| explained_variance  | -0.0119  |\n",
      "| fps                 | 71       |\n",
      "| loss                | 0.222    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.000272 |\n",
      "| loss_policy         | 0.000272 |\n",
      "| loss_q              | 0.46     |\n",
      "| mean_episode_length | 1        |\n",
      "| mean_episode_reward | 0.35     |\n",
      "| norm_grads          | 0.212    |\n",
      "| norm_grads_policy   | 0.00576  |\n",
      "| norm_grads_q        | 0.212    |\n",
      "| total_timesteps     | 6000     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| avg_norm_adj        | 0.0516    |\n",
      "| avg_norm_g          | 0.944     |\n",
      "| avg_norm_grads_f    | 0.896     |\n",
      "| avg_norm_k          | 1.49      |\n",
      "| avg_norm_k_dot_g    | 0.943     |\n",
      "| entropy             | 0.477     |\n",
      "| explained_variance  | 0.00397   |\n",
      "| fps                 | 71        |\n",
      "| loss                | 0.236     |\n",
      "| loss_bc             | -0        |\n",
      "| loss_f              | -0.000711 |\n",
      "| loss_policy         | -0.000711 |\n",
      "| loss_q              | 0.482     |\n",
      "| mean_episode_length | 1         |\n",
      "| mean_episode_reward | 0.05      |\n",
      "| norm_grads          | 0.424     |\n",
      "| norm_grads_policy   | 0.00728   |\n",
      "| norm_grads_q        | 0.423     |\n",
      "| total_timesteps     | 8000      |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.acer.acer_simple.ACER at 0x7f66cc15df10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACERmodel = ACER(MlpPolicy, env, verbose=1)\n",
    "ACERmodel.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACERmodel.save('models/ACER-qiscoin-v1-10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the agents\n",
    "We now compare and evalute the agents using the evaluation functions provided in [evaluation.py](evaluation.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation as ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start running and evaluating the simple random agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -0.012\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_random(gym.make('qiscoin-v1'), num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average reward is around $0$. As before, the result makes sense since the agent has $50\\%$ probability of guessing right at each iteration, and thus, in the long run, the positive rewards for guessing right ($+1$) compensate the negative rewards for guessing wrong ($-1$).\n",
    "\n",
    "Next we test a biased agent that constantly guesses $0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.274\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_biased(gym.make('qiscoin-v1'), num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average reward is improved compared to the random agent. Once again, adopting the policy of always guessing 0 allows the agent to achieve a better performance.\n",
    "\n",
    "Finally, we get to test the three agents (PPO2, A2C, ACER) we trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.316\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_model(PPO2model, env, num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.338\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_model(A2Cmodel, env, num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.314\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_model(ACERmodel, env, num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the agents achieve average rewards over 0.3. This is a slight improvement over the agents with deterministic non-learned policies, but it seems still far from a perfect player (a detailed examination would require an estimation of all the possibilities and the chances of guessing right, as done in the previous notebook). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing agents trained for longer\n",
    "\n",
    "For completeness, we evalute the performances of the three models under a longer training of 100000 iterations of the game (performed offline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
     ]
    }
   ],
   "source": [
    "PPO2model_100k = PPO2.load('models/PPO2-qiscoin-v1-100k')\n",
    "A2Cmodel_100k = A2C.load('models/A2C-qiscoin-v1-100k')\n",
    "ACERmodel_100k = ACER.load('models/ACER-qiscoin-v1-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.292\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_model(PPO2model_100k, env, num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.328\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_model(A2Cmodel_100k, env, num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.312\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_model(ACERmodel_100k, env, num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look in line with the previous average rewards, suggesting that further training hardly help in learning better models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guessing the outcome of the measurement in a quantum circuit built up by six random quantum gates proved to be a non-trivial challenge for default reinforcement learning agents. While a human agents can easily exploit his knowledge of quantum mechanics and come up with heuristics to quickly solve the problem (such as, observing whether the last gate in the circuit makes all previous transformation irrelevant, as in the case of a *x* or *reset* gate), the artificila agents are presented only with an observation made up by a flat six-dimensional vector, and they lack any information about the structure of the problem. In general, learning a supervised mapping between a six-dimensional space (the observation vector) and a deterministic or noisy output is far from being an unsurmountable challenge; however, we hypothesize that intrinsic uncertainty of quantum measurement creates a significant challenge for the reinforcement learning agents. Yet, our evaluation of the RL models have been quite shallow, and limited to standard setting; it is likely that a better tuning of the agents (and the possible injection of prior knowledge about the problem and its structure) may lead to better learned models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
