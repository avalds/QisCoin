{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent Playing QisCoin v0\n",
    "\n",
    "In this notebook we load a simple version of **QisCoin** (*qiscoin-v0*) in which a quantum circuit with a single random gate is generated. We instantiate and run a random agent and few RL agents from the stable-baselines library and we observe their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "\n",
    "We start importing the main required libraries: OpenAI *gym* to run the game; *IPython.display* to print out our circuits.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing gym-qiscoin\n",
    "\n",
    "Next, we import the version of **QisCoin** wrapped into the *gym* interface. The code for this version of the game is available [here](https://github.uio.no/fabiomz/gym-qiscoin) and it can be installed as explained in the notebook [Setup](https://github.com/avalds/QisCoin/blob/master/1-%20Setup.ipynb).\n",
    "\n",
    "This version of **QisCoin** implements a game environment that inherits from the *OpenAI gym* **Env** class. It implements four main methods: *__init__()* for setting up the game; *step()* computing the result of a single time-step of evolution of the environment; *reset()* restarting the game; *render()* displaying the game.\n",
    "\n",
    "The **QisCoin** game has been modeled with a *discrete state space* (an integer number between 0 and 5 identifies which of the six possible gates has been randomly added on the circuit) and a *discrete action space* (the two integer numbers 0 and 1 corresponds to the possible guesses of the agent). Since the game is fully observed, the state space corresponds to the observation space. A positive reward (+1) is returned for guessing correctly, a negative reward (-1) is returned for guessing wrong.\n",
    "\n",
    "The code is available in the source file: https://github.uio.no/fabiomz/gym-qiscoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiscoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the game\n",
    "We create the game enviroment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('qiscoin-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we test the game running a single iteration of the game where the AI agent takes a random guess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 293.776x144.48 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is guessing that the outcome will be 1\n",
      "The guess is wrong!\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "display(env.render())\n",
    "\n",
    "for _ in range(1):\n",
    "    guess = env.action_space.sample()\n",
    "    print(\"AI is guessing that the outcome will be {0}\".format(guess))\n",
    "    obs, reward, done, info = env.step(guess)\n",
    "    if(reward==1):\n",
    "        print(\"The guess is correct!\")\n",
    "    else:\n",
    "        print(\"The guess is wrong!\")\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Reinforcement Learning Agent\n",
    "\n",
    "Running a random agent playing **QisCoin** is not particularly interesting. We then turn to loading and running reinforcement learning agents that, starting from a random policy, would be able to learn to play **QisCoin** in a sensible way. To do so, we rely on the library of agents provided by stable-baselines.\n",
    "\n",
    "More information and examples on stable-baselines: https://github.com/hill-a/stable-baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a PPO2 Agent\n",
    "\n",
    "We consider instanting and training a PPO2 agent.\n",
    "\n",
    "More information on the PPO2 agent: https://stable-baselines.readthedocs.io/en/v2.3.0/modules/ppo2.html\n",
    "\n",
    "First of all we import the required modules: *DummyVecEnv* providing a wrapper for our environment as required by stable-baselines; *MlpPolicy* specifying a policy for our agent; *PPO2* implementing the actual agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then vectorize our environment (this is a formal step required for the agent to be able to play the game), we instantiate the PPO2 model, and we train it by playing 10000 games of **QisCoin**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/input.py:20: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/policies.py:562: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/distributions.py:323: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/distributions.py:324: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:193: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:201: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:209: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:243: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:245: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "-------------------------------------\n",
      "| approxkl           | 7.693445e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0213      |\n",
      "| fps                | 53           |\n",
      "| n_updates          | 1            |\n",
      "| policy_entropy     | 0.6930711    |\n",
      "| policy_loss        | -0.008845119 |\n",
      "| serial_timesteps   | 128          |\n",
      "| time_elapsed       | 6.2e-06      |\n",
      "| total_timesteps    | 128          |\n",
      "| value_loss         | 0.50188786   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00013692732 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0914       |\n",
      "| fps                | 78            |\n",
      "| n_updates          | 2             |\n",
      "| policy_entropy     | 0.6924358     |\n",
      "| policy_loss        | -0.011318557  |\n",
      "| serial_timesteps   | 256           |\n",
      "| time_elapsed       | 2.38          |\n",
      "| total_timesteps    | 256           |\n",
      "| value_loss         | 0.55051774    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0003077288 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0283      |\n",
      "| fps                | 75           |\n",
      "| n_updates          | 3            |\n",
      "| policy_entropy     | 0.6902249    |\n",
      "| policy_loss        | -0.017182305 |\n",
      "| serial_timesteps   | 384          |\n",
      "| time_elapsed       | 4.02         |\n",
      "| total_timesteps    | 384          |\n",
      "| value_loss         | 0.5051036    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0007083648 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0329      |\n",
      "| fps                | 72           |\n",
      "| n_updates          | 4            |\n",
      "| policy_entropy     | 0.6840919    |\n",
      "| policy_loss        | -0.026551645 |\n",
      "| serial_timesteps   | 512          |\n",
      "| time_elapsed       | 5.73         |\n",
      "| total_timesteps    | 512          |\n",
      "| value_loss         | 0.5137408    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0011109058 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.0088       |\n",
      "| fps                | 70           |\n",
      "| n_updates          | 5            |\n",
      "| policy_entropy     | 0.67152065   |\n",
      "| policy_loss        | -0.031824958 |\n",
      "| serial_timesteps   | 640          |\n",
      "| time_elapsed       | 7.51         |\n",
      "| total_timesteps    | 640          |\n",
      "| value_loss         | 0.4925857    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0018547138 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.0032       |\n",
      "| fps                | 69           |\n",
      "| n_updates          | 6            |\n",
      "| policy_entropy     | 0.64634377   |\n",
      "| policy_loss        | -0.04216621  |\n",
      "| serial_timesteps   | 768          |\n",
      "| time_elapsed       | 9.32         |\n",
      "| total_timesteps    | 768          |\n",
      "| value_loss         | 0.4883912    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0031021056 |\n",
      "| clipfrac           | 0.029296875  |\n",
      "| explained_variance | 0.0343       |\n",
      "| fps                | 70           |\n",
      "| n_updates          | 7            |\n",
      "| policy_entropy     | 0.6067466    |\n",
      "| policy_loss        | -0.04946518  |\n",
      "| serial_timesteps   | 896          |\n",
      "| time_elapsed       | 11.1         |\n",
      "| total_timesteps    | 896          |\n",
      "| value_loss         | 0.4690866    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0033274174 |\n",
      "| clipfrac           | 0.04296875   |\n",
      "| explained_variance | 0.0208       |\n",
      "| fps                | 72           |\n",
      "| n_updates          | 8            |\n",
      "| policy_entropy     | 0.52880067   |\n",
      "| policy_loss        | -0.052035764 |\n",
      "| serial_timesteps   | 1024         |\n",
      "| time_elapsed       | 13           |\n",
      "| total_timesteps    | 1024         |\n",
      "| value_loss         | 0.4283456    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0033595848 |\n",
      "| clipfrac           | 0.044921875  |\n",
      "| explained_variance | 0.0345       |\n",
      "| fps                | 71           |\n",
      "| n_updates          | 9            |\n",
      "| policy_entropy     | 0.47678277   |\n",
      "| policy_loss        | -0.049283408 |\n",
      "| serial_timesteps   | 1152         |\n",
      "| time_elapsed       | 14.7         |\n",
      "| total_timesteps    | 1152         |\n",
      "| value_loss         | 0.38884616   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.0019178754 |\n",
      "| clipfrac           | 0.029296875  |\n",
      "| explained_variance | 0.118        |\n",
      "| fps                | 70           |\n",
      "| n_updates          | 10           |\n",
      "| policy_entropy     | 0.40448287   |\n",
      "| policy_loss        | -0.036613468 |\n",
      "| serial_timesteps   | 1280         |\n",
      "| time_elapsed       | 16.5         |\n",
      "| total_timesteps    | 1280         |\n",
      "| value_loss         | 0.2836885    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0015799836 |\n",
      "| clipfrac           | 0.025390625  |\n",
      "| explained_variance | 0.2          |\n",
      "| fps                | 155          |\n",
      "| n_updates          | 11           |\n",
      "| policy_entropy     | 0.37039658   |\n",
      "| policy_loss        | -0.027952518 |\n",
      "| serial_timesteps   | 1408         |\n",
      "| time_elapsed       | 18.4         |\n",
      "| total_timesteps    | 1408         |\n",
      "| value_loss         | 0.24142356   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.001827776 |\n",
      "| clipfrac           | 0.03125     |\n",
      "| explained_variance | 0.0921      |\n",
      "| fps                | 79          |\n",
      "| n_updates          | 12          |\n",
      "| policy_entropy     | 0.30824274  |\n",
      "| policy_loss        | -0.03326519 |\n",
      "| serial_timesteps   | 1536        |\n",
      "| time_elapsed       | 19.2        |\n",
      "| total_timesteps    | 1536        |\n",
      "| value_loss         | 0.25953206  |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00085032266 |\n",
      "| clipfrac           | 0.01171875    |\n",
      "| explained_variance | 0.111         |\n",
      "| fps                | 70            |\n",
      "| n_updates          | 13            |\n",
      "| policy_entropy     | 0.23857404    |\n",
      "| policy_loss        | -0.023285134  |\n",
      "| serial_timesteps   | 1664          |\n",
      "| time_elapsed       | 20.8          |\n",
      "| total_timesteps    | 1664          |\n",
      "| value_loss         | 0.15257049    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0005615933 |\n",
      "| clipfrac           | 0.0078125    |\n",
      "| explained_variance | 0.109        |\n",
      "| fps                | 70           |\n",
      "| n_updates          | 14           |\n",
      "| policy_entropy     | 0.25262758   |\n",
      "| policy_loss        | -0.014262097 |\n",
      "| serial_timesteps   | 1792         |\n",
      "| time_elapsed       | 22.6         |\n",
      "| total_timesteps    | 1792         |\n",
      "| value_loss         | 0.15263478   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0020264196 |\n",
      "| clipfrac           | 0.021484375  |\n",
      "| explained_variance | 0.259        |\n",
      "| fps                | 87           |\n",
      "| n_updates          | 15           |\n",
      "| policy_entropy     | 0.22083177   |\n",
      "| policy_loss        | -0.025792548 |\n",
      "| serial_timesteps   | 1920         |\n",
      "| time_elapsed       | 24.4         |\n",
      "| total_timesteps    | 1920         |\n",
      "| value_loss         | 0.22029978   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0020648139 |\n",
      "| clipfrac           | 0.037109375  |\n",
      "| explained_variance | 0.507        |\n",
      "| fps                | 78           |\n",
      "| n_updates          | 16           |\n",
      "| policy_entropy     | 0.20720242   |\n",
      "| policy_loss        | -0.016199214 |\n",
      "| serial_timesteps   | 2048         |\n",
      "| time_elapsed       | 25.9         |\n",
      "| total_timesteps    | 2048         |\n",
      "| value_loss         | 0.10000205   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00018825663 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.203         |\n",
      "| fps                | 68            |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 0.18758059    |\n",
      "| policy_loss        | -0.004649076  |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 27.5          |\n",
      "| total_timesteps    | 2176          |\n",
      "| value_loss         | 0.11801868    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00018127114  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.557          |\n",
      "| fps                | 67             |\n",
      "| n_updates          | 18             |\n",
      "| policy_entropy     | 0.2010183      |\n",
      "| policy_loss        | -0.00037928554 |\n",
      "| serial_timesteps   | 2304           |\n",
      "| time_elapsed       | 29.4           |\n",
      "| total_timesteps    | 2304           |\n",
      "| value_loss         | 0.10792536     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00039693253 |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| explained_variance | 0.285         |\n",
      "| fps                | 68            |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 0.16617912    |\n",
      "| policy_loss        | -0.009279782  |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 31.3          |\n",
      "| total_timesteps    | 2432          |\n",
      "| value_loss         | 0.12196244    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.142156e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.503          |\n",
      "| fps                | 70             |\n",
      "| n_updates          | 20             |\n",
      "| policy_entropy     | 0.16461124     |\n",
      "| policy_loss        | -3.7789578e-05 |\n",
      "| serial_timesteps   | 2560           |\n",
      "| time_elapsed       | 33.2           |\n",
      "| total_timesteps    | 2560           |\n",
      "| value_loss         | 0.07843196     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00014644703 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.432         |\n",
      "| fps                | 74            |\n",
      "| n_updates          | 21            |\n",
      "| policy_entropy     | 0.17265964    |\n",
      "| policy_loss        | -0.006166753  |\n",
      "| serial_timesteps   | 2688          |\n",
      "| time_elapsed       | 35            |\n",
      "| total_timesteps    | 2688          |\n",
      "| value_loss         | 0.13312428    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00038056847 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.39          |\n",
      "| fps                | 72            |\n",
      "| n_updates          | 22            |\n",
      "| policy_entropy     | 0.18497194    |\n",
      "| policy_loss        | -0.0050695823 |\n",
      "| serial_timesteps   | 2816          |\n",
      "| time_elapsed       | 36.7          |\n",
      "| total_timesteps    | 2816          |\n",
      "| value_loss         | 0.12637776    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.8178503e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.627         |\n",
      "| fps                | 70            |\n",
      "| n_updates          | 23            |\n",
      "| policy_entropy     | 0.14214057    |\n",
      "| policy_loss        | 0.0011089651  |\n",
      "| serial_timesteps   | 2944          |\n",
      "| time_elapsed       | 38.5          |\n",
      "| total_timesteps    | 2944          |\n",
      "| value_loss         | 0.07620451    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00032568586 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.406         |\n",
      "| fps                | 78            |\n",
      "| n_updates          | 24            |\n",
      "| policy_entropy     | 0.17872202    |\n",
      "| policy_loss        | -0.007454437  |\n",
      "| serial_timesteps   | 3072          |\n",
      "| time_elapsed       | 40.3          |\n",
      "| total_timesteps    | 3072          |\n",
      "| value_loss         | 0.14377148    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00064184034 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.566         |\n",
      "| fps                | 81            |\n",
      "| n_updates          | 25            |\n",
      "| policy_entropy     | 0.14276543    |\n",
      "| policy_loss        | -0.006339334  |\n",
      "| serial_timesteps   | 3200          |\n",
      "| time_elapsed       | 41.9          |\n",
      "| total_timesteps    | 3200          |\n",
      "| value_loss         | 0.089544095   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00051746145 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0383        |\n",
      "| fps                | 69            |\n",
      "| n_updates          | 26            |\n",
      "| policy_entropy     | 0.14005375    |\n",
      "| policy_loss        | -0.0078226775 |\n",
      "| serial_timesteps   | 3328          |\n",
      "| time_elapsed       | 43.5          |\n",
      "| total_timesteps    | 3328          |\n",
      "| value_loss         | 0.11327341    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0002493692  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.532         |\n",
      "| fps                | 74            |\n",
      "| n_updates          | 27            |\n",
      "| policy_entropy     | 0.1422244     |\n",
      "| policy_loss        | -0.0019805476 |\n",
      "| serial_timesteps   | 3456          |\n",
      "| time_elapsed       | 45.3          |\n",
      "| total_timesteps    | 3456          |\n",
      "| value_loss         | 0.09887835    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.225408e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0828        |\n",
      "| fps                | 73            |\n",
      "| n_updates          | 28            |\n",
      "| policy_entropy     | 0.09167169    |\n",
      "| policy_loss        | -0.0032891284 |\n",
      "| serial_timesteps   | 3584          |\n",
      "| time_elapsed       | 47.1          |\n",
      "| total_timesteps    | 3584          |\n",
      "| value_loss         | 0.06898909    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.322252e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.294         |\n",
      "| fps                | 82            |\n",
      "| n_updates          | 29            |\n",
      "| policy_entropy     | 0.17424743    |\n",
      "| policy_loss        | -0.0026778143 |\n",
      "| serial_timesteps   | 3712          |\n",
      "| time_elapsed       | 48.8          |\n",
      "| total_timesteps    | 3712          |\n",
      "| value_loss         | 0.12735131    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00048058835 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.408         |\n",
      "| fps                | 70            |\n",
      "| n_updates          | 30            |\n",
      "| policy_entropy     | 0.13156758    |\n",
      "| policy_loss        | -0.0028161916 |\n",
      "| serial_timesteps   | 3840          |\n",
      "| time_elapsed       | 50.4          |\n",
      "| total_timesteps    | 3840          |\n",
      "| value_loss         | 0.08561251    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.1638992e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.356         |\n",
      "| fps                | 71            |\n",
      "| n_updates          | 31            |\n",
      "| policy_entropy     | 0.11767687    |\n",
      "| policy_loss        | 0.0009248877  |\n",
      "| serial_timesteps   | 3968          |\n",
      "| time_elapsed       | 52.2          |\n",
      "| total_timesteps    | 3968          |\n",
      "| value_loss         | 0.07550512    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00034393463 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.512         |\n",
      "| fps                | 55            |\n",
      "| n_updates          | 32            |\n",
      "| policy_entropy     | 0.118922      |\n",
      "| policy_loss        | -0.0025736808 |\n",
      "| serial_timesteps   | 4096          |\n",
      "| time_elapsed       | 54            |\n",
      "| total_timesteps    | 4096          |\n",
      "| value_loss         | 0.08315307    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.8492763e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.341         |\n",
      "| fps                | 71            |\n",
      "| n_updates          | 33            |\n",
      "| policy_entropy     | 0.1473266     |\n",
      "| policy_loss        | -0.0012824995 |\n",
      "| serial_timesteps   | 4224          |\n",
      "| time_elapsed       | 56.3          |\n",
      "| total_timesteps    | 4224          |\n",
      "| value_loss         | 0.11222612    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0008769326  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.431         |\n",
      "| fps                | 82            |\n",
      "| n_updates          | 34            |\n",
      "| policy_entropy     | 0.120687686   |\n",
      "| policy_loss        | -0.0038220808 |\n",
      "| serial_timesteps   | 4352          |\n",
      "| time_elapsed       | 58.1          |\n",
      "| total_timesteps    | 4352          |\n",
      "| value_loss         | 0.08202251    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00024186763 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.358         |\n",
      "| fps                | 95            |\n",
      "| n_updates          | 35            |\n",
      "| policy_entropy     | 0.1087758     |\n",
      "| policy_loss        | -0.0045893327 |\n",
      "| serial_timesteps   | 4480          |\n",
      "| time_elapsed       | 59.6          |\n",
      "| total_timesteps    | 4480          |\n",
      "| value_loss         | 0.10934821    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00042746094 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.374         |\n",
      "| fps                | 86            |\n",
      "| n_updates          | 36            |\n",
      "| policy_entropy     | 0.098984666   |\n",
      "| policy_loss        | -0.008177131  |\n",
      "| serial_timesteps   | 4608          |\n",
      "| time_elapsed       | 61            |\n",
      "| total_timesteps    | 4608          |\n",
      "| value_loss         | 0.073893234   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.3886652e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.526         |\n",
      "| fps                | 115           |\n",
      "| n_updates          | 37            |\n",
      "| policy_entropy     | 0.06754608    |\n",
      "| policy_loss        | 0.0012208247  |\n",
      "| serial_timesteps   | 4736          |\n",
      "| time_elapsed       | 62.4          |\n",
      "| total_timesteps    | 4736          |\n",
      "| value_loss         | 0.055752408   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.2646855e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.457         |\n",
      "| fps                | 86            |\n",
      "| n_updates          | 38            |\n",
      "| policy_entropy     | 0.09173801    |\n",
      "| policy_loss        | 7.4270065e-05 |\n",
      "| serial_timesteps   | 4864          |\n",
      "| time_elapsed       | 63.6          |\n",
      "| total_timesteps    | 4864          |\n",
      "| value_loss         | 0.07824034    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.5474239e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.4           |\n",
      "| fps                | 67            |\n",
      "| n_updates          | 39            |\n",
      "| policy_entropy     | 0.07805302    |\n",
      "| policy_loss        | -0.0004167601 |\n",
      "| serial_timesteps   | 4992          |\n",
      "| time_elapsed       | 65            |\n",
      "| total_timesteps    | 4992          |\n",
      "| value_loss         | 0.070303984   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.5247933e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.466         |\n",
      "| fps                | 77            |\n",
      "| n_updates          | 40            |\n",
      "| policy_entropy     | 0.10631426    |\n",
      "| policy_loss        | -0.0018226102 |\n",
      "| serial_timesteps   | 5120          |\n",
      "| time_elapsed       | 66.9          |\n",
      "| total_timesteps    | 5120          |\n",
      "| value_loss         | 0.117587075   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00044123948 |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| explained_variance | 0.132         |\n",
      "| fps                | 95            |\n",
      "| n_updates          | 41            |\n",
      "| policy_entropy     | 0.10210124    |\n",
      "| policy_loss        | -0.0033728094 |\n",
      "| serial_timesteps   | 5248          |\n",
      "| time_elapsed       | 68.6          |\n",
      "| total_timesteps    | 5248          |\n",
      "| value_loss         | 0.09169347    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0001900546  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.35          |\n",
      "| fps                | 85            |\n",
      "| n_updates          | 42            |\n",
      "| policy_entropy     | 0.08937421    |\n",
      "| policy_loss        | -0.0025636991 |\n",
      "| serial_timesteps   | 5376          |\n",
      "| time_elapsed       | 69.9          |\n",
      "| total_timesteps    | 5376          |\n",
      "| value_loss         | 0.08511101    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.1517723e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.359          |\n",
      "| fps                | 63             |\n",
      "| n_updates          | 43             |\n",
      "| policy_entropy     | 0.12076512     |\n",
      "| policy_loss        | -0.00074643537 |\n",
      "| serial_timesteps   | 5504           |\n",
      "| time_elapsed       | 71.4           |\n",
      "| total_timesteps    | 5504           |\n",
      "| value_loss         | 0.109114625    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.00023282185 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.307         |\n",
      "| fps                | 57            |\n",
      "| n_updates          | 44            |\n",
      "| policy_entropy     | 0.08344525    |\n",
      "| policy_loss        | -0.0029010624 |\n",
      "| serial_timesteps   | 5632          |\n",
      "| time_elapsed       | 73.4          |\n",
      "| total_timesteps    | 5632          |\n",
      "| value_loss         | 0.06253563    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.9304827e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.198        |\n",
      "| fps                | 70            |\n",
      "| n_updates          | 45            |\n",
      "| policy_entropy     | 0.08173285    |\n",
      "| policy_loss        | 0.0008634463  |\n",
      "| serial_timesteps   | 5760          |\n",
      "| time_elapsed       | 75.7          |\n",
      "| total_timesteps    | 5760          |\n",
      "| value_loss         | 0.053450324   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.945291e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.451         |\n",
      "| fps                | 77            |\n",
      "| n_updates          | 46            |\n",
      "| policy_entropy     | 0.076599926   |\n",
      "| policy_loss        | 0.00037267932 |\n",
      "| serial_timesteps   | 5888          |\n",
      "| time_elapsed       | 77.5          |\n",
      "| total_timesteps    | 5888          |\n",
      "| value_loss         | 0.07435802    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.4463909e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.376         |\n",
      "| fps                | 74            |\n",
      "| n_updates          | 47            |\n",
      "| policy_entropy     | 0.111644894   |\n",
      "| policy_loss        | 0.00052080373 |\n",
      "| serial_timesteps   | 6016          |\n",
      "| time_elapsed       | 79.2          |\n",
      "| total_timesteps    | 6016          |\n",
      "| value_loss         | 0.08894257    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00012318172 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.513         |\n",
      "| fps                | 80            |\n",
      "| n_updates          | 48            |\n",
      "| policy_entropy     | 0.09012147    |\n",
      "| policy_loss        | -0.0024113446 |\n",
      "| serial_timesteps   | 6144          |\n",
      "| time_elapsed       | 80.9          |\n",
      "| total_timesteps    | 6144          |\n",
      "| value_loss         | 0.07459627    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003795639  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.339         |\n",
      "| fps                | 105           |\n",
      "| n_updates          | 49            |\n",
      "| policy_entropy     | 0.14017904    |\n",
      "| policy_loss        | -0.0013198112 |\n",
      "| serial_timesteps   | 6272          |\n",
      "| time_elapsed       | 82.5          |\n",
      "| total_timesteps    | 6272          |\n",
      "| value_loss         | 0.10539022    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.258801e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.484         |\n",
      "| fps                | 109           |\n",
      "| n_updates          | 50            |\n",
      "| policy_entropy     | 0.10307722    |\n",
      "| policy_loss        | 0.00015122465 |\n",
      "| serial_timesteps   | 6400          |\n",
      "| time_elapsed       | 83.7          |\n",
      "| total_timesteps    | 6400          |\n",
      "| value_loss         | 0.07495909    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3201997e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.355         |\n",
      "| fps                | 101           |\n",
      "| n_updates          | 51            |\n",
      "| policy_entropy     | 0.11759814    |\n",
      "| policy_loss        | -5.86191e-05  |\n",
      "| serial_timesteps   | 6528          |\n",
      "| time_elapsed       | 84.9          |\n",
      "| total_timesteps    | 6528          |\n",
      "| value_loss         | 0.08463475    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.3186898e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.381         |\n",
      "| fps                | 78            |\n",
      "| n_updates          | 52            |\n",
      "| policy_entropy     | 0.10443464    |\n",
      "| policy_loss        | 0.0007313299  |\n",
      "| serial_timesteps   | 6656          |\n",
      "| time_elapsed       | 86.1          |\n",
      "| total_timesteps    | 6656          |\n",
      "| value_loss         | 0.072522804   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005003708  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.169         |\n",
      "| fps                | 114           |\n",
      "| n_updates          | 53            |\n",
      "| policy_entropy     | 0.092759356   |\n",
      "| policy_loss        | -0.0016623971 |\n",
      "| serial_timesteps   | 6784          |\n",
      "| time_elapsed       | 87.8          |\n",
      "| total_timesteps    | 6784          |\n",
      "| value_loss         | 0.06177176    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.5985665e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.422          |\n",
      "| fps                | 98             |\n",
      "| n_updates          | 54             |\n",
      "| policy_entropy     | 0.124539085    |\n",
      "| policy_loss        | -0.00012953556 |\n",
      "| serial_timesteps   | 6912           |\n",
      "| time_elapsed       | 88.9           |\n",
      "| total_timesteps    | 6912           |\n",
      "| value_loss         | 0.10681619     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0001795257  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.385         |\n",
      "| fps                | 86            |\n",
      "| n_updates          | 55            |\n",
      "| policy_entropy     | 0.11591643    |\n",
      "| policy_loss        | -0.0018905348 |\n",
      "| serial_timesteps   | 7040          |\n",
      "| time_elapsed       | 90.2          |\n",
      "| total_timesteps    | 7040          |\n",
      "| value_loss         | 0.096452214   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00020026456 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.467         |\n",
      "| fps                | 73            |\n",
      "| n_updates          | 56            |\n",
      "| policy_entropy     | 0.0898033     |\n",
      "| policy_loss        | 0.0023209988  |\n",
      "| serial_timesteps   | 7168          |\n",
      "| time_elapsed       | 91.7          |\n",
      "| total_timesteps    | 7168          |\n",
      "| value_loss         | 0.083214924   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0004970537 |\n",
      "| clipfrac           | 0.01171875   |\n",
      "| explained_variance | 0.171        |\n",
      "| fps                | 76           |\n",
      "| n_updates          | 57           |\n",
      "| policy_entropy     | 0.0896866    |\n",
      "| policy_loss        | -0.009804263 |\n",
      "| serial_timesteps   | 7296         |\n",
      "| time_elapsed       | 93.4         |\n",
      "| total_timesteps    | 7296         |\n",
      "| value_loss         | 0.07530966   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.2110613e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.453         |\n",
      "| fps                | 75            |\n",
      "| n_updates          | 58            |\n",
      "| policy_entropy     | 0.0965129     |\n",
      "| policy_loss        | -0.0011048992 |\n",
      "| serial_timesteps   | 7424          |\n",
      "| time_elapsed       | 95.1          |\n",
      "| total_timesteps    | 7424          |\n",
      "| value_loss         | 0.07955003    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00070891477 |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| explained_variance | 0.365         |\n",
      "| fps                | 74            |\n",
      "| n_updates          | 59            |\n",
      "| policy_entropy     | 0.10178584    |\n",
      "| policy_loss        | -0.0049839197 |\n",
      "| serial_timesteps   | 7552          |\n",
      "| time_elapsed       | 96.8          |\n",
      "| total_timesteps    | 7552          |\n",
      "| value_loss         | 0.09179879    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.2743148e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.361         |\n",
      "| fps                | 70            |\n",
      "| n_updates          | 60            |\n",
      "| policy_entropy     | 0.08552111    |\n",
      "| policy_loss        | 0.0004647037  |\n",
      "| serial_timesteps   | 7680          |\n",
      "| time_elapsed       | 98.5          |\n",
      "| total_timesteps    | 7680          |\n",
      "| value_loss         | 0.08355879    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 4.055905e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.458         |\n",
      "| fps                | 83            |\n",
      "| n_updates          | 61            |\n",
      "| policy_entropy     | 0.06543382    |\n",
      "| policy_loss        | -0.0017138233 |\n",
      "| serial_timesteps   | 7808          |\n",
      "| time_elapsed       | 100           |\n",
      "| total_timesteps    | 7808          |\n",
      "| value_loss         | 0.063732736   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 7.907526e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.363        |\n",
      "| fps                | 102          |\n",
      "| n_updates          | 62           |\n",
      "| policy_entropy     | 0.078900576  |\n",
      "| policy_loss        | 0.0023977545 |\n",
      "| serial_timesteps   | 7936         |\n",
      "| time_elapsed       | 102          |\n",
      "| total_timesteps    | 7936         |\n",
      "| value_loss         | 0.08334798   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.0085777e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.435         |\n",
      "| fps                | 87            |\n",
      "| n_updates          | 63            |\n",
      "| policy_entropy     | 0.095583595   |\n",
      "| policy_loss        | 0.00016207737 |\n",
      "| serial_timesteps   | 8064          |\n",
      "| time_elapsed       | 103           |\n",
      "| total_timesteps    | 8064          |\n",
      "| value_loss         | 0.10327236    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00014420618 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.51          |\n",
      "| fps                | 86            |\n",
      "| n_updates          | 64            |\n",
      "| policy_entropy     | 0.10896791    |\n",
      "| policy_loss        | -0.003202822  |\n",
      "| serial_timesteps   | 8192          |\n",
      "| time_elapsed       | 105           |\n",
      "| total_timesteps    | 8192          |\n",
      "| value_loss         | 0.110993795   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.000416111   |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| explained_variance | 0.374         |\n",
      "| fps                | 68            |\n",
      "| n_updates          | 65            |\n",
      "| policy_entropy     | 0.11070327    |\n",
      "| policy_loss        | -0.0007851869 |\n",
      "| serial_timesteps   | 8320          |\n",
      "| time_elapsed       | 106           |\n",
      "| total_timesteps    | 8320          |\n",
      "| value_loss         | 0.09998897    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.932283e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.573         |\n",
      "| fps                | 70            |\n",
      "| n_updates          | 66            |\n",
      "| policy_entropy     | 0.10068675    |\n",
      "| policy_loss        | -0.0009791232 |\n",
      "| serial_timesteps   | 8448          |\n",
      "| time_elapsed       | 108           |\n",
      "| total_timesteps    | 8448          |\n",
      "| value_loss         | 0.08375951    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.5990096e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.599          |\n",
      "| fps                | 77             |\n",
      "| n_updates          | 67             |\n",
      "| policy_entropy     | 0.08886867     |\n",
      "| policy_loss        | -0.00016006059 |\n",
      "| serial_timesteps   | 8576           |\n",
      "| time_elapsed       | 110            |\n",
      "| total_timesteps    | 8576           |\n",
      "| value_loss         | 0.072422534    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00028660338 |\n",
      "| clipfrac           | 0.005859375   |\n",
      "| explained_variance | -0.131        |\n",
      "| fps                | 81            |\n",
      "| n_updates          | 68            |\n",
      "| policy_entropy     | 0.05769041    |\n",
      "| policy_loss        | -0.008337624  |\n",
      "| serial_timesteps   | 8704          |\n",
      "| time_elapsed       | 111           |\n",
      "| total_timesteps    | 8704          |\n",
      "| value_loss         | 0.05284904    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3763061e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.147         |\n",
      "| fps                | 73            |\n",
      "| n_updates          | 69            |\n",
      "| policy_entropy     | 0.07937067    |\n",
      "| policy_loss        | 0.00077523116 |\n",
      "| serial_timesteps   | 8832          |\n",
      "| time_elapsed       | 113           |\n",
      "| total_timesteps    | 8832          |\n",
      "| value_loss         | 0.06097571    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.9032464e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.524          |\n",
      "| fps                | 73             |\n",
      "| n_updates          | 70             |\n",
      "| policy_entropy     | 0.09691095     |\n",
      "| policy_loss        | -3.3846009e-06 |\n",
      "| serial_timesteps   | 8960           |\n",
      "| time_elapsed       | 115            |\n",
      "| total_timesteps    | 8960           |\n",
      "| value_loss         | 0.07628048     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00019588592 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.386         |\n",
      "| fps                | 71            |\n",
      "| n_updates          | 71            |\n",
      "| policy_entropy     | 0.12746625    |\n",
      "| policy_loss        | -0.002372413  |\n",
      "| serial_timesteps   | 9088          |\n",
      "| time_elapsed       | 116           |\n",
      "| total_timesteps    | 9088          |\n",
      "| value_loss         | 0.10540139    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.6267475e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.502         |\n",
      "| fps                | 76            |\n",
      "| n_updates          | 72            |\n",
      "| policy_entropy     | 0.098793104   |\n",
      "| policy_loss        | -0.0030344205 |\n",
      "| serial_timesteps   | 9216          |\n",
      "| time_elapsed       | 118           |\n",
      "| total_timesteps    | 9216          |\n",
      "| value_loss         | 0.097997494   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.7751946e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.471         |\n",
      "| fps                | 73            |\n",
      "| n_updates          | 73            |\n",
      "| policy_entropy     | 0.11200641    |\n",
      "| policy_loss        | 0.0020733844  |\n",
      "| serial_timesteps   | 9344          |\n",
      "| time_elapsed       | 120           |\n",
      "| total_timesteps    | 9344          |\n",
      "| value_loss         | 0.09008233    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.004616e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00871       |\n",
      "| fps                | 74            |\n",
      "| n_updates          | 74            |\n",
      "| policy_entropy     | 0.120665975   |\n",
      "| policy_loss        | -0.0019159755 |\n",
      "| serial_timesteps   | 9472          |\n",
      "| time_elapsed       | 122           |\n",
      "| total_timesteps    | 9472          |\n",
      "| value_loss         | 0.11479677    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00040669268 |\n",
      "| clipfrac           | 0.005859375   |\n",
      "| explained_variance | 0.574         |\n",
      "| fps                | 72            |\n",
      "| n_updates          | 75            |\n",
      "| policy_entropy     | 0.115262404   |\n",
      "| policy_loss        | -0.008767853  |\n",
      "| serial_timesteps   | 9600          |\n",
      "| time_elapsed       | 123           |\n",
      "| total_timesteps    | 9600          |\n",
      "| value_loss         | 0.09943605    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0018712068 |\n",
      "| clipfrac           | 0.025390625  |\n",
      "| explained_variance | 0.422        |\n",
      "| fps                | 72           |\n",
      "| n_updates          | 76           |\n",
      "| policy_entropy     | 0.14712605   |\n",
      "| policy_loss        | -0.011505418 |\n",
      "| serial_timesteps   | 9728         |\n",
      "| time_elapsed       | 125          |\n",
      "| total_timesteps    | 9728         |\n",
      "| value_loss         | 0.106853485  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00019095652 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.547         |\n",
      "| fps                | 74            |\n",
      "| n_updates          | 77            |\n",
      "| policy_entropy     | 0.14567348    |\n",
      "| policy_loss        | 0.0007097635  |\n",
      "| serial_timesteps   | 9856          |\n",
      "| time_elapsed       | 127           |\n",
      "| total_timesteps    | 9856          |\n",
      "| value_loss         | 0.09880745    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.00025656977 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.421         |\n",
      "| fps                | 72            |\n",
      "| n_updates          | 78            |\n",
      "| policy_entropy     | 0.107708685   |\n",
      "| policy_loss        | -0.002398899  |\n",
      "| serial_timesteps   | 9984          |\n",
      "| time_elapsed       | 129           |\n",
      "| total_timesteps    | 9984          |\n",
      "| value_loss         | 0.07646519    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7eff453f4b10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = DummyVecEnv([lambda: env])\n",
    "PPO2model = PPO2(MlpPolicy, env, verbose=1)\n",
    "PPO2model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save our model to be able to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO2model.save('PPO2-qiscoin-v0-10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a A2C agent\n",
    "For the sake of comparison, we also train a A2C agent.\n",
    "\n",
    "More information on the A2C agent: https://stable-baselines.readthedocs.io/en/v2.3.0/modules/a2c.html\n",
    "\n",
    "As before, we import the module for the *A2C* agent, we set up the agent, train it on 10000 games of **QisCoin** and save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:312: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:312: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:159: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "| explained_variance | -0.0335  |\n",
      "| fps                | 18       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.34     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.439   |\n",
      "| fps                | 83       |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1.08     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.068   |\n",
      "| fps                | 77       |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 0.692    |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.19     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.15     |\n",
      "| fps                | 76       |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 0.69     |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.24     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0651  |\n",
      "| fps                | 76       |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 0.684    |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 1.16     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.103   |\n",
      "| fps                | 76       |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 0.649    |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 1.28     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 75       |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 0.577    |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.356    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 75       |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 0.523    |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.27     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.448   |\n",
      "| fps                | 74       |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 0.362    |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.937    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 0.17     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 0.00395  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.039    |\n",
      "| fps                | 74       |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 0.0995   |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.753    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 0.0565   |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 1.04e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 0.0441   |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.00184  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 0.0185   |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 0.000975 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 0.0357   |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.29e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 0.0248   |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.00032  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 0.0277   |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.00131  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 0.0173   |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 0.000474 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 0.0211   |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.000145 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 0.0439   |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.318    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 73       |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 0.00857  |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 9.13e-05 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.a2c.a2c.A2C at 0x7eff442766d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2Cmodel = A2C(MlpPolicy, env, verbose=1)\n",
    "A2Cmodel.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2Cmodel.save('A2C-qiscoin-v0-10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the agents\n",
    "We now compare and evalute the agents. \n",
    "\n",
    "First of all, we import the module *evaluation.py* to run an evaluation functions on our agents. The module provides simple functions that run a number of iteration of the **QisCoin** game (default: 1000 games) and returns the average reward collected. The source of all these evaluation functions is available in *evaluation.py*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation as ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start running and evaluating the simple starting agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -0.0\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_random(gym.make('qiscoin-v0'), num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average reward is $0$. The result makes sense since the agent has $50\\%$ probability of guessing right at each iteration, and thus, in the long run, the positive reward for guessing right ($+1$) compensate the negative reward for guessing wrong ($-1$).\n",
    "\n",
    "Next we test a biased agent that constantly guesses $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.5\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_biased(gym.make('qiscoin-v0'), num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average reward of a biased agent always guessing 0 is much better than the random agent. This is due to the fact that 4 out of the 6 gates (*id, reset, t, tdg*) deterministically return 0, 1 of them (*x*) deterministically return 1, while the last one (*h*) may return 0 or 1 with the same probability. Given that the gates are selected with uniform probability, the biased agent is expect to be correct on $4.5 * \\frac{100}{6} = 75\\%$ of times, and be wrong on $1.5 * \\frac{100}{6} = 25\\%$ of times. Thus the expected reward can be estimated as:\n",
    "\\begin{equation}\n",
    "0.75 * 1 + 0.25 * -1 = 0.5.\n",
    "\\end{equation}\n",
    "\n",
    "Finally, we get to test the two agents we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.8\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_model(PPO2model, env, num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.8\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_model(A2Cmodel, env, num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both agents achieve an average reward of $0.8$. This result represents, in this scenario, an almost perfect performance. \n",
    "Remember that in the game there 5 gates ($id, reset, x, t, tdg$) that are deterministic, and 1 gate ($h$) which can produce any of the two outputs with equal probability. A perfect agent would then always guess correctly when presented with a deterministic gate, and guess right on average half of the time when presented with a Hadamard gate. In total a perfect agent should guess correctly $5.5 * \\frac{100}{6} \\approx 91.6 \\%$ of the times, and be wrong $5.5 * \\frac{100}{6} \\approx 8.3 \\%$ of the times. Given that all the gates are equally likely to be selected, we can compute the average reward as:\n",
    "\\begin{equation}\n",
    "0.916 * 1 + 0.083 * -1 \\approx 0.83.\n",
    "\\end{equation}\n",
    "The performance of the PPO2 and A2C agent is then very close to the theoretical best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple problem resembles more a *contextual n-armed bandit* or even a simpler *supervised learning* problem. It hardly constitute a challenge for the reinforcement learning algorithms that are able to achieve an almost perfect performance. In the next notebook we will consider a more complex instantiation of the game."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
