{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent Playing QisCoin v0\n",
    "\n",
    "In this notebook we load a simple version of **QisCoin** (*qiscoin-v0*) in which a quantum circuit with a single random gate is generated. We instantiate and run a random agent and few RL agents from the stable-baselines library and we observe their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "\n",
    "We start importing the main required libraries: OpenAI *gym* to run the game; *IPython.display* to print out our circuits.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing gym-qiscoin\n",
    "\n",
    "Next, we import the version of **QisCoin** wrapped into the *gym* interface. The code for this version of the game is available [here](https://github.uio.no/fabiomz/gym-qiscoin) and it can be installed as explained in the notebook [Setup](https://github.com/avalds/QisCoin/blob/master/1-%20Setup.ipynb).\n",
    "\n",
    "This version of **QisCoin** implements a game environment that inherits from the *OpenAI gym* **Env** class. It implements four main methods: *__init__()* for setting up the game; *step()* computing the result of a single time-step of evolution of the environment; *reset()* restarting the game; *render()* displaying the game.\n",
    "\n",
    "The **QisCoin** game has been modeled with a *discrete state space* (an integer number between 0 and 5 identifies which of the six possible gates has been randomly added on the circuit) and a *discrete action space* (the two integer numbers 0 and 1 corresponds to the possible guesses of the agent). Since the game is fully observed, the state space corresponds to the observation space. A positive reward (+1) is returned for guessing correctly, a negative reward (-1) is returned for guessing wrong.\n",
    "\n",
    "The code is available in the source file: https://github.uio.no/fabiomz/gym-qiscoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiscoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the game\n",
    "We create the game enviroment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('qiscoin-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we test the game running a single iteration of the game where the AI agent takes a random guess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 233.576x144.48 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is guessing that the outcome will be 1\n",
      "The guess is correct!\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "display(env.render())\n",
    "\n",
    "for _ in range(1):\n",
    "    guess = env.action_space.sample()\n",
    "    print(\"AI is guessing that the outcome will be {0}\".format(guess))\n",
    "    obs, reward, done, info = env.step(guess)\n",
    "    if(reward==1):\n",
    "        print(\"The guess is correct!\")\n",
    "    else:\n",
    "        print(\"The guess is wrong!\")\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Reinforcement Learning Agent\n",
    "\n",
    "Running a random agent playing **QisCoin** is not particularly interesting. We then turn to loading and running reinforcement learning agents that, starting from a random policy, would be able to learn to play **QisCoin** in a sensible way. To do so, we rely on the library of agents provided by stable-baselines.\n",
    "\n",
    "More information and examples on stable-baselines: https://github.com/hill-a/stable-baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a PPO2 Agent\n",
    "\n",
    "We consider instanting and training a PPO2 agent.\n",
    "\n",
    "More information on the PPO2 agent: https://stable-baselines.readthedocs.io/en/v2.3.0/modules/ppo2.html\n",
    "\n",
    "First of all we import the required modules: *DummyVecEnv* providing a wrapper for our environment as required by stable-baselines; *MlpPolicy* specifying a policy for our agent; *PPO2* implementing the actual agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then vectorize our environment (this is a formal step required for the agent to be able to play the game), we instantiate the PPO2 model, and we train it by playing 10000 games of **QisCoin**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/input.py:20: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/policies.py:562: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/distributions.py:323: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/distributions.py:324: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:193: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:201: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:209: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:243: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:245: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "-------------------------------------\n",
      "| approxkl           | 6.935479e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0725      |\n",
      "| fps                | 135          |\n",
      "| n_updates          | 1            |\n",
      "| policy_entropy     | 0.6930742    |\n",
      "| policy_loss        | -0.008390352 |\n",
      "| serial_timesteps   | 128          |\n",
      "| time_elapsed       | 2.62e-06     |\n",
      "| total_timesteps    | 128          |\n",
      "| value_loss         | 0.5348885    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00013550652 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.021        |\n",
      "| fps                | 154           |\n",
      "| n_updates          | 2             |\n",
      "| policy_entropy     | 0.6924768     |\n",
      "| policy_loss        | -0.012370881  |\n",
      "| serial_timesteps   | 256           |\n",
      "| time_elapsed       | 0.943         |\n",
      "| total_timesteps    | 256           |\n",
      "| value_loss         | 0.5074789     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00030443558 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00206      |\n",
      "| fps                | 190           |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 0.69023865    |\n",
      "| policy_loss        | -0.018125692  |\n",
      "| serial_timesteps   | 384           |\n",
      "| time_elapsed       | 1.77          |\n",
      "| total_timesteps    | 384           |\n",
      "| value_loss         | 0.4991789     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0006175514 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0123      |\n",
      "| fps                | 179          |\n",
      "| n_updates          | 4            |\n",
      "| policy_entropy     | 0.68481624   |\n",
      "| policy_loss        | -0.024471508 |\n",
      "| serial_timesteps   | 512          |\n",
      "| time_elapsed       | 2.45         |\n",
      "| total_timesteps    | 512          |\n",
      "| value_loss         | 0.5025073    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0012920577 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.00387     |\n",
      "| fps                | 194          |\n",
      "| n_updates          | 5            |\n",
      "| policy_entropy     | 0.67049396   |\n",
      "| policy_loss        | -0.036286894 |\n",
      "| serial_timesteps   | 640          |\n",
      "| time_elapsed       | 3.16         |\n",
      "| total_timesteps    | 640          |\n",
      "| value_loss         | 0.49552497   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.002212811 |\n",
      "| clipfrac           | 0.0         |\n",
      "| explained_variance | -0.0135     |\n",
      "| fps                | 153         |\n",
      "| n_updates          | 6           |\n",
      "| policy_entropy     | 0.6442038   |\n",
      "| policy_loss        | -0.04713081 |\n",
      "| serial_timesteps   | 768         |\n",
      "| time_elapsed       | 3.82        |\n",
      "| total_timesteps    | 768         |\n",
      "| value_loss         | 0.49037978  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.00234829   |\n",
      "| clipfrac           | 0.0078125    |\n",
      "| explained_variance | 0.00458      |\n",
      "| fps                | 176          |\n",
      "| n_updates          | 7            |\n",
      "| policy_entropy     | 0.60757023   |\n",
      "| policy_loss        | -0.044033695 |\n",
      "| serial_timesteps   | 896          |\n",
      "| time_elapsed       | 4.65         |\n",
      "| total_timesteps    | 896          |\n",
      "| value_loss         | 0.44932127   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.002583113 |\n",
      "| clipfrac           | 0.029296875 |\n",
      "| explained_variance | 0.00611     |\n",
      "| fps                | 158         |\n",
      "| n_updates          | 8           |\n",
      "| policy_entropy     | 0.5577553   |\n",
      "| policy_loss        | -0.04657011 |\n",
      "| serial_timesteps   | 1024        |\n",
      "| time_elapsed       | 5.38        |\n",
      "| total_timesteps    | 1024        |\n",
      "| value_loss         | 0.41345754  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0025935094 |\n",
      "| clipfrac           | 0.033203125  |\n",
      "| explained_variance | 0.0249       |\n",
      "| fps                | 179          |\n",
      "| n_updates          | 9            |\n",
      "| policy_entropy     | 0.48820812   |\n",
      "| policy_loss        | -0.044575028 |\n",
      "| serial_timesteps   | 1152         |\n",
      "| time_elapsed       | 6.19         |\n",
      "| total_timesteps    | 1152         |\n",
      "| value_loss         | 0.35340625   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.0019015888 |\n",
      "| clipfrac           | 0.029296875  |\n",
      "| explained_variance | 0.0747       |\n",
      "| fps                | 181          |\n",
      "| n_updates          | 10           |\n",
      "| policy_entropy     | 0.4334612    |\n",
      "| policy_loss        | -0.035162725 |\n",
      "| serial_timesteps   | 1280         |\n",
      "| time_elapsed       | 6.9          |\n",
      "| total_timesteps    | 1280         |\n",
      "| value_loss         | 0.30663377   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0023028697 |\n",
      "| clipfrac           | 0.037109375  |\n",
      "| explained_variance | 0.00321      |\n",
      "| fps                | 188          |\n",
      "| n_updates          | 11           |\n",
      "| policy_entropy     | 0.36602375   |\n",
      "| policy_loss        | -0.04176493  |\n",
      "| serial_timesteps   | 1408         |\n",
      "| time_elapsed       | 7.61         |\n",
      "| total_timesteps    | 1408         |\n",
      "| value_loss         | 0.3007572    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0009188501 |\n",
      "| clipfrac           | 0.01171875   |\n",
      "| explained_variance | 0.187        |\n",
      "| fps                | 197          |\n",
      "| n_updates          | 12           |\n",
      "| policy_entropy     | 0.3209325    |\n",
      "| policy_loss        | -0.018971942 |\n",
      "| serial_timesteps   | 1536         |\n",
      "| time_elapsed       | 8.29         |\n",
      "| total_timesteps    | 1536         |\n",
      "| value_loss         | 0.19713512   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0009790767 |\n",
      "| clipfrac           | 0.01171875   |\n",
      "| explained_variance | 0.258        |\n",
      "| fps                | 196          |\n",
      "| n_updates          | 13           |\n",
      "| policy_entropy     | 0.28931433   |\n",
      "| policy_loss        | -0.021429764 |\n",
      "| serial_timesteps   | 1664         |\n",
      "| time_elapsed       | 8.94         |\n",
      "| total_timesteps    | 1664         |\n",
      "| value_loss         | 0.167604     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0009971494 |\n",
      "| clipfrac           | 0.009765625  |\n",
      "| explained_variance | 0.255        |\n",
      "| fps                | 180          |\n",
      "| n_updates          | 14           |\n",
      "| policy_entropy     | 0.25002718   |\n",
      "| policy_loss        | -0.011864336 |\n",
      "| serial_timesteps   | 1792         |\n",
      "| time_elapsed       | 9.59         |\n",
      "| total_timesteps    | 1792         |\n",
      "| value_loss         | 0.17074358   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00065104634 |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| explained_variance | 0.334         |\n",
      "| fps                | 180           |\n",
      "| n_updates          | 15            |\n",
      "| policy_entropy     | 0.24170876    |\n",
      "| policy_loss        | -0.012849567  |\n",
      "| serial_timesteps   | 1920          |\n",
      "| time_elapsed       | 10.3          |\n",
      "| total_timesteps    | 1920          |\n",
      "| value_loss         | 0.15361561    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0009816384 |\n",
      "| clipfrac           | 0.009765625  |\n",
      "| explained_variance | 0.103        |\n",
      "| fps                | 183          |\n",
      "| n_updates          | 16           |\n",
      "| policy_entropy     | 0.19382572   |\n",
      "| policy_loss        | -0.0186774   |\n",
      "| serial_timesteps   | 2048         |\n",
      "| time_elapsed       | 11           |\n",
      "| total_timesteps    | 2048         |\n",
      "| value_loss         | 0.15145415   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00048443093 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | -0.0629       |\n",
      "| fps                | 177           |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 0.1910058     |\n",
      "| policy_loss        | -0.0049765343 |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 11.7          |\n",
      "| total_timesteps    | 2176          |\n",
      "| value_loss         | 0.107013434   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00068093557 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.324         |\n",
      "| fps                | 191           |\n",
      "| n_updates          | 18            |\n",
      "| policy_entropy     | 0.19232737    |\n",
      "| policy_loss        | -0.0129560605 |\n",
      "| serial_timesteps   | 2304          |\n",
      "| time_elapsed       | 12.4          |\n",
      "| total_timesteps    | 2304          |\n",
      "| value_loss         | 0.17078231    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0001393619  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.478         |\n",
      "| fps                | 195           |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 0.1570657     |\n",
      "| policy_loss        | 0.00038274832 |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 13.1          |\n",
      "| total_timesteps    | 2432          |\n",
      "| value_loss         | 0.090302356   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.3000182e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.474         |\n",
      "| fps                | 195           |\n",
      "| n_updates          | 20            |\n",
      "| policy_entropy     | 0.18332846    |\n",
      "| policy_loss        | -0.001653363  |\n",
      "| serial_timesteps   | 2560          |\n",
      "| time_elapsed       | 13.8          |\n",
      "| total_timesteps    | 2560          |\n",
      "| value_loss         | 0.11862289    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.1392275e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.469         |\n",
      "| fps                | 194           |\n",
      "| n_updates          | 21            |\n",
      "| policy_entropy     | 0.15996729    |\n",
      "| policy_loss        | -0.0012900839 |\n",
      "| serial_timesteps   | 2688          |\n",
      "| time_elapsed       | 14.4          |\n",
      "| total_timesteps    | 2688          |\n",
      "| value_loss         | 0.09082198    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.6715486e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.431         |\n",
      "| fps                | 191           |\n",
      "| n_updates          | 22            |\n",
      "| policy_entropy     | 0.14671707    |\n",
      "| policy_loss        | -0.0022843664 |\n",
      "| serial_timesteps   | 2816          |\n",
      "| time_elapsed       | 15.1          |\n",
      "| total_timesteps    | 2816          |\n",
      "| value_loss         | 0.11170296    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.8281955e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.423         |\n",
      "| fps                | 193           |\n",
      "| n_updates          | 23            |\n",
      "| policy_entropy     | 0.12922391    |\n",
      "| policy_loss        | 0.0016976377  |\n",
      "| serial_timesteps   | 2944          |\n",
      "| time_elapsed       | 15.7          |\n",
      "| total_timesteps    | 2944          |\n",
      "| value_loss         | 0.0678217     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0010384554 |\n",
      "| clipfrac           | 0.009765625  |\n",
      "| explained_variance | 0.051        |\n",
      "| fps                | 197          |\n",
      "| n_updates          | 24           |\n",
      "| policy_entropy     | 0.16980259   |\n",
      "| policy_loss        | -0.012647085 |\n",
      "| serial_timesteps   | 3072         |\n",
      "| time_elapsed       | 16.4         |\n",
      "| total_timesteps    | 3072         |\n",
      "| value_loss         | 0.12105103   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00016504     |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.336          |\n",
      "| fps                | 198            |\n",
      "| n_updates          | 25             |\n",
      "| policy_entropy     | 0.13754313     |\n",
      "| policy_loss        | -0.00067311036 |\n",
      "| serial_timesteps   | 3200           |\n",
      "| time_elapsed       | 17             |\n",
      "| total_timesteps    | 3200           |\n",
      "| value_loss         | 0.10488249     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00012512929 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.52          |\n",
      "| fps                | 199           |\n",
      "| n_updates          | 26            |\n",
      "| policy_entropy     | 0.16865408    |\n",
      "| policy_loss        | 0.0013917201  |\n",
      "| serial_timesteps   | 3328          |\n",
      "| time_elapsed       | 17.7          |\n",
      "| total_timesteps    | 3328          |\n",
      "| value_loss         | 0.1297903     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 3.742303e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.478         |\n",
      "| fps                | 183           |\n",
      "| n_updates          | 27            |\n",
      "| policy_entropy     | 0.14685893    |\n",
      "| policy_loss        | -7.811177e-05 |\n",
      "| serial_timesteps   | 3456          |\n",
      "| time_elapsed       | 18.3          |\n",
      "| total_timesteps    | 3456          |\n",
      "| value_loss         | 0.10202525    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.2415462e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.28          |\n",
      "| fps                | 193           |\n",
      "| n_updates          | 28            |\n",
      "| policy_entropy     | 0.1269525     |\n",
      "| policy_loss        | 0.00029859878 |\n",
      "| serial_timesteps   | 3584          |\n",
      "| time_elapsed       | 19            |\n",
      "| total_timesteps    | 3584          |\n",
      "| value_loss         | 0.08397887    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0002881654  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.399         |\n",
      "| fps                | 195           |\n",
      "| n_updates          | 29            |\n",
      "| policy_entropy     | 0.15945753    |\n",
      "| policy_loss        | -0.0028005277 |\n",
      "| serial_timesteps   | 3712          |\n",
      "| time_elapsed       | 19.7          |\n",
      "| total_timesteps    | 3712          |\n",
      "| value_loss         | 0.11711841    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.8679426e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.424          |\n",
      "| fps                | 136            |\n",
      "| n_updates          | 30             |\n",
      "| policy_entropy     | 0.14476362     |\n",
      "| policy_loss        | -0.00089263637 |\n",
      "| serial_timesteps   | 3840           |\n",
      "| time_elapsed       | 20.3           |\n",
      "| total_timesteps    | 3840           |\n",
      "| value_loss         | 0.12683257     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.139288e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.381         |\n",
      "| fps                | 172           |\n",
      "| n_updates          | 31            |\n",
      "| policy_entropy     | 0.12702218    |\n",
      "| policy_loss        | -0.0021862907 |\n",
      "| serial_timesteps   | 3968          |\n",
      "| time_elapsed       | 21.3          |\n",
      "| total_timesteps    | 3968          |\n",
      "| value_loss         | 0.105386265   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003416599  |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.349         |\n",
      "| fps                | 187           |\n",
      "| n_updates          | 32            |\n",
      "| policy_entropy     | 0.16642892    |\n",
      "| policy_loss        | -0.0073113455 |\n",
      "| serial_timesteps   | 4096          |\n",
      "| time_elapsed       | 22            |\n",
      "| total_timesteps    | 4096          |\n",
      "| value_loss         | 0.17178066    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00037265627 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.495         |\n",
      "| fps                | 182           |\n",
      "| n_updates          | 33            |\n",
      "| policy_entropy     | 0.09989824    |\n",
      "| policy_loss        | -0.0053473576 |\n",
      "| serial_timesteps   | 4224          |\n",
      "| time_elapsed       | 22.7          |\n",
      "| total_timesteps    | 4224          |\n",
      "| value_loss         | 0.103816435   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.7177874e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.463          |\n",
      "| fps                | 184            |\n",
      "| n_updates          | 34             |\n",
      "| policy_entropy     | 0.1007364      |\n",
      "| policy_loss        | -0.00026451307 |\n",
      "| serial_timesteps   | 4352           |\n",
      "| time_elapsed       | 23.4           |\n",
      "| total_timesteps    | 4352           |\n",
      "| value_loss         | 0.09865384     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.3131273e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.238         |\n",
      "| fps                | 181           |\n",
      "| n_updates          | 35            |\n",
      "| policy_entropy     | 0.099768706   |\n",
      "| policy_loss        | 0.000472127   |\n",
      "| serial_timesteps   | 4480          |\n",
      "| time_elapsed       | 24.1          |\n",
      "| total_timesteps    | 4480          |\n",
      "| value_loss         | 0.10865533    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.2446993e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.457         |\n",
      "| fps                | 138           |\n",
      "| n_updates          | 36            |\n",
      "| policy_entropy     | 0.10872491    |\n",
      "| policy_loss        | 0.0009416537  |\n",
      "| serial_timesteps   | 4608          |\n",
      "| time_elapsed       | 24.8          |\n",
      "| total_timesteps    | 4608          |\n",
      "| value_loss         | 0.10637942    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.000594968  |\n",
      "| clipfrac           | 0.015625     |\n",
      "| explained_variance | 0.545        |\n",
      "| fps                | 187          |\n",
      "| n_updates          | 37           |\n",
      "| policy_entropy     | 0.096073784  |\n",
      "| policy_loss        | -0.003819995 |\n",
      "| serial_timesteps   | 4736         |\n",
      "| time_elapsed       | 25.7         |\n",
      "| total_timesteps    | 4736         |\n",
      "| value_loss         | 0.08183929   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.2940676e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.571         |\n",
      "| fps                | 193           |\n",
      "| n_updates          | 38            |\n",
      "| policy_entropy     | 0.1257256     |\n",
      "| policy_loss        | -0.0016527956 |\n",
      "| serial_timesteps   | 4864          |\n",
      "| time_elapsed       | 26.4          |\n",
      "| total_timesteps    | 4864          |\n",
      "| value_loss         | 0.11007835    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00010108587 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.39          |\n",
      "| fps                | 178           |\n",
      "| n_updates          | 39            |\n",
      "| policy_entropy     | 0.07965561    |\n",
      "| policy_loss        | 0.00010567065 |\n",
      "| serial_timesteps   | 4992          |\n",
      "| time_elapsed       | 27.1          |\n",
      "| total_timesteps    | 4992          |\n",
      "| value_loss         | 0.07457813    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00016172609 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.488         |\n",
      "| fps                | 149           |\n",
      "| n_updates          | 40            |\n",
      "| policy_entropy     | 0.073162645   |\n",
      "| policy_loss        | -0.0045451326 |\n",
      "| serial_timesteps   | 5120          |\n",
      "| time_elapsed       | 27.8          |\n",
      "| total_timesteps    | 5120          |\n",
      "| value_loss         | 0.08049284    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00015679623 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.403         |\n",
      "| fps                | 182           |\n",
      "| n_updates          | 41            |\n",
      "| policy_entropy     | 0.08725195    |\n",
      "| policy_loss        | -0.0034246186 |\n",
      "| serial_timesteps   | 5248          |\n",
      "| time_elapsed       | 28.7          |\n",
      "| total_timesteps    | 5248          |\n",
      "| value_loss         | 0.10109789    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00019767458 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.627         |\n",
      "| fps                | 177           |\n",
      "| n_updates          | 42            |\n",
      "| policy_entropy     | 0.06021136    |\n",
      "| policy_loss        | -0.002527228  |\n",
      "| serial_timesteps   | 5376          |\n",
      "| time_elapsed       | 29.4          |\n",
      "| total_timesteps    | 5376          |\n",
      "| value_loss         | 0.07368994    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00020521092 |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| explained_variance | 0.611         |\n",
      "| fps                | 194           |\n",
      "| n_updates          | 43            |\n",
      "| policy_entropy     | 0.061023485   |\n",
      "| policy_loss        | -0.0024401576 |\n",
      "| serial_timesteps   | 5504          |\n",
      "| time_elapsed       | 30.1          |\n",
      "| total_timesteps    | 5504          |\n",
      "| value_loss         | 0.08743587    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 3.4316952e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.354         |\n",
      "| fps                | 176           |\n",
      "| n_updates          | 44            |\n",
      "| policy_entropy     | 0.027325513   |\n",
      "| policy_loss        | -0.0024129478 |\n",
      "| serial_timesteps   | 5632          |\n",
      "| time_elapsed       | 30.7          |\n",
      "| total_timesteps    | 5632          |\n",
      "| value_loss         | 0.058310937   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.795249e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.424         |\n",
      "| fps                | 186           |\n",
      "| n_updates          | 45            |\n",
      "| policy_entropy     | 0.03447568    |\n",
      "| policy_loss        | -0.0014892403 |\n",
      "| serial_timesteps   | 5760          |\n",
      "| time_elapsed       | 31.5          |\n",
      "| total_timesteps    | 5760          |\n",
      "| value_loss         | 0.06682341    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.0398995e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.425         |\n",
      "| fps                | 151           |\n",
      "| n_updates          | 46            |\n",
      "| policy_entropy     | 0.044212792   |\n",
      "| policy_loss        | 0.00072651333 |\n",
      "| serial_timesteps   | 5888          |\n",
      "| time_elapsed       | 32.2          |\n",
      "| total_timesteps    | 5888          |\n",
      "| value_loss         | 0.10339881    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.4882465e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.54          |\n",
      "| fps                | 187           |\n",
      "| n_updates          | 47            |\n",
      "| policy_entropy     | 0.04450368    |\n",
      "| policy_loss        | 4.826355e-05  |\n",
      "| serial_timesteps   | 6016          |\n",
      "| time_elapsed       | 33            |\n",
      "| total_timesteps    | 6016          |\n",
      "| value_loss         | 0.09633354    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.544969e-09  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.46          |\n",
      "| fps                | 189           |\n",
      "| n_updates          | 48            |\n",
      "| policy_entropy     | 0.035597745   |\n",
      "| policy_loss        | 8.7125227e-07 |\n",
      "| serial_timesteps   | 6144          |\n",
      "| time_elapsed       | 33.7          |\n",
      "| total_timesteps    | 6144          |\n",
      "| value_loss         | 0.07094813    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 6.714574e-06 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.298        |\n",
      "| fps                | 176          |\n",
      "| n_updates          | 49           |\n",
      "| policy_entropy     | 0.04311451   |\n",
      "| policy_loss        | -0.000314235 |\n",
      "| serial_timesteps   | 6272         |\n",
      "| time_elapsed       | 34.4         |\n",
      "| total_timesteps    | 6272         |\n",
      "| value_loss         | 0.09061687   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.2470374e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.457         |\n",
      "| fps                | 144           |\n",
      "| n_updates          | 50            |\n",
      "| policy_entropy     | 0.041919615   |\n",
      "| policy_loss        | 7.832114e-05  |\n",
      "| serial_timesteps   | 6400          |\n",
      "| time_elapsed       | 35.1          |\n",
      "| total_timesteps    | 6400          |\n",
      "| value_loss         | 0.07889373    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00039728265 |\n",
      "| clipfrac           | 0.009765625   |\n",
      "| explained_variance | 0.367         |\n",
      "| fps                | 104           |\n",
      "| n_updates          | 51            |\n",
      "| policy_entropy     | 0.05835075    |\n",
      "| policy_loss        | -0.0058209565 |\n",
      "| serial_timesteps   | 6528          |\n",
      "| time_elapsed       | 36            |\n",
      "| total_timesteps    | 6528          |\n",
      "| value_loss         | 0.099616796   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.4014882e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.355         |\n",
      "| fps                | 126           |\n",
      "| n_updates          | 52            |\n",
      "| policy_entropy     | 0.05344563    |\n",
      "| policy_loss        | 0.0004540239  |\n",
      "| serial_timesteps   | 6656          |\n",
      "| time_elapsed       | 37.2          |\n",
      "| total_timesteps    | 6656          |\n",
      "| value_loss         | 0.07544631    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.290458e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.368         |\n",
      "| fps                | 139           |\n",
      "| n_updates          | 53            |\n",
      "| policy_entropy     | 0.037716407   |\n",
      "| policy_loss        | -0.0040572304 |\n",
      "| serial_timesteps   | 6784          |\n",
      "| time_elapsed       | 38.2          |\n",
      "| total_timesteps    | 6784          |\n",
      "| value_loss         | 0.07443055    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00018403555 |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| explained_variance | 0.452         |\n",
      "| fps                | 113           |\n",
      "| n_updates          | 54            |\n",
      "| policy_entropy     | 0.05474763    |\n",
      "| policy_loss        | -0.0044541047 |\n",
      "| serial_timesteps   | 6912          |\n",
      "| time_elapsed       | 39.1          |\n",
      "| total_timesteps    | 6912          |\n",
      "| value_loss         | 0.12564164    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.7905e-05    |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.335         |\n",
      "| fps                | 125           |\n",
      "| n_updates          | 55            |\n",
      "| policy_entropy     | 0.04772889    |\n",
      "| policy_loss        | -0.0028096652 |\n",
      "| serial_timesteps   | 7040          |\n",
      "| time_elapsed       | 40.2          |\n",
      "| total_timesteps    | 7040          |\n",
      "| value_loss         | 0.11430832    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.750833e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.4           |\n",
      "| fps                | 140           |\n",
      "| n_updates          | 56            |\n",
      "| policy_entropy     | 0.058625456   |\n",
      "| policy_loss        | 0.00013472594 |\n",
      "| serial_timesteps   | 7168          |\n",
      "| time_elapsed       | 41.3          |\n",
      "| total_timesteps    | 7168          |\n",
      "| value_loss         | 0.10947215    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 7.917547e-05 |\n",
      "| clipfrac           | 0.001953125  |\n",
      "| explained_variance | 0.267        |\n",
      "| fps                | 153          |\n",
      "| n_updates          | 57           |\n",
      "| policy_entropy     | 0.047085334  |\n",
      "| policy_loss        | -0.001963888 |\n",
      "| serial_timesteps   | 7296         |\n",
      "| time_elapsed       | 42.2         |\n",
      "| total_timesteps    | 7296         |\n",
      "| value_loss         | 0.07483544   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.5820505e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.479         |\n",
      "| fps                | 120           |\n",
      "| n_updates          | 58            |\n",
      "| policy_entropy     | 0.056614332   |\n",
      "| policy_loss        | 0.00045632542 |\n",
      "| serial_timesteps   | 7424          |\n",
      "| time_elapsed       | 43            |\n",
      "| total_timesteps    | 7424          |\n",
      "| value_loss         | 0.089374416   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00023371614 |\n",
      "| clipfrac           | 0.005859375   |\n",
      "| explained_variance | 0.472         |\n",
      "| fps                | 144           |\n",
      "| n_updates          | 59            |\n",
      "| policy_entropy     | 0.07508273    |\n",
      "| policy_loss        | -0.0032197798 |\n",
      "| serial_timesteps   | 7552          |\n",
      "| time_elapsed       | 44.1          |\n",
      "| total_timesteps    | 7552          |\n",
      "| value_loss         | 0.1142946     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.671322e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.479         |\n",
      "| fps                | 145           |\n",
      "| n_updates          | 60            |\n",
      "| policy_entropy     | 0.061407063   |\n",
      "| policy_loss        | 0.00022286549 |\n",
      "| serial_timesteps   | 7680          |\n",
      "| time_elapsed       | 45            |\n",
      "| total_timesteps    | 7680          |\n",
      "| value_loss         | 0.08193303    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 6.668204e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.539         |\n",
      "| fps                | 141           |\n",
      "| n_updates          | 61            |\n",
      "| policy_entropy     | 0.03957184    |\n",
      "| policy_loss        | -0.0017030494 |\n",
      "| serial_timesteps   | 7808          |\n",
      "| time_elapsed       | 45.8          |\n",
      "| total_timesteps    | 7808          |\n",
      "| value_loss         | 0.0539545     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.452124e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.421         |\n",
      "| fps                | 165           |\n",
      "| n_updates          | 62            |\n",
      "| policy_entropy     | 0.05058552    |\n",
      "| policy_loss        | -0.0025506634 |\n",
      "| serial_timesteps   | 7936          |\n",
      "| time_elapsed       | 46.8          |\n",
      "| total_timesteps    | 7936          |\n",
      "| value_loss         | 0.09105356    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 7.959067e-06 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.397        |\n",
      "| fps                | 165          |\n",
      "| n_updates          | 63           |\n",
      "| policy_entropy     | 0.042441893  |\n",
      "| policy_loss        | 0.0007321951 |\n",
      "| serial_timesteps   | 8064         |\n",
      "| time_elapsed       | 47.5         |\n",
      "| total_timesteps    | 8064         |\n",
      "| value_loss         | 0.08639654   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.2012526e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.117         |\n",
      "| fps                | 170           |\n",
      "| n_updates          | 64            |\n",
      "| policy_entropy     | 0.059804007   |\n",
      "| policy_loss        | 0.00014522905 |\n",
      "| serial_timesteps   | 8192          |\n",
      "| time_elapsed       | 48.3          |\n",
      "| total_timesteps    | 8192          |\n",
      "| value_loss         | 0.1117791     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.0582862e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.436         |\n",
      "| fps                | 176           |\n",
      "| n_updates          | 65            |\n",
      "| policy_entropy     | 0.03866609    |\n",
      "| policy_loss        | 9.205029e-05  |\n",
      "| serial_timesteps   | 8320          |\n",
      "| time_elapsed       | 49.1          |\n",
      "| total_timesteps    | 8320          |\n",
      "| value_loss         | 0.0831502     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.992203e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.412          |\n",
      "| fps                | 175            |\n",
      "| n_updates          | 66             |\n",
      "| policy_entropy     | 0.042255152    |\n",
      "| policy_loss        | -0.00058397005 |\n",
      "| serial_timesteps   | 8448           |\n",
      "| time_elapsed       | 49.8           |\n",
      "| total_timesteps    | 8448           |\n",
      "| value_loss         | 0.09115067     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.9563136e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.515         |\n",
      "| fps                | 176           |\n",
      "| n_updates          | 67            |\n",
      "| policy_entropy     | 0.041738562   |\n",
      "| policy_loss        | -0.0010977763 |\n",
      "| serial_timesteps   | 8576          |\n",
      "| time_elapsed       | 50.5          |\n",
      "| total_timesteps    | 8576          |\n",
      "| value_loss         | 0.10290796    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 8.991611e-08 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.638        |\n",
      "| fps                | 174          |\n",
      "| n_updates          | 68           |\n",
      "| policy_entropy     | 0.033272717  |\n",
      "| policy_loss        | 0.0001412353 |\n",
      "| serial_timesteps   | 8704         |\n",
      "| time_elapsed       | 51.2         |\n",
      "| total_timesteps    | 8704         |\n",
      "| value_loss         | 0.07486324   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.3944433e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.317         |\n",
      "| fps                | 181           |\n",
      "| n_updates          | 69            |\n",
      "| policy_entropy     | 0.040368978   |\n",
      "| policy_loss        | -0.0010114239 |\n",
      "| serial_timesteps   | 8832          |\n",
      "| time_elapsed       | 52            |\n",
      "| total_timesteps    | 8832          |\n",
      "| value_loss         | 0.12560523    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00044734933 |\n",
      "| clipfrac           | 0.005859375   |\n",
      "| explained_variance | 0.448         |\n",
      "| fps                | 185           |\n",
      "| n_updates          | 70            |\n",
      "| policy_entropy     | 0.023070673   |\n",
      "| policy_loss        | -0.004575087  |\n",
      "| serial_timesteps   | 8960          |\n",
      "| time_elapsed       | 52.7          |\n",
      "| total_timesteps    | 8960          |\n",
      "| value_loss         | 0.07869964    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.3915229e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.561         |\n",
      "| fps                | 179           |\n",
      "| n_updates          | 71            |\n",
      "| policy_entropy     | 0.02046395    |\n",
      "| policy_loss        | 0.00015645452 |\n",
      "| serial_timesteps   | 9088          |\n",
      "| time_elapsed       | 53.4          |\n",
      "| total_timesteps    | 9088          |\n",
      "| value_loss         | 0.08553532    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.511502e-09   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.273          |\n",
      "| fps                | 181            |\n",
      "| n_updates          | 72             |\n",
      "| policy_entropy     | 0.018020328    |\n",
      "| policy_loss        | -2.1536485e-05 |\n",
      "| serial_timesteps   | 9216           |\n",
      "| time_elapsed       | 54.1           |\n",
      "| total_timesteps    | 9216           |\n",
      "| value_loss         | 0.077116564    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.1273866e-10 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.593         |\n",
      "| fps                | 181           |\n",
      "| n_updates          | 73            |\n",
      "| policy_entropy     | 0.019129679   |\n",
      "| policy_loss        | 1.055887e-06  |\n",
      "| serial_timesteps   | 9344          |\n",
      "| time_elapsed       | 54.8          |\n",
      "| total_timesteps    | 9344          |\n",
      "| value_loss         | 0.081298634   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.21085e-10    |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.192          |\n",
      "| fps                | 185            |\n",
      "| n_updates          | 74             |\n",
      "| policy_entropy     | 0.015116239    |\n",
      "| policy_loss        | -2.1401793e-06 |\n",
      "| serial_timesteps   | 9472           |\n",
      "| time_elapsed       | 55.5           |\n",
      "| total_timesteps    | 9472           |\n",
      "| value_loss         | 0.06228566     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.1930727e-10 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.561         |\n",
      "| fps                | 189           |\n",
      "| n_updates          | 75            |\n",
      "| policy_entropy     | 0.017056689   |\n",
      "| policy_loss        | 3.676978e-06  |\n",
      "| serial_timesteps   | 9600          |\n",
      "| time_elapsed       | 56.2          |\n",
      "| total_timesteps    | 9600          |\n",
      "| value_loss         | 0.07000032    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.134559e-05  |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.466         |\n",
      "| fps                | 187           |\n",
      "| n_updates          | 76            |\n",
      "| policy_entropy     | 0.016156813   |\n",
      "| policy_loss        | -0.0018684964 |\n",
      "| serial_timesteps   | 9728          |\n",
      "| time_elapsed       | 56.9          |\n",
      "| total_timesteps    | 9728          |\n",
      "| value_loss         | 0.06275324    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.4610536e-05 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.37          |\n",
      "| fps                | 188           |\n",
      "| n_updates          | 77            |\n",
      "| policy_entropy     | 0.027580822   |\n",
      "| policy_loss        | -0.0016363205 |\n",
      "| serial_timesteps   | 9856          |\n",
      "| time_elapsed       | 57.5          |\n",
      "| total_timesteps    | 9856          |\n",
      "| value_loss         | 0.098917745   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 6.313466e-05  |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | -0.0731       |\n",
      "| fps                | 186           |\n",
      "| n_updates          | 78            |\n",
      "| policy_entropy     | 0.023529831   |\n",
      "| policy_loss        | -0.0021195642 |\n",
      "| serial_timesteps   | 9984          |\n",
      "| time_elapsed       | 58.2          |\n",
      "| total_timesteps    | 9984          |\n",
      "| value_loss         | 0.061529253   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7f3c03551650>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = DummyVecEnv([lambda: env])\n",
    "PPO2model = PPO2(MlpPolicy, env, verbose=1)\n",
    "PPO2model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save our model to be able to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO2model.save('models/PPO2-qiscoin-v0-10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a A2C agent\n",
    "For the sake of comparison, we also train a A2C agent.\n",
    "\n",
    "More information on the A2C agent: https://stable-baselines.readthedocs.io/en/v2.3.0/modules/a2c.html\n",
    "\n",
    "As before, we import the module for the *A2C* agent, we set up the agent, train it on 10000 games of **QisCoin** and save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:312: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:312: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:159: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "| explained_variance | -0.0413  |\n",
      "| fps                | 25       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.05     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.047    |\n",
      "| fps                | 147      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 1        |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0498  |\n",
      "| fps                | 155      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 0.692    |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.08     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.163    |\n",
      "| fps                | 156      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 0.687    |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.833    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.0751   |\n",
      "| fps                | 159      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 0.681    |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.903    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.11     |\n",
      "| fps                | 163      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 0.648    |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.802    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.0525   |\n",
      "| fps                | 165      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 0.599    |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.709    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.000246 |\n",
      "| fps                | 167      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 0.397    |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 1.16     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.709    |\n",
      "| fps                | 169      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 0.318    |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.212    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.599    |\n",
      "| fps                | 167      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 0.219    |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 0.334    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.319   |\n",
      "| fps                | 166      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 0.257    |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.894    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.708    |\n",
      "| fps                | 166      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 0.166    |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 0.225    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.718    |\n",
      "| fps                | 167      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 0.204    |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.234    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 167      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 0.123    |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 0.201    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 168      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 0.101    |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.212    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 169      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 0.162    |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.164    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 169      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 0.147    |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.285    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 169      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 0.0279   |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 5.22e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 168      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 0.0262   |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.000321 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 168      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 0.019    |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.000391 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 167      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 0.138    |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.272    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.a2c.a2c.A2C at 0x7f3c003ea450>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2Cmodel = A2C(MlpPolicy, env, verbose=1)\n",
    "A2Cmodel.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2Cmodel.save('models/A2C-qiscoin-v0-10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the agents\n",
    "We now compare and evalute the agents. \n",
    "\n",
    "First of all, we import the module *evaluation.py* to run an evaluation functions on our agents. The module provides simple functions that run a number of iteration of the **QisCoin** game (default: 1000 games) and returns the average reward collected. The source of all these evaluation functions is available in *evaluation.py*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation as ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start running and evaluating the simple starting agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: -0.0\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_random(gym.make('qiscoin-v0'), num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average reward is $0$. The result makes sense since the agent has $50\\%$ probability of guessing right at each iteration, and thus, in the long run, the positive reward for guessing right ($+1$) compensate the negative reward for guessing wrong ($-1$).\n",
    "\n",
    "Next we test a biased agent that constantly guesses $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.5\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_biased(gym.make('qiscoin-v0'), num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average reward of a biased agent always guessing 0 is much better than the random agent. This is due to the fact that 4 out of the 6 gates (*id, reset, t, tdg*) deterministically return 0, 1 of them (*x*) deterministically return 1, while the last one (*h*) may return 0 or 1 with the same probability. Given that the gates are selected with uniform probability, the biased agent is expect to be correct on $4.5 * \\frac{100}{6} = 75\\%$ of times, and be wrong on $1.5 * \\frac{100}{6} = 25\\%$ of times. Thus the expected reward can be estimated as:\n",
    "\\begin{equation}\n",
    "0.75 * 1 + 0.25 * -1 = 0.5.\n",
    "\\end{equation}\n",
    "\n",
    "Finally, we get to test the two agents we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.8\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_model(PPO2model, env, num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.8\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_model(A2Cmodel, env, num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both agents achieve an average reward of $0.8$. This result represents, in this scenario, an almost perfect performance. \n",
    "Remember that in the game there 5 gates ($id, reset, x, t, tdg$) that are deterministic, and 1 gate ($h$) which can produce any of the two outputs with equal probability. A perfect agent would then always guess correctly when presented with a deterministic gate, and guess right on average half of the time when presented with a Hadamard gate. In total a perfect agent should guess correctly $5.5 * \\frac{100}{6} \\approx 91.6 \\%$ of the times, and be wrong $5.5 * \\frac{100}{6} \\approx 8.3 \\%$ of the times. Given that all the gates are equally likely to be selected, we can compute the average reward as:\n",
    "\\begin{equation}\n",
    "0.916 * 1 + 0.083 * -1 \\approx 0.83.\n",
    "\\end{equation}\n",
    "The performance of the PPO2 and A2C agent is then very close to the theoretical best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple problem resembles more a *contextual n-armed bandit* or even a simpler *supervised learning* problem. It hardly constitute a challenge for the reinforcement learning algorithms that are able to achieve an almost perfect performance. In the next notebook we will consider a more complex instantiation of the game."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
