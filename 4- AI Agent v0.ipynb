{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent Playing QisCoin v0\n",
    "\n",
    "In this notebook we load a simple version of **QisCoin** (*qiscoin-v0*) in which a quantum circuit with a single random gate is generated. We instantiate and run a random agent and few RL agents from the stable-baselines library and we observe their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "\n",
    "We start importing the main required libraries: OpenAI *gym* to run the game; *IPython.display* to print out our circuits.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing gym-qiscoin\n",
    "\n",
    "Next, we import the version of **QisCoin** wrapped into the *gym* interface. The code for this version of the game is available [here](https://github.uio.no/fabiomz/gym-qiscoin) and it can be installed as explained in the notebook [Setup](https://github.com/avalds/QisCoin/blob/master/1-%20Setup.ipynb).\n",
    "\n",
    "This version of **QisCoin** implements a game environment that inherits from the OpenAI *gym* **Env** class. It implements four main methods: *\\__init__()* for setting up the game; *step()* computing the result of a single time-step of evolution of the environment; *reset()* restarting the game; *render()* displaying the game.\n",
    "\n",
    "The **QisCoin** game has been modeled with a *discrete state space* (an integer number between 0 and 5 identifies which of the six possible gates has been randomly added on the circuit) and a *discrete action space* (the two integer numbers 0 and 1 corresponds to the possible guesses of the agent). Since the game is fully observed, the state space corresponds to the observation space. A positive reward (+1) is returned for guessing correctly, a negative reward (-1) is returned for guessing wrong.\n",
    "\n",
    "The game we run in **qiscoin-v0** is a simplified version of the base game generating a quantum circuit with only a single random gate selected among six options (*x, id, reset, h, t, tdg*). Check the [Rules](2-%20Rules.ipynb) for more details. \n",
    "\n",
    "The code is available in the source file: https://github.uio.no/fabiomz/gym-qiscoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiscoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the game\n",
    "We create the game enviroment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('qiscoin-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we test the game running a single iteration of the game where the AI agent takes a random guess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 293.776x144.48 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is guessing that the outcome will be 1\n",
      "The guess is wrong!\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "display(env.render())\n",
    "\n",
    "for _ in range(1):\n",
    "    guess = env.action_space.sample()\n",
    "    print(\"AI is guessing that the outcome will be {0}\".format(guess))\n",
    "    obs, reward, done, info = env.step(guess)\n",
    "    if(reward==1):\n",
    "        print(\"The guess is correct!\")\n",
    "    else:\n",
    "        print(\"The guess is wrong!\")\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Reinforcement Learning Agent\n",
    "\n",
    "Running a random agent playing **QisCoin** is not particularly interesting. We then turn to loading and running reinforcement learning agents that, starting from a random policy, would be able to learn to play **QisCoin** in a sensible way. To do so, we rely on the library of agents provided by stable-baselines.\n",
    "\n",
    "More information and examples on stable-baselines: https://github.com/hill-a/stable-baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a PPO2 Agent\n",
    "\n",
    "We consider instanting and training a PPO2 agent.\n",
    "\n",
    "More information on the PPO2 agent: https://stable-baselines.readthedocs.io/en/v2.3.0/modules/ppo2.html\n",
    "\n",
    "First of all we import the required modules: *DummyVecEnv* providing a wrapper for our environment as required by stable-baselines; *MlpPolicy* specifying a policy network for our agent; *PPO2* implementing the actual agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then vectorize our environment (this is a formal step required for the agent to be able to play the game), we instantiate the PPO2 model, and we train it by playing 10000 games of **QisCoin**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/input.py:20: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/policies.py:562: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/distributions.py:323: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/distributions.py:324: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:193: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:201: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:209: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:243: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:245: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "--------------------------------------\n",
      "| approxkl           | 6.3838364e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0511       |\n",
      "| fps                | 133           |\n",
      "| n_updates          | 1             |\n",
      "| policy_entropy     | 0.6930816     |\n",
      "| policy_loss        | -0.007927172  |\n",
      "| serial_timesteps   | 128           |\n",
      "| time_elapsed       | 3.34e-06      |\n",
      "| total_timesteps    | 128           |\n",
      "| value_loss         | 0.52241796    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00010894248 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0892       |\n",
      "| fps                | 185           |\n",
      "| n_updates          | 2             |\n",
      "| policy_entropy     | 0.69255894    |\n",
      "| policy_loss        | -0.010692329  |\n",
      "| serial_timesteps   | 256           |\n",
      "| time_elapsed       | 0.959         |\n",
      "| total_timesteps    | 256           |\n",
      "| value_loss         | 0.5354515     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00023480358 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00392      |\n",
      "| fps                | 160           |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 0.69080925    |\n",
      "| policy_loss        | -0.015349174  |\n",
      "| serial_timesteps   | 384           |\n",
      "| time_elapsed       | 1.65          |\n",
      "| total_timesteps    | 384           |\n",
      "| value_loss         | 0.49961433    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0005662171 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.00813     |\n",
      "| fps                | 166          |\n",
      "| n_updates          | 4            |\n",
      "| policy_entropy     | 0.6857129    |\n",
      "| policy_loss        | -0.02522771  |\n",
      "| serial_timesteps   | 512          |\n",
      "| time_elapsed       | 2.45         |\n",
      "| total_timesteps    | 512          |\n",
      "| value_loss         | 0.5023785    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0010672202 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.00144      |\n",
      "| fps                | 167          |\n",
      "| n_updates          | 5            |\n",
      "| policy_entropy     | 0.6733884    |\n",
      "| policy_loss        | -0.032211892 |\n",
      "| serial_timesteps   | 640          |\n",
      "| time_elapsed       | 3.22         |\n",
      "| total_timesteps    | 640          |\n",
      "| value_loss         | 0.4777324    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0018811201 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.019        |\n",
      "| fps                | 166          |\n",
      "| n_updates          | 6            |\n",
      "| policy_entropy     | 0.65098184   |\n",
      "| policy_loss        | -0.04094315  |\n",
      "| serial_timesteps   | 768          |\n",
      "| time_elapsed       | 3.98         |\n",
      "| total_timesteps    | 768          |\n",
      "| value_loss         | 0.48576078   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0026500153 |\n",
      "| clipfrac           | 0.015625     |\n",
      "| explained_variance | 0.0356       |\n",
      "| fps                | 194          |\n",
      "| n_updates          | 7            |\n",
      "| policy_entropy     | 0.6090725    |\n",
      "| policy_loss        | -0.047578126 |\n",
      "| serial_timesteps   | 896          |\n",
      "| time_elapsed       | 4.75         |\n",
      "| total_timesteps    | 896          |\n",
      "| value_loss         | 0.4458298    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.003261732  |\n",
      "| clipfrac           | 0.044921875  |\n",
      "| explained_variance | -0.0138      |\n",
      "| fps                | 188          |\n",
      "| n_updates          | 8            |\n",
      "| policy_entropy     | 0.54227906   |\n",
      "| policy_loss        | -0.051351152 |\n",
      "| serial_timesteps   | 1024         |\n",
      "| time_elapsed       | 5.41         |\n",
      "| total_timesteps    | 1024         |\n",
      "| value_loss         | 0.41543284   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0026255043 |\n",
      "| clipfrac           | 0.025390625  |\n",
      "| explained_variance | 0.0592       |\n",
      "| fps                | 193          |\n",
      "| n_updates          | 9            |\n",
      "| policy_entropy     | 0.5011664    |\n",
      "| policy_loss        | -0.04487677  |\n",
      "| serial_timesteps   | 1152         |\n",
      "| time_elapsed       | 6.09         |\n",
      "| total_timesteps    | 1152         |\n",
      "| value_loss         | 0.37439835   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.0018838282 |\n",
      "| clipfrac           | 0.02734375   |\n",
      "| explained_variance | 0.0753       |\n",
      "| fps                | 195          |\n",
      "| n_updates          | 10           |\n",
      "| policy_entropy     | 0.44229704   |\n",
      "| policy_loss        | -0.031341426 |\n",
      "| serial_timesteps   | 1280         |\n",
      "| time_elapsed       | 6.75         |\n",
      "| total_timesteps    | 1280         |\n",
      "| value_loss         | 0.31889597   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0015691593 |\n",
      "| clipfrac           | 0.0234375    |\n",
      "| explained_variance | 0.123        |\n",
      "| fps                | 195          |\n",
      "| n_updates          | 11           |\n",
      "| policy_entropy     | 0.37510973   |\n",
      "| policy_loss        | -0.03088452  |\n",
      "| serial_timesteps   | 1408         |\n",
      "| time_elapsed       | 7.41         |\n",
      "| total_timesteps    | 1408         |\n",
      "| value_loss         | 0.25208205   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0025304193 |\n",
      "| clipfrac           | 0.041015625  |\n",
      "| explained_variance | 0.171        |\n",
      "| fps                | 196          |\n",
      "| n_updates          | 12           |\n",
      "| policy_entropy     | 0.31720164   |\n",
      "| policy_loss        | -0.035082154 |\n",
      "| serial_timesteps   | 1536         |\n",
      "| time_elapsed       | 8.06         |\n",
      "| total_timesteps    | 1536         |\n",
      "| value_loss         | 0.2992669    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.001860966 |\n",
      "| clipfrac           | 0.02734375  |\n",
      "| explained_variance | 0.0688      |\n",
      "| fps                | 197         |\n",
      "| n_updates          | 13          |\n",
      "| policy_entropy     | 0.24398725  |\n",
      "| policy_loss        | -0.02768773 |\n",
      "| serial_timesteps   | 1664        |\n",
      "| time_elapsed       | 8.71        |\n",
      "| total_timesteps    | 1664        |\n",
      "| value_loss         | 0.20693478  |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00031250433 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.284         |\n",
      "| fps                | 196           |\n",
      "| n_updates          | 14            |\n",
      "| policy_entropy     | 0.23402673    |\n",
      "| policy_loss        | -0.010643412  |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 9.36          |\n",
      "| total_timesteps    | 1792          |\n",
      "| value_loss         | 0.13339081    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0007748675 |\n",
      "| clipfrac           | 0.005859375  |\n",
      "| explained_variance | 0.357        |\n",
      "| fps                | 195          |\n",
      "| n_updates          | 15           |\n",
      "| policy_entropy     | 0.23134394   |\n",
      "| policy_loss        | -0.013493254 |\n",
      "| serial_timesteps   | 1920         |\n",
      "| time_elapsed       | 10           |\n",
      "| total_timesteps    | 1920         |\n",
      "| value_loss         | 0.17561561   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0013633767 |\n",
      "| clipfrac           | 0.021484375  |\n",
      "| explained_variance | 0.0911       |\n",
      "| fps                | 197          |\n",
      "| n_updates          | 16           |\n",
      "| policy_entropy     | 0.18342985   |\n",
      "| policy_loss        | -0.023529531 |\n",
      "| serial_timesteps   | 2048         |\n",
      "| time_elapsed       | 10.7         |\n",
      "| total_timesteps    | 2048         |\n",
      "| value_loss         | 0.17675552   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00064764114 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.423         |\n",
      "| fps                | 196           |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 0.17332628    |\n",
      "| policy_loss        | -0.011830378  |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 11.3          |\n",
      "| total_timesteps    | 2176          |\n",
      "| value_loss         | 0.10652088    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00018475659 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.561         |\n",
      "| fps                | 197           |\n",
      "| n_updates          | 18            |\n",
      "| policy_entropy     | 0.15352319    |\n",
      "| policy_loss        | 0.0004339607  |\n",
      "| serial_timesteps   | 2304          |\n",
      "| time_elapsed       | 12            |\n",
      "| total_timesteps    | 2304          |\n",
      "| value_loss         | 0.06709985    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00029856391 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00476      |\n",
      "| fps                | 194           |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 0.16888142    |\n",
      "| policy_loss        | -0.006344689  |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 12.6          |\n",
      "| total_timesteps    | 2432          |\n",
      "| value_loss         | 0.11799899    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00063533377 |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| explained_variance | -0.000259     |\n",
      "| fps                | 196           |\n",
      "| n_updates          | 20            |\n",
      "| policy_entropy     | 0.15577449    |\n",
      "| policy_loss        | -0.013408627  |\n",
      "| serial_timesteps   | 2560          |\n",
      "| time_elapsed       | 13.3          |\n",
      "| total_timesteps    | 2560          |\n",
      "| value_loss         | 0.12510024    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.001501331  |\n",
      "| clipfrac           | 0.01953125   |\n",
      "| explained_variance | 0.427        |\n",
      "| fps                | 193          |\n",
      "| n_updates          | 21           |\n",
      "| policy_entropy     | 0.19363326   |\n",
      "| policy_loss        | -0.010475519 |\n",
      "| serial_timesteps   | 2688         |\n",
      "| time_elapsed       | 13.9         |\n",
      "| total_timesteps    | 2688         |\n",
      "| value_loss         | 0.16847087   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00023015124 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.341         |\n",
      "| fps                | 197           |\n",
      "| n_updates          | 22            |\n",
      "| policy_entropy     | 0.10221614    |\n",
      "| policy_loss        | -0.0023070492 |\n",
      "| serial_timesteps   | 2816          |\n",
      "| time_elapsed       | 14.6          |\n",
      "| total_timesteps    | 2816          |\n",
      "| value_loss         | 0.07819822    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00025646962 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0986        |\n",
      "| fps                | 186           |\n",
      "| n_updates          | 23            |\n",
      "| policy_entropy     | 0.13290036    |\n",
      "| policy_loss        | -0.0035451956 |\n",
      "| serial_timesteps   | 2944          |\n",
      "| time_elapsed       | 15.2          |\n",
      "| total_timesteps    | 2944          |\n",
      "| value_loss         | 0.11743961    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 4.880892e-06 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.404        |\n",
      "| fps                | 161          |\n",
      "| n_updates          | 24           |\n",
      "| policy_entropy     | 0.10383418   |\n",
      "| policy_loss        | 0.0005604774 |\n",
      "| serial_timesteps   | 3072         |\n",
      "| time_elapsed       | 15.9         |\n",
      "| total_timesteps    | 3072         |\n",
      "| value_loss         | 0.08712654   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00011824862 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.511         |\n",
      "| fps                | 172           |\n",
      "| n_updates          | 25            |\n",
      "| policy_entropy     | 0.10747291    |\n",
      "| policy_loss        | -0.005150959  |\n",
      "| serial_timesteps   | 3200          |\n",
      "| time_elapsed       | 16.7          |\n",
      "| total_timesteps    | 3200          |\n",
      "| value_loss         | 0.09279838    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.779347e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.424         |\n",
      "| fps                | 195           |\n",
      "| n_updates          | 26            |\n",
      "| policy_entropy     | 0.1188213     |\n",
      "| policy_loss        | 0.00088417646 |\n",
      "| serial_timesteps   | 3328          |\n",
      "| time_elapsed       | 17.5          |\n",
      "| total_timesteps    | 3328          |\n",
      "| value_loss         | 0.09758069    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.00039793612 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.302         |\n",
      "| fps                | 194           |\n",
      "| n_updates          | 27            |\n",
      "| policy_entropy     | 0.09650291    |\n",
      "| policy_loss        | -0.0026956282 |\n",
      "| serial_timesteps   | 3456          |\n",
      "| time_elapsed       | 18.1          |\n",
      "| total_timesteps    | 3456          |\n",
      "| value_loss         | 0.07280447    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.6600841e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.597         |\n",
      "| fps                | 193           |\n",
      "| n_updates          | 28            |\n",
      "| policy_entropy     | 0.11750673    |\n",
      "| policy_loss        | -0.0003064396 |\n",
      "| serial_timesteps   | 3584          |\n",
      "| time_elapsed       | 18.8          |\n",
      "| total_timesteps    | 3584          |\n",
      "| value_loss         | 0.10008956    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.586311e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.368         |\n",
      "| fps                | 197           |\n",
      "| n_updates          | 29            |\n",
      "| policy_entropy     | 0.1005265     |\n",
      "| policy_loss        | -0.0038377293 |\n",
      "| serial_timesteps   | 3712          |\n",
      "| time_elapsed       | 19.4          |\n",
      "| total_timesteps    | 3712          |\n",
      "| value_loss         | 0.100710526   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0007647544 |\n",
      "| clipfrac           | 0.01953125   |\n",
      "| explained_variance | 0.385        |\n",
      "| fps                | 166          |\n",
      "| n_updates          | 30           |\n",
      "| policy_entropy     | 0.12228021   |\n",
      "| policy_loss        | -0.006618829 |\n",
      "| serial_timesteps   | 3840         |\n",
      "| time_elapsed       | 20.1         |\n",
      "| total_timesteps    | 3840         |\n",
      "| value_loss         | 0.096150205  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017501909 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.207         |\n",
      "| fps                | 173           |\n",
      "| n_updates          | 31            |\n",
      "| policy_entropy     | 0.1054355     |\n",
      "| policy_loss        | -0.0034452248 |\n",
      "| serial_timesteps   | 3968          |\n",
      "| time_elapsed       | 20.9          |\n",
      "| total_timesteps    | 3968          |\n",
      "| value_loss         | 0.0688083     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00012584396 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.399         |\n",
      "| fps                | 165           |\n",
      "| n_updates          | 32            |\n",
      "| policy_entropy     | 0.09180434    |\n",
      "| policy_loss        | 0.0018234544  |\n",
      "| serial_timesteps   | 4096          |\n",
      "| time_elapsed       | 21.6          |\n",
      "| total_timesteps    | 4096          |\n",
      "| value_loss         | 0.053635877   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0002603011  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.364         |\n",
      "| fps                | 147           |\n",
      "| n_updates          | 33            |\n",
      "| policy_entropy     | 0.13467447    |\n",
      "| policy_loss        | -0.0023317263 |\n",
      "| serial_timesteps   | 4224          |\n",
      "| time_elapsed       | 22.4          |\n",
      "| total_timesteps    | 4224          |\n",
      "| value_loss         | 0.08319915    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 9.843666e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.46         |\n",
      "| fps                | 92           |\n",
      "| n_updates          | 34           |\n",
      "| policy_entropy     | 0.120016076  |\n",
      "| policy_loss        | -0.002145765 |\n",
      "| serial_timesteps   | 4352         |\n",
      "| time_elapsed       | 23.2         |\n",
      "| total_timesteps    | 4352         |\n",
      "| value_loss         | 0.07795445   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00022940645 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.498         |\n",
      "| fps                | 120           |\n",
      "| n_updates          | 35            |\n",
      "| policy_entropy     | 0.14463459    |\n",
      "| policy_loss        | 0.00028675597 |\n",
      "| serial_timesteps   | 4480          |\n",
      "| time_elapsed       | 24.6          |\n",
      "| total_timesteps    | 4480          |\n",
      "| value_loss         | 0.10121524    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00058648654 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.3           |\n",
      "| fps                | 106           |\n",
      "| n_updates          | 36            |\n",
      "| policy_entropy     | 0.14190312    |\n",
      "| policy_loss        | -0.005592813  |\n",
      "| serial_timesteps   | 4608          |\n",
      "| time_elapsed       | 25.7          |\n",
      "| total_timesteps    | 4608          |\n",
      "| value_loss         | 0.103872344   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00042827625 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.219         |\n",
      "| fps                | 100           |\n",
      "| n_updates          | 37            |\n",
      "| policy_entropy     | 0.119859934   |\n",
      "| policy_loss        | 0.00034247083 |\n",
      "| serial_timesteps   | 4736          |\n",
      "| time_elapsed       | 26.9          |\n",
      "| total_timesteps    | 4736          |\n",
      "| value_loss         | 0.08881559    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00023088235 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.371         |\n",
      "| fps                | 123           |\n",
      "| n_updates          | 38            |\n",
      "| policy_entropy     | 0.093597755   |\n",
      "| policy_loss        | -0.006045026  |\n",
      "| serial_timesteps   | 4864          |\n",
      "| time_elapsed       | 28.2          |\n",
      "| total_timesteps    | 4864          |\n",
      "| value_loss         | 0.083628304   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0007141779 |\n",
      "| clipfrac           | 0.0078125    |\n",
      "| explained_variance | 0.102        |\n",
      "| fps                | 141          |\n",
      "| n_updates          | 39           |\n",
      "| policy_entropy     | 0.11478753   |\n",
      "| policy_loss        | -0.009133993 |\n",
      "| serial_timesteps   | 4992         |\n",
      "| time_elapsed       | 29.2         |\n",
      "| total_timesteps    | 4992         |\n",
      "| value_loss         | 0.08032371   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.116477e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.456         |\n",
      "| fps                | 130           |\n",
      "| n_updates          | 40            |\n",
      "| policy_entropy     | 0.10804866    |\n",
      "| policy_loss        | 0.00059364934 |\n",
      "| serial_timesteps   | 5120          |\n",
      "| time_elapsed       | 30.1          |\n",
      "| total_timesteps    | 5120          |\n",
      "| value_loss         | 0.07870863    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00011860188 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.307         |\n",
      "| fps                | 126           |\n",
      "| n_updates          | 41            |\n",
      "| policy_entropy     | 0.1148796     |\n",
      "| policy_loss        | -0.0025830364 |\n",
      "| serial_timesteps   | 5248          |\n",
      "| time_elapsed       | 31.1          |\n",
      "| total_timesteps    | 5248          |\n",
      "| value_loss         | 0.072174236   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 3.836868e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.447        |\n",
      "| fps                | 109          |\n",
      "| n_updates          | 42           |\n",
      "| policy_entropy     | 0.11866254   |\n",
      "| policy_loss        | -0.000528326 |\n",
      "| serial_timesteps   | 5376         |\n",
      "| time_elapsed       | 32.1         |\n",
      "| total_timesteps    | 5376         |\n",
      "| value_loss         | 0.10899263   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0011983076 |\n",
      "| clipfrac           | 0.03125      |\n",
      "| explained_variance | 0.264        |\n",
      "| fps                | 91           |\n",
      "| n_updates          | 43           |\n",
      "| policy_entropy     | 0.1106028    |\n",
      "| policy_loss        | -0.01550775  |\n",
      "| serial_timesteps   | 5504         |\n",
      "| time_elapsed       | 33.3         |\n",
      "| total_timesteps    | 5504         |\n",
      "| value_loss         | 0.08786835   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 2.9092984e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.441         |\n",
      "| fps                | 126           |\n",
      "| n_updates          | 44            |\n",
      "| policy_entropy     | 0.14945719    |\n",
      "| policy_loss        | 0.000982032   |\n",
      "| serial_timesteps   | 5632          |\n",
      "| time_elapsed       | 34.7          |\n",
      "| total_timesteps    | 5632          |\n",
      "| value_loss         | 0.10188837    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 6.541604e-06 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.461        |\n",
      "| fps                | 139          |\n",
      "| n_updates          | 45           |\n",
      "| policy_entropy     | 0.10760135   |\n",
      "| policy_loss        | 0.0004118277 |\n",
      "| serial_timesteps   | 5760         |\n",
      "| time_elapsed       | 35.7         |\n",
      "| total_timesteps    | 5760         |\n",
      "| value_loss         | 0.07044351   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.9259135e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.433          |\n",
      "| fps                | 155            |\n",
      "| n_updates          | 46             |\n",
      "| policy_entropy     | 0.11223404     |\n",
      "| policy_loss        | -0.00012389504 |\n",
      "| serial_timesteps   | 5888           |\n",
      "| time_elapsed       | 36.6           |\n",
      "| total_timesteps    | 5888           |\n",
      "| value_loss         | 0.074229285    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00011987547 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.477         |\n",
      "| fps                | 158           |\n",
      "| n_updates          | 47            |\n",
      "| policy_entropy     | 0.11742085    |\n",
      "| policy_loss        | -0.0008439985 |\n",
      "| serial_timesteps   | 6016          |\n",
      "| time_elapsed       | 37.4          |\n",
      "| total_timesteps    | 6016          |\n",
      "| value_loss         | 0.08231436    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00081182073 |\n",
      "| clipfrac           | 0.01171875    |\n",
      "| explained_variance | 0.529         |\n",
      "| fps                | 155           |\n",
      "| n_updates          | 48            |\n",
      "| policy_entropy     | 0.10220977    |\n",
      "| policy_loss        | -0.010351125  |\n",
      "| serial_timesteps   | 6144          |\n",
      "| time_elapsed       | 38.2          |\n",
      "| total_timesteps    | 6144          |\n",
      "| value_loss         | 0.073848516   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00014521845 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.443         |\n",
      "| fps                | 156           |\n",
      "| n_updates          | 49            |\n",
      "| policy_entropy     | 0.12223011    |\n",
      "| policy_loss        | 0.0008282482  |\n",
      "| serial_timesteps   | 6272          |\n",
      "| time_elapsed       | 39.1          |\n",
      "| total_timesteps    | 6272          |\n",
      "| value_loss         | 0.10187411    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.657361e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.39          |\n",
      "| fps                | 145           |\n",
      "| n_updates          | 50            |\n",
      "| policy_entropy     | 0.079495884   |\n",
      "| policy_loss        | 0.00023912537 |\n",
      "| serial_timesteps   | 6400          |\n",
      "| time_elapsed       | 39.9          |\n",
      "| total_timesteps    | 6400          |\n",
      "| value_loss         | 0.062736355   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.9408824e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.481         |\n",
      "| fps                | 165           |\n",
      "| n_updates          | 51            |\n",
      "| policy_entropy     | 0.13590023    |\n",
      "| policy_loss        | -6.516301e-05 |\n",
      "| serial_timesteps   | 6528          |\n",
      "| time_elapsed       | 40.8          |\n",
      "| total_timesteps    | 6528          |\n",
      "| value_loss         | 0.1144925     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00015445313 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.282         |\n",
      "| fps                | 166           |\n",
      "| n_updates          | 52            |\n",
      "| policy_entropy     | 0.07587468    |\n",
      "| policy_loss        | 0.00046865875 |\n",
      "| serial_timesteps   | 6656          |\n",
      "| time_elapsed       | 41.5          |\n",
      "| total_timesteps    | 6656          |\n",
      "| value_loss         | 0.054349974   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00051533885 |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| explained_variance | 0.189         |\n",
      "| fps                | 166           |\n",
      "| n_updates          | 53            |\n",
      "| policy_entropy     | 0.10155467    |\n",
      "| policy_loss        | -0.0069963555 |\n",
      "| serial_timesteps   | 6784          |\n",
      "| time_elapsed       | 42.3          |\n",
      "| total_timesteps    | 6784          |\n",
      "| value_loss         | 0.08259795    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0007617202  |\n",
      "| clipfrac           | 0.013671875   |\n",
      "| explained_variance | 0.564         |\n",
      "| fps                | 172           |\n",
      "| n_updates          | 54            |\n",
      "| policy_entropy     | 0.09088346    |\n",
      "| policy_loss        | -0.0094902385 |\n",
      "| serial_timesteps   | 6912          |\n",
      "| time_elapsed       | 43.1          |\n",
      "| total_timesteps    | 6912          |\n",
      "| value_loss         | 0.063703656   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.9586085e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.534         |\n",
      "| fps                | 173           |\n",
      "| n_updates          | 55            |\n",
      "| policy_entropy     | 0.13584664    |\n",
      "| policy_loss        | 0.0011795252  |\n",
      "| serial_timesteps   | 7040          |\n",
      "| time_elapsed       | 43.8          |\n",
      "| total_timesteps    | 7040          |\n",
      "| value_loss         | 0.088997565   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.4341824e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.36          |\n",
      "| fps                | 173           |\n",
      "| n_updates          | 56            |\n",
      "| policy_entropy     | 0.07621058    |\n",
      "| policy_loss        | 0.0010091544  |\n",
      "| serial_timesteps   | 7168          |\n",
      "| time_elapsed       | 44.6          |\n",
      "| total_timesteps    | 7168          |\n",
      "| value_loss         | 0.04859677    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00012152511 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.498         |\n",
      "| fps                | 175           |\n",
      "| n_updates          | 57            |\n",
      "| policy_entropy     | 0.16031238    |\n",
      "| policy_loss        | -0.0034287833 |\n",
      "| serial_timesteps   | 7296          |\n",
      "| time_elapsed       | 45.3          |\n",
      "| total_timesteps    | 7296          |\n",
      "| value_loss         | 0.122456096   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.8097467e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.452         |\n",
      "| fps                | 174           |\n",
      "| n_updates          | 58            |\n",
      "| policy_entropy     | 0.16172385    |\n",
      "| policy_loss        | 0.00091617275 |\n",
      "| serial_timesteps   | 7424          |\n",
      "| time_elapsed       | 46            |\n",
      "| total_timesteps    | 7424          |\n",
      "| value_loss         | 0.114005655   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00096984406 |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| explained_variance | 0.425         |\n",
      "| fps                | 177           |\n",
      "| n_updates          | 59            |\n",
      "| policy_entropy     | 0.122219436   |\n",
      "| policy_loss        | -0.011350177  |\n",
      "| serial_timesteps   | 7552          |\n",
      "| time_elapsed       | 46.8          |\n",
      "| total_timesteps    | 7552          |\n",
      "| value_loss         | 0.0976052     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0004011154 |\n",
      "| clipfrac           | 0.001953125  |\n",
      "| explained_variance | 0.455        |\n",
      "| fps                | 176          |\n",
      "| n_updates          | 60           |\n",
      "| policy_entropy     | 0.116096005  |\n",
      "| policy_loss        | -0.005524846 |\n",
      "| serial_timesteps   | 7680         |\n",
      "| time_elapsed       | 47.5         |\n",
      "| total_timesteps    | 7680         |\n",
      "| value_loss         | 0.092683755  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 4.4087974e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.108         |\n",
      "| fps                | 180           |\n",
      "| n_updates          | 61            |\n",
      "| policy_entropy     | 0.112581804   |\n",
      "| policy_loss        | 0.00020006334 |\n",
      "| serial_timesteps   | 7808          |\n",
      "| time_elapsed       | 48.2          |\n",
      "| total_timesteps    | 7808          |\n",
      "| value_loss         | 0.079269774   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.6444588e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.372         |\n",
      "| fps                | 178           |\n",
      "| n_updates          | 62            |\n",
      "| policy_entropy     | 0.09869638    |\n",
      "| policy_loss        | 0.0008886056  |\n",
      "| serial_timesteps   | 7936          |\n",
      "| time_elapsed       | 48.9          |\n",
      "| total_timesteps    | 7936          |\n",
      "| value_loss         | 0.064796284   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00013736996 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.306         |\n",
      "| fps                | 179           |\n",
      "| n_updates          | 63            |\n",
      "| policy_entropy     | 0.114962265   |\n",
      "| policy_loss        | -0.0018014219 |\n",
      "| serial_timesteps   | 8064          |\n",
      "| time_elapsed       | 49.6          |\n",
      "| total_timesteps    | 8064          |\n",
      "| value_loss         | 0.071516216   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00029213165 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.425         |\n",
      "| fps                | 180           |\n",
      "| n_updates          | 64            |\n",
      "| policy_entropy     | 0.1150094     |\n",
      "| policy_loss        | -0.006433119  |\n",
      "| serial_timesteps   | 8192          |\n",
      "| time_elapsed       | 50.4          |\n",
      "| total_timesteps    | 8192          |\n",
      "| value_loss         | 0.08338491    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0002600163 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.34         |\n",
      "| fps                | 182          |\n",
      "| n_updates          | 65           |\n",
      "| policy_entropy     | 0.116368294  |\n",
      "| policy_loss        | 0.0046243686 |\n",
      "| serial_timesteps   | 8320         |\n",
      "| time_elapsed       | 51.1         |\n",
      "| total_timesteps    | 8320         |\n",
      "| value_loss         | 0.07750596   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.001009572   |\n",
      "| clipfrac           | 0.005859375   |\n",
      "| explained_variance | 0.514         |\n",
      "| fps                | 184           |\n",
      "| n_updates          | 66            |\n",
      "| policy_entropy     | 0.156145      |\n",
      "| policy_loss        | -0.0060748514 |\n",
      "| serial_timesteps   | 8448          |\n",
      "| time_elapsed       | 51.8          |\n",
      "| total_timesteps    | 8448          |\n",
      "| value_loss         | 0.1211531     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000622432    |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.528          |\n",
      "| fps                | 183            |\n",
      "| n_updates          | 67             |\n",
      "| policy_entropy     | 0.15691128     |\n",
      "| policy_loss        | -6.6090375e-05 |\n",
      "| serial_timesteps   | 8576           |\n",
      "| time_elapsed       | 52.5           |\n",
      "| total_timesteps    | 8576           |\n",
      "| value_loss         | 0.10607388     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00014364191  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.312          |\n",
      "| fps                | 182            |\n",
      "| n_updates          | 68             |\n",
      "| policy_entropy     | 0.10869678     |\n",
      "| policy_loss        | -0.00087504624 |\n",
      "| serial_timesteps   | 8704           |\n",
      "| time_elapsed       | 53.2           |\n",
      "| total_timesteps    | 8704           |\n",
      "| value_loss         | 0.08310104     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0002080207 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.618        |\n",
      "| fps                | 185          |\n",
      "| n_updates          | 69           |\n",
      "| policy_entropy     | 0.11861236   |\n",
      "| policy_loss        | -0.004776224 |\n",
      "| serial_timesteps   | 8832         |\n",
      "| time_elapsed       | 53.9         |\n",
      "| total_timesteps    | 8832         |\n",
      "| value_loss         | 0.07517863   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00074017624 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.356         |\n",
      "| fps                | 182           |\n",
      "| n_updates          | 70            |\n",
      "| policy_entropy     | 0.093282685   |\n",
      "| policy_loss        | -0.008401725  |\n",
      "| serial_timesteps   | 8960          |\n",
      "| time_elapsed       | 54.5          |\n",
      "| total_timesteps    | 8960          |\n",
      "| value_loss         | 0.06699964    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0018757163 |\n",
      "| clipfrac           | 0.021484375  |\n",
      "| explained_variance | -0.19        |\n",
      "| fps                | 180          |\n",
      "| n_updates          | 71           |\n",
      "| policy_entropy     | 0.13579296   |\n",
      "| policy_loss        | -0.010770718 |\n",
      "| serial_timesteps   | 9088         |\n",
      "| time_elapsed       | 55.3         |\n",
      "| total_timesteps    | 9088         |\n",
      "| value_loss         | 0.10175143   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0002161679  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.143         |\n",
      "| fps                | 182           |\n",
      "| n_updates          | 72            |\n",
      "| policy_entropy     | 0.11241615    |\n",
      "| policy_loss        | -0.0021671122 |\n",
      "| serial_timesteps   | 9216          |\n",
      "| time_elapsed       | 56            |\n",
      "| total_timesteps    | 9216          |\n",
      "| value_loss         | 0.073095754   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00026769497 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.383         |\n",
      "| fps                | 179           |\n",
      "| n_updates          | 73            |\n",
      "| policy_entropy     | 0.12411916    |\n",
      "| policy_loss        | -0.004969434  |\n",
      "| serial_timesteps   | 9344          |\n",
      "| time_elapsed       | 56.7          |\n",
      "| total_timesteps    | 9344          |\n",
      "| value_loss         | 0.106599316   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.5192314e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.42          |\n",
      "| fps                | 183           |\n",
      "| n_updates          | 74            |\n",
      "| policy_entropy     | 0.08997823    |\n",
      "| policy_loss        | 0.0021360847  |\n",
      "| serial_timesteps   | 9472          |\n",
      "| time_elapsed       | 57.4          |\n",
      "| total_timesteps    | 9472          |\n",
      "| value_loss         | 0.08156298    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000105689476 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.322          |\n",
      "| fps                | 183            |\n",
      "| n_updates          | 75             |\n",
      "| policy_entropy     | 0.08870321     |\n",
      "| policy_loss        | -0.00090564357 |\n",
      "| serial_timesteps   | 9600           |\n",
      "| time_elapsed       | 58.1           |\n",
      "| total_timesteps    | 9600           |\n",
      "| value_loss         | 0.07100533     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.497348e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.405         |\n",
      "| fps                | 183           |\n",
      "| n_updates          | 76            |\n",
      "| policy_entropy     | 0.080773875   |\n",
      "| policy_loss        | 0.00022132299 |\n",
      "| serial_timesteps   | 9728          |\n",
      "| time_elapsed       | 58.8          |\n",
      "| total_timesteps    | 9728          |\n",
      "| value_loss         | 0.061650947   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0002052832 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.318        |\n",
      "| fps                | 183          |\n",
      "| n_updates          | 77           |\n",
      "| policy_entropy     | 0.15481283   |\n",
      "| policy_loss        | -0.003396569 |\n",
      "| serial_timesteps   | 9856         |\n",
      "| time_elapsed       | 59.5         |\n",
      "| total_timesteps    | 9856         |\n",
      "| value_loss         | 0.115897425  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.00054385146 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.499         |\n",
      "| fps                | 183           |\n",
      "| n_updates          | 78            |\n",
      "| policy_entropy     | 0.13999169    |\n",
      "| policy_loss        | 0.0008117856  |\n",
      "| serial_timesteps   | 9984          |\n",
      "| time_elapsed       | 60.2          |\n",
      "| total_timesteps    | 9984          |\n",
      "| value_loss         | 0.11088308    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7fa13f6ce950>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = DummyVecEnv([lambda: env])\n",
    "PPO2model = PPO2(MlpPolicy, env, verbose=1)\n",
    "PPO2model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save our model in order to be able to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO2model.save('models/PPO2-qiscoin-v0-10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a A2C agent\n",
    "For the sake of comparison, we also train a A2C agent.\n",
    "\n",
    "More information on the A2C agent: https://stable-baselines.readthedocs.io/en/v2.3.0/modules/a2c.html\n",
    "\n",
    "As before, we import the module for the *A2C* agent, we set up the agent, train it on 10000 games of **QisCoin** and save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:312: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:312: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:159: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "| explained_variance | 0.275    |\n",
      "| fps                | 26       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.06     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.169    |\n",
      "| fps                | 165      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.932    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0145  |\n",
      "| fps                | 167      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 1.2      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.104   |\n",
      "| fps                | 172      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 0.688    |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 1.27     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.0584   |\n",
      "| fps                | 159      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 0.673    |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.905    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0985  |\n",
      "| fps                | 155      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 0.647    |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.868    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 157      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 0.577    |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 0.462    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.395    |\n",
      "| fps                | 160      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 0.48     |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.432    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0105  |\n",
      "| fps                | 160      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 0.252    |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.56     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.375    |\n",
      "| fps                | 157      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 0.368    |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 0.4      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 156      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 0.134    |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.00129  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 157      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 0.0663   |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 0.000702 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 159      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 0.076    |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 4.19e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.815    |\n",
      "| fps                | 159      |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 0.179    |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 0.143    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 160      |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 0.161    |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 0.362    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.862    |\n",
      "| fps                | 160      |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 0.168    |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 0.109    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 160      |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 0.1      |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.128    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 161      |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 0.0201   |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 2.52e-05 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.37     |\n",
      "| fps                | 161      |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 0.115    |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.406    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 161      |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 0.0218   |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 0.000103 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 161      |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 0.0206   |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 2.7e-05  |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.a2c.a2c.A2C at 0x7fa13c56e8d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2Cmodel = A2C(MlpPolicy, env, verbose=1)\n",
    "A2Cmodel.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2Cmodel.save('models/A2C-qiscoin-v0-10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the agents\n",
    "We now compare and evalute the agents. \n",
    "\n",
    "First of all, we import the module *evaluation.py* to run an evaluation functions on our agents. The module provides simple functions that run a number of iteration of the **QisCoin** game (default: 1000 games) and return the average reward collected. The source of all these evaluation functions is available in [evaluation.py](evaluation.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation as ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start running and evaluating the simple random agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.024\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_random(gym.make('qiscoin-v0'), num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average reward is around $0$. The result makes sense since the agent has $50\\%$ probability of guessing right at each iteration, and thus, in the long run, the positive rewards for guessing right ($+1$) compensate the negative rewards for guessing wrong ($-1$).\n",
    "\n",
    "Next we test a biased agent that constantly guesses $0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.503\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_biased(gym.make('qiscoin-v0'), num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average reward of a biased agent always guessing 0 is significantly better than the random agent. This is due to the fact that 4 out of the 6 gates (*id, reset, t, tdg*) deterministically return 0, 1 of them (*x*) deterministically returns 1, while the last one (*h*) may return 0 or 1 with the same probability. Given that the gates are selected with uniform probability, the biased agent is expected to be correct on $4.5 * \\frac{100}{6} = 75\\%$ of times, and be wrong on $1.5 * \\frac{100}{6} = 25\\%$ of times. Thus the expected reward can be estimated as:\n",
    "\\begin{equation}\n",
    "0.75 * 1 + 0.25 * -1 = 0.5,\n",
    "\\end{equation}\n",
    "which matches the experimental result.\n",
    "\n",
    "Finally, we test the two agents (PPO2 and A2C) that we trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.823\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_model(PPO2model, env, num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.827\n"
     ]
    }
   ],
   "source": [
    "mean_reward, _ = ev.evaluate_model(A2Cmodel, env, num_steps=1000)\n",
    "print('Mean reward: {0}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both agents achieve an average reward above $0.8$. This result represents, in this scenario, an almost perfect performance. \n",
    "Remember that in the game there are 5 deterministic gates ($id, reset, x, t, tdg$), and 1 gate ($h$) which can produce any of the two outputs with equal probability. A perfect agent would then always guess correctly when presented with a deterministic gate, and guess correctly on average half of the time when presented with a Hadamard gate. In total a perfect agent should guess correctly $5.5 * \\frac{100}{6} \\approx 91.6 \\%$ of the times, and be wrong $5.5 * \\frac{100}{6} \\approx 8.3 \\%$ of the times. Given that all the gates are equally likely to be selected, we can compute the average reward as:\n",
    "\\begin{equation}\n",
    "0.916 * 1 + 0.083 * -1 \\approx 0.83.\n",
    "\\end{equation}\n",
    "The performance of the PPO2 and A2C agent is then very close to the theoretical best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple problem resembles more a *contextual 2-armed bandit* or even a simpler *supervised learning* problem. It hardly constitutes a challenge for the reinforcement learning algorithms that are able to achieve an almost perfect performance. In the next notebook we will consider a more complex instantiation of the **QisCoin**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
