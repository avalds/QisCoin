{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent Playing Game v0\n",
    "\n",
    "In this notebook we load a simple version of our game (*game-v0*) in which a quantum circuit with a single random gate is generated. The aim of the game is to guess the outcome of a measurement performed at the end of the circuit. We instantiate and run a random agent and few RL agents from the stable-baselines library and we observe their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "\n",
    "We start importing the main required libraries: OpenAI *gym* to run the game; *IPython.display* to print out our circuits.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the game\n",
    "\n",
    "Next, we import the version of our game wrapped into the *gym* interface. The code for this version of the game is available at URL and it can be installed as explained in SETUP.\n",
    "\n",
    "This version of the game implements a game environment that inherits from the *OpenAI gym* **Env** class. It implements four main methods: *__init__()* for setting up the game; *step()* computing the result of a single time-step of evolution of the environment; *reset()* restarting the game; *render()* displaying the game.\n",
    "\n",
    "The game has been modeled with a *discrete state space* (an integer number between 0 and 5 identifies which of the six possible gates has been randomly added on the circuit) and a *discrete action space* (the two integer numbers 0 and 1 corresponds to the possible guesses of the agent). Since the game is fully observed, the state space corresponds to the observation space. A positive reward (+1) is returned for guessing correctly, a negative reward (-1) is returned for guessing wrong.\n",
    "\n",
    "The code is available in the source file: URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qcoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the game\n",
    "We create the game enviroment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('qcoin-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we test the game running a single iteration of the game where the AI agent takes a random guess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 233.576x144.48 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is guessing that the outcome will be 0\n",
      "The guess is correct!\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "display(env.render())\n",
    "\n",
    "for _ in range(1):\n",
    "    guess = env.action_space.sample()\n",
    "    print(\"AI is guessing that the outcome will be {0}\".format(guess))\n",
    "    obs, reward, done, info = env.step(guess)\n",
    "    if(reward==1):\n",
    "        print(\"The guess is correct!\")\n",
    "    else:\n",
    "        print(\"The guess is wrong!\")\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Reinforcement Learning Agent\n",
    "\n",
    "Running a random agent on the game is not particularly interesting. We then turn to loading and running reinforcement learning agents that, starting from a random policy, would be able to learn to play the game in a sensible way. To do so, we rely on the library of agents provided by stable-baselines.\n",
    "\n",
    "More information and examples on stable-baselines: https://github.com/hill-a/stable-baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a PPO2 Agent\n",
    "\n",
    "We consider instanting and training a PPO2 agent.\n",
    "\n",
    "First of all we import the required modules: *DummyVecEnv* providing a wrapper for our environment as required by stable-baselines; *MlpPolicy* specifying a policy for our agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:57: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:66: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/input.py:42: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/policies.py:562: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/a2c/utils.py:156: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/distributions.py:323: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/distributions.py:324: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:193: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:201: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:209: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:243: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:245: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "-------------------------------------\n",
      "| approxkl           | 8.309672e-05 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.287       |\n",
      "| fps                | 78           |\n",
      "| n_updates          | 1            |\n",
      "| policy_entropy     | 0.6930544    |\n",
      "| policy_loss        | -0.001494581 |\n",
      "| serial_timesteps   | 128          |\n",
      "| time_elapsed       | 3.58e-06     |\n",
      "| total_timesteps    | 128          |\n",
      "| value_loss         | 0.60175395   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000108649176 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0833        |\n",
      "| fps                | 86             |\n",
      "| n_updates          | 2              |\n",
      "| policy_entropy     | 0.6926012      |\n",
      "| policy_loss        | -0.0043406864  |\n",
      "| serial_timesteps   | 256            |\n",
      "| time_elapsed       | 1.63           |\n",
      "| total_timesteps    | 256            |\n",
      "| value_loss         | 0.5205561      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00020184177 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.172        |\n",
      "| fps                | 93            |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 0.69186974    |\n",
      "| policy_loss        | -0.0038826738 |\n",
      "| serial_timesteps   | 384           |\n",
      "| time_elapsed       | 3.11          |\n",
      "| total_timesteps    | 384           |\n",
      "| value_loss         | 0.55699015    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00039707575 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0215       |\n",
      "| fps                | 94            |\n",
      "| n_updates          | 4             |\n",
      "| policy_entropy     | 0.688835      |\n",
      "| policy_loss        | -0.008210496  |\n",
      "| serial_timesteps   | 512           |\n",
      "| time_elapsed       | 4.48          |\n",
      "| total_timesteps    | 512           |\n",
      "| value_loss         | 0.51501405    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0009149227 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0188      |\n",
      "| fps                | 95           |\n",
      "| n_updates          | 5            |\n",
      "| policy_entropy     | 0.680341     |\n",
      "| policy_loss        | -0.012490073 |\n",
      "| serial_timesteps   | 640          |\n",
      "| time_elapsed       | 5.83         |\n",
      "| total_timesteps    | 640          |\n",
      "| value_loss         | 0.49717483   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0010867564 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0238      |\n",
      "| fps                | 93           |\n",
      "| n_updates          | 6            |\n",
      "| policy_entropy     | 0.6619183    |\n",
      "| policy_loss        | -0.00588667  |\n",
      "| serial_timesteps   | 768          |\n",
      "| time_elapsed       | 7.17         |\n",
      "| total_timesteps    | 768          |\n",
      "| value_loss         | 0.5151566    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0014855529 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0436      |\n",
      "| fps                | 89           |\n",
      "| n_updates          | 7            |\n",
      "| policy_entropy     | 0.6355783    |\n",
      "| policy_loss        | -0.017914418 |\n",
      "| serial_timesteps   | 896          |\n",
      "| time_elapsed       | 8.54         |\n",
      "| total_timesteps    | 896          |\n",
      "| value_loss         | 0.51091415   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.003494081  |\n",
      "| clipfrac           | 0.01953125   |\n",
      "| explained_variance | -0.0035      |\n",
      "| fps                | 89           |\n",
      "| n_updates          | 8            |\n",
      "| policy_entropy     | 0.5912351    |\n",
      "| policy_loss        | -0.026608294 |\n",
      "| serial_timesteps   | 1024         |\n",
      "| time_elapsed       | 9.97         |\n",
      "| total_timesteps    | 1024         |\n",
      "| value_loss         | 0.48871258   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0020560178 |\n",
      "| clipfrac           | 0.01171875   |\n",
      "| explained_variance | -0.0422      |\n",
      "| fps                | 81           |\n",
      "| n_updates          | 9            |\n",
      "| policy_entropy     | 0.5217431    |\n",
      "| policy_loss        | -0.008706601 |\n",
      "| serial_timesteps   | 1152         |\n",
      "| time_elapsed       | 11.4         |\n",
      "| total_timesteps    | 1152         |\n",
      "| value_loss         | 0.4992254    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.0011958777 |\n",
      "| clipfrac           | 0.001953125  |\n",
      "| explained_variance | 0.00474      |\n",
      "| fps                | 83           |\n",
      "| n_updates          | 10           |\n",
      "| policy_entropy     | 0.46855655   |\n",
      "| policy_loss        | -0.008418754 |\n",
      "| serial_timesteps   | 1280         |\n",
      "| time_elapsed       | 13           |\n",
      "| total_timesteps    | 1280         |\n",
      "| value_loss         | 0.48170447   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0034434418 |\n",
      "| clipfrac           | 0.0390625    |\n",
      "| explained_variance | -0.00569     |\n",
      "| fps                | 83           |\n",
      "| n_updates          | 11           |\n",
      "| policy_entropy     | 0.4041364    |\n",
      "| policy_loss        | -0.020768259 |\n",
      "| serial_timesteps   | 1408         |\n",
      "| time_elapsed       | 14.5         |\n",
      "| total_timesteps    | 1408         |\n",
      "| value_loss         | 0.46804875   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0004130934  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00241      |\n",
      "| fps                | 103           |\n",
      "| n_updates          | 12            |\n",
      "| policy_entropy     | 0.3481586     |\n",
      "| policy_loss        | -0.0015977374 |\n",
      "| serial_timesteps   | 1536          |\n",
      "| time_elapsed       | 16            |\n",
      "| total_timesteps    | 1536          |\n",
      "| value_loss         | 0.472265      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0007088707  |\n",
      "| clipfrac           | 0.005859375   |\n",
      "| explained_variance | -0.00781      |\n",
      "| fps                | 89            |\n",
      "| n_updates          | 13            |\n",
      "| policy_entropy     | 0.31434628    |\n",
      "| policy_loss        | -0.0074056266 |\n",
      "| serial_timesteps   | 1664          |\n",
      "| time_elapsed       | 17.3          |\n",
      "| total_timesteps    | 1664          |\n",
      "| value_loss         | 0.5026921     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003845638  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.01         |\n",
      "| fps                | 81            |\n",
      "| n_updates          | 14            |\n",
      "| policy_entropy     | 0.26694143    |\n",
      "| policy_loss        | -0.0017521796 |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 18.7          |\n",
      "| total_timesteps    | 1792          |\n",
      "| value_loss         | 0.4562766     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.00114352   |\n",
      "| clipfrac           | 0.017578125  |\n",
      "| explained_variance | -0.0306      |\n",
      "| fps                | 30           |\n",
      "| n_updates          | 15           |\n",
      "| policy_entropy     | 0.2362617    |\n",
      "| policy_loss        | -0.007539995 |\n",
      "| serial_timesteps   | 1920         |\n",
      "| time_elapsed       | 20.3         |\n",
      "| total_timesteps    | 1920         |\n",
      "| value_loss         | 0.4418302    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.6185636e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00593      |\n",
      "| fps                | 53            |\n",
      "| n_updates          | 16            |\n",
      "| policy_entropy     | 0.21013239    |\n",
      "| policy_loss        | -8.636224e-05 |\n",
      "| serial_timesteps   | 2048          |\n",
      "| time_elapsed       | 24.5          |\n",
      "| total_timesteps    | 2048          |\n",
      "| value_loss         | 0.46373796    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006536206  |\n",
      "| clipfrac           | 0.009765625   |\n",
      "| explained_variance | -0.0497       |\n",
      "| fps                | 73            |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 0.20284015    |\n",
      "| policy_loss        | -0.0053209076 |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 26.9          |\n",
      "| total_timesteps    | 2176          |\n",
      "| value_loss         | 0.5304328     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0011477141  |\n",
      "| clipfrac           | 0.01953125    |\n",
      "| explained_variance | -0.00563      |\n",
      "| fps                | 92            |\n",
      "| n_updates          | 18            |\n",
      "| policy_entropy     | 0.16511197    |\n",
      "| policy_loss        | -0.0037407335 |\n",
      "| serial_timesteps   | 2304          |\n",
      "| time_elapsed       | 28.6          |\n",
      "| total_timesteps    | 2304          |\n",
      "| value_loss         | 0.46958864    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00016177185 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00376      |\n",
      "| fps                | 87            |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 0.13827942    |\n",
      "| policy_loss        | -0.0020319524 |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 30            |\n",
      "| total_timesteps    | 2432          |\n",
      "| value_loss         | 0.47597227    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00013908897 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0102        |\n",
      "| fps                | 85            |\n",
      "| n_updates          | 20            |\n",
      "| policy_entropy     | 0.12811661    |\n",
      "| policy_loss        | -0.0017631231 |\n",
      "| serial_timesteps   | 2560          |\n",
      "| time_elapsed       | 31.5          |\n",
      "| total_timesteps    | 2560          |\n",
      "| value_loss         | 0.44673002    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.700456e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0104        |\n",
      "| fps                | 85            |\n",
      "| n_updates          | 21            |\n",
      "| policy_entropy     | 0.11595604    |\n",
      "| policy_loss        | 0.00021964335 |\n",
      "| serial_timesteps   | 2688          |\n",
      "| time_elapsed       | 33            |\n",
      "| total_timesteps    | 2688          |\n",
      "| value_loss         | 0.4447527     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.6876997e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0216        |\n",
      "| fps                | 82             |\n",
      "| n_updates          | 22             |\n",
      "| policy_entropy     | 0.12005717     |\n",
      "| policy_loss        | -0.00034613837 |\n",
      "| serial_timesteps   | 2816           |\n",
      "| time_elapsed       | 34.5           |\n",
      "| total_timesteps    | 2816           |\n",
      "| value_loss         | 0.4923355      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.879971e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0236       |\n",
      "| fps                | 63            |\n",
      "| n_updates          | 23            |\n",
      "| policy_entropy     | 0.11356251    |\n",
      "| policy_loss        | -0.0008429525 |\n",
      "| serial_timesteps   | 2944          |\n",
      "| time_elapsed       | 36            |\n",
      "| total_timesteps    | 2944          |\n",
      "| value_loss         | 0.45693243    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00030148798 |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| explained_variance | -0.00348      |\n",
      "| fps                | 85            |\n",
      "| n_updates          | 24            |\n",
      "| policy_entropy     | 0.11130656    |\n",
      "| policy_loss        | -0.003401706  |\n",
      "| serial_timesteps   | 3072          |\n",
      "| time_elapsed       | 38            |\n",
      "| total_timesteps    | 3072          |\n",
      "| value_loss         | 0.47539282    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00014988746 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.0186        |\n",
      "| fps                | 82            |\n",
      "| n_updates          | 25            |\n",
      "| policy_entropy     | 0.08883566    |\n",
      "| policy_loss        | -0.0011794145 |\n",
      "| serial_timesteps   | 3200          |\n",
      "| time_elapsed       | 39.5          |\n",
      "| total_timesteps    | 3200          |\n",
      "| value_loss         | 0.47634065    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.4982663e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0288       |\n",
      "| fps                | 90            |\n",
      "| n_updates          | 26            |\n",
      "| policy_entropy     | 0.080157064   |\n",
      "| policy_loss        | 2.6495662e-05 |\n",
      "| serial_timesteps   | 3328          |\n",
      "| time_elapsed       | 41.1          |\n",
      "| total_timesteps    | 3328          |\n",
      "| value_loss         | 0.46835688    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| approxkl           | 1.4008025e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.027         |\n",
      "| fps                | 83             |\n",
      "| n_updates          | 27             |\n",
      "| policy_entropy     | 0.08139556     |\n",
      "| policy_loss        | -0.00042136712 |\n",
      "| serial_timesteps   | 3456           |\n",
      "| time_elapsed       | 42.5           |\n",
      "| total_timesteps    | 3456           |\n",
      "| value_loss         | 0.46894366     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00027669914 |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| explained_variance | 0.000356      |\n",
      "| fps                | 81            |\n",
      "| n_updates          | 28            |\n",
      "| policy_entropy     | 0.0718555     |\n",
      "| policy_loss        | -0.0024419203 |\n",
      "| serial_timesteps   | 3584          |\n",
      "| time_elapsed       | 44            |\n",
      "| total_timesteps    | 3584          |\n",
      "| value_loss         | 0.45155683    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 2.104394e-06 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.0165      |\n",
      "| fps                | 76           |\n",
      "| n_updates          | 29           |\n",
      "| policy_entropy     | 0.061779004  |\n",
      "| policy_loss        | 6.99847e-05  |\n",
      "| serial_timesteps   | 3712         |\n",
      "| time_elapsed       | 45.6         |\n",
      "| total_timesteps    | 3712         |\n",
      "| value_loss         | 0.3735649    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 8.244878e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0191         |\n",
      "| fps                | 77             |\n",
      "| n_updates          | 30             |\n",
      "| policy_entropy     | 0.0625259      |\n",
      "| policy_loss        | -0.00038270524 |\n",
      "| serial_timesteps   | 3840           |\n",
      "| time_elapsed       | 47.3           |\n",
      "| total_timesteps    | 3840           |\n",
      "| value_loss         | 0.47668675     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.5319736e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0354        |\n",
      "| fps                | 75             |\n",
      "| n_updates          | 31             |\n",
      "| policy_entropy     | 0.06471619     |\n",
      "| policy_loss        | -0.00052963797 |\n",
      "| serial_timesteps   | 3968           |\n",
      "| time_elapsed       | 48.9           |\n",
      "| total_timesteps    | 3968           |\n",
      "| value_loss         | 0.419285       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000110355075 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0169         |\n",
      "| fps                | 77             |\n",
      "| n_updates          | 32             |\n",
      "| policy_entropy     | 0.064403586    |\n",
      "| policy_loss        | -0.0025319532  |\n",
      "| serial_timesteps   | 4096           |\n",
      "| time_elapsed       | 50.6           |\n",
      "| total_timesteps    | 4096           |\n",
      "| value_loss         | 0.423706       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.9696644e-07  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0112         |\n",
      "| fps                | 63             |\n",
      "| n_updates          | 33             |\n",
      "| policy_entropy     | 0.055043202    |\n",
      "| policy_loss        | -1.0609976e-05 |\n",
      "| serial_timesteps   | 4224           |\n",
      "| time_elapsed       | 52.3           |\n",
      "| total_timesteps    | 4224           |\n",
      "| value_loss         | 0.45531318     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.5013162e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0108       |\n",
      "| fps                | 63            |\n",
      "| n_updates          | 34            |\n",
      "| policy_entropy     | 0.051567543   |\n",
      "| policy_loss        | -0.0003757684 |\n",
      "| serial_timesteps   | 4352          |\n",
      "| time_elapsed       | 54.3          |\n",
      "| total_timesteps    | 4352          |\n",
      "| value_loss         | 0.49156916    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000102708684 |\n",
      "| clipfrac           | 0.001953125    |\n",
      "| explained_variance | -0.00228       |\n",
      "| fps                | 74             |\n",
      "| n_updates          | 35             |\n",
      "| policy_entropy     | 0.047567315    |\n",
      "| policy_loss        | -0.0016911901  |\n",
      "| serial_timesteps   | 4480           |\n",
      "| time_elapsed       | 56.3           |\n",
      "| total_timesteps    | 4480           |\n",
      "| value_loss         | 0.44998196     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.2265518e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00705       |\n",
      "| fps                | 73            |\n",
      "| n_updates          | 36            |\n",
      "| policy_entropy     | 0.04369758    |\n",
      "| policy_loss        | -4.117284e-05 |\n",
      "| serial_timesteps   | 4608          |\n",
      "| time_elapsed       | 58            |\n",
      "| total_timesteps    | 4608          |\n",
      "| value_loss         | 0.44697067    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.3524884e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00112      |\n",
      "| fps                | 78            |\n",
      "| n_updates          | 37            |\n",
      "| policy_entropy     | 0.039163012   |\n",
      "| policy_loss        | -0.0010095416 |\n",
      "| serial_timesteps   | 4736          |\n",
      "| time_elapsed       | 59.7          |\n",
      "| total_timesteps    | 4736          |\n",
      "| value_loss         | 0.46100482    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00038429047 |\n",
      "| clipfrac           | 0.005859375   |\n",
      "| explained_variance | -0.067        |\n",
      "| fps                | 95            |\n",
      "| n_updates          | 38            |\n",
      "| policy_entropy     | 0.032885186   |\n",
      "| policy_loss        | -0.002331839  |\n",
      "| serial_timesteps   | 4864          |\n",
      "| time_elapsed       | 61.4          |\n",
      "| total_timesteps    | 4864          |\n",
      "| value_loss         | 0.4770578     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.2921722e-08 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00335      |\n",
      "| fps                | 85            |\n",
      "| n_updates          | 39            |\n",
      "| policy_entropy     | 0.026946396   |\n",
      "| policy_loss        | 1.1579832e-06 |\n",
      "| serial_timesteps   | 4992          |\n",
      "| time_elapsed       | 62.7          |\n",
      "| total_timesteps    | 4992          |\n",
      "| value_loss         | 0.42652568    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.0995163e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0139        |\n",
      "| fps                | 81            |\n",
      "| n_updates          | 40            |\n",
      "| policy_entropy     | 0.025985848   |\n",
      "| policy_loss        | -0.0005327661 |\n",
      "| serial_timesteps   | 5120          |\n",
      "| time_elapsed       | 64.2          |\n",
      "| total_timesteps    | 5120          |\n",
      "| value_loss         | 0.4686039     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.4547053e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0198        |\n",
      "| fps                | 69             |\n",
      "| n_updates          | 41             |\n",
      "| policy_entropy     | 0.024595017    |\n",
      "| policy_loss        | -0.00016713445 |\n",
      "| serial_timesteps   | 5248           |\n",
      "| time_elapsed       | 65.8           |\n",
      "| total_timesteps    | 5248           |\n",
      "| value_loss         | 0.4933352      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.14678285e-08 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0611        |\n",
      "| fps                | 75             |\n",
      "| n_updates          | 42             |\n",
      "| policy_entropy     | 0.022489082    |\n",
      "| policy_loss        | 1.0003569e-06  |\n",
      "| serial_timesteps   | 5376           |\n",
      "| time_elapsed       | 67.7           |\n",
      "| total_timesteps    | 5376           |\n",
      "| value_loss         | 0.48216203     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| approxkl           | 1.9627338e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0163         |\n",
      "| fps                | 74             |\n",
      "| n_updates          | 43             |\n",
      "| policy_entropy     | 0.022420749    |\n",
      "| policy_loss        | -0.00034862966 |\n",
      "| serial_timesteps   | 5504           |\n",
      "| time_elapsed       | 69.4           |\n",
      "| total_timesteps    | 5504           |\n",
      "| value_loss         | 0.45383006     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.6260584e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00178      |\n",
      "| fps                | 71            |\n",
      "| n_updates          | 44            |\n",
      "| policy_entropy     | 0.022885242   |\n",
      "| policy_loss        | 8.375943e-05  |\n",
      "| serial_timesteps   | 5632          |\n",
      "| time_elapsed       | 71.1          |\n",
      "| total_timesteps    | 5632          |\n",
      "| value_loss         | 0.43131265    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3718633e-08 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0383       |\n",
      "| fps                | 74            |\n",
      "| n_updates          | 45            |\n",
      "| policy_entropy     | 0.022190241   |\n",
      "| policy_loss        | 2.0290026e-06 |\n",
      "| serial_timesteps   | 5760          |\n",
      "| time_elapsed       | 72.9          |\n",
      "| total_timesteps    | 5760          |\n",
      "| value_loss         | 0.44792646    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.3955205e-10  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.00631        |\n",
      "| fps                | 78             |\n",
      "| n_updates          | 46             |\n",
      "| policy_entropy     | 0.021165438    |\n",
      "| policy_loss        | -1.2154924e-06 |\n",
      "| serial_timesteps   | 5888           |\n",
      "| time_elapsed       | 74.6           |\n",
      "| total_timesteps    | 5888           |\n",
      "| value_loss         | 0.5076391      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.7524473e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.000805       |\n",
      "| fps                | 75             |\n",
      "| n_updates          | 47             |\n",
      "| policy_entropy     | 0.02106343     |\n",
      "| policy_loss        | -0.00035963207 |\n",
      "| serial_timesteps   | 6016           |\n",
      "| time_elapsed       | 76.2           |\n",
      "| total_timesteps    | 6016           |\n",
      "| value_loss         | 0.4474027      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.3825208e-08 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00208       |\n",
      "| fps                | 64            |\n",
      "| n_updates          | 48            |\n",
      "| policy_entropy     | 0.023331095   |\n",
      "| policy_loss        | 1.6710022e-05 |\n",
      "| serial_timesteps   | 6144          |\n",
      "| time_elapsed       | 77.9          |\n",
      "| total_timesteps    | 6144          |\n",
      "| value_loss         | 0.4697421     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3787117e-09 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0144       |\n",
      "| fps                | 73            |\n",
      "| n_updates          | 49            |\n",
      "| policy_entropy     | 0.024695754   |\n",
      "| policy_loss        | -9.719515e-07 |\n",
      "| serial_timesteps   | 6272          |\n",
      "| time_elapsed       | 79.9          |\n",
      "| total_timesteps    | 6272          |\n",
      "| value_loss         | 0.4672643     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.1509465e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0431       |\n",
      "| fps                | 73            |\n",
      "| n_updates          | 50            |\n",
      "| policy_entropy     | 0.02418213    |\n",
      "| policy_loss        | -4.621793e-05 |\n",
      "| serial_timesteps   | 6400          |\n",
      "| time_elapsed       | 81.6          |\n",
      "| total_timesteps    | 6400          |\n",
      "| value_loss         | 0.5108934     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 8.786022e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0459        |\n",
      "| fps                | 76             |\n",
      "| n_updates          | 51             |\n",
      "| policy_entropy     | 0.023291118    |\n",
      "| policy_loss        | -0.00020708144 |\n",
      "| serial_timesteps   | 6528           |\n",
      "| time_elapsed       | 83.4           |\n",
      "| total_timesteps    | 6528           |\n",
      "| value_loss         | 0.47448614     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.6892145e-08  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.00818        |\n",
      "| fps                | 71             |\n",
      "| n_updates          | 52             |\n",
      "| policy_entropy     | 0.025143377    |\n",
      "| policy_loss        | -5.3942204e-06 |\n",
      "| serial_timesteps   | 6656           |\n",
      "| time_elapsed       | 85             |\n",
      "| total_timesteps    | 6656           |\n",
      "| value_loss         | 0.4575546      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.91206e-06   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0299       |\n",
      "| fps                | 78            |\n",
      "| n_updates          | 53            |\n",
      "| policy_entropy     | 0.026384406   |\n",
      "| policy_loss        | -0.0001446429 |\n",
      "| serial_timesteps   | 6784          |\n",
      "| time_elapsed       | 86.8          |\n",
      "| total_timesteps    | 6784          |\n",
      "| value_loss         | 0.47611076    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.4778764e-09 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0173        |\n",
      "| fps                | 74            |\n",
      "| n_updates          | 54            |\n",
      "| policy_entropy     | 0.026179397   |\n",
      "| policy_loss        | 3.0148076e-06 |\n",
      "| serial_timesteps   | 6912          |\n",
      "| time_elapsed       | 88.4          |\n",
      "| total_timesteps    | 6912          |\n",
      "| value_loss         | 0.43778035    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.243836e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0353        |\n",
      "| fps                | 71             |\n",
      "| n_updates          | 55             |\n",
      "| policy_entropy     | 0.024484131    |\n",
      "| policy_loss        | -0.00081480073 |\n",
      "| serial_timesteps   | 7040           |\n",
      "| time_elapsed       | 90.2           |\n",
      "| total_timesteps    | 7040           |\n",
      "| value_loss         | 0.4439892      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.17988e-08   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0281       |\n",
      "| fps                | 69            |\n",
      "| n_updates          | 56            |\n",
      "| policy_entropy     | 0.021938873   |\n",
      "| policy_loss        | 3.9361184e-06 |\n",
      "| serial_timesteps   | 7168          |\n",
      "| time_elapsed       | 92            |\n",
      "| total_timesteps    | 7168          |\n",
      "| value_loss         | 0.41205102    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.889958e-10   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.042         |\n",
      "| fps                | 67             |\n",
      "| n_updates          | 57             |\n",
      "| policy_entropy     | 0.02079618     |\n",
      "| policy_loss        | -1.8978026e-06 |\n",
      "| serial_timesteps   | 7296           |\n",
      "| time_elapsed       | 93.8           |\n",
      "| total_timesteps    | 7296           |\n",
      "| value_loss         | 0.49114978     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.6968753e-11  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0114        |\n",
      "| fps                | 87             |\n",
      "| n_updates          | 58             |\n",
      "| policy_entropy     | 0.021175828    |\n",
      "| policy_loss        | -6.6589564e-07 |\n",
      "| serial_timesteps   | 7424           |\n",
      "| time_elapsed       | 95.7           |\n",
      "| total_timesteps    | 7424           |\n",
      "| value_loss         | 0.46227255     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 3.896014e-11  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0441       |\n",
      "| fps                | 72            |\n",
      "| n_updates          | 59            |\n",
      "| policy_entropy     | 0.020343615   |\n",
      "| policy_loss        | -5.962793e-07 |\n",
      "| serial_timesteps   | 7552          |\n",
      "| time_elapsed       | 97.2          |\n",
      "| total_timesteps    | 7552          |\n",
      "| value_loss         | 0.4615866     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.9878734e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0204       |\n",
      "| fps                | 67            |\n",
      "| n_updates          | 60            |\n",
      "| policy_entropy     | 0.020265378   |\n",
      "| policy_loss        | -0.0005239026 |\n",
      "| serial_timesteps   | 7680          |\n",
      "| time_elapsed       | 98.9          |\n",
      "| total_timesteps    | 7680          |\n",
      "| value_loss         | 0.48115486    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.2623077e-08 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0223       |\n",
      "| fps                | 74            |\n",
      "| n_updates          | 61            |\n",
      "| policy_entropy     | 0.017761523   |\n",
      "| policy_loss        | -3.282912e-08 |\n",
      "| serial_timesteps   | 7808          |\n",
      "| time_elapsed       | 101           |\n",
      "| total_timesteps    | 7808          |\n",
      "| value_loss         | 0.45164517    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.8656438e-10 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0306       |\n",
      "| fps                | 85            |\n",
      "| n_updates          | 62            |\n",
      "| policy_entropy     | 0.017236935   |\n",
      "| policy_loss        | 2.2316817e-07 |\n",
      "| serial_timesteps   | 7936          |\n",
      "| time_elapsed       | 103           |\n",
      "| total_timesteps    | 7936          |\n",
      "| value_loss         | 0.4764704     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.143591e-12  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0195       |\n",
      "| fps                | 79            |\n",
      "| n_updates          | 63            |\n",
      "| policy_entropy     | 0.017728245   |\n",
      "| policy_loss        | 1.7462298e-09 |\n",
      "| serial_timesteps   | 8064          |\n",
      "| time_elapsed       | 104           |\n",
      "| total_timesteps    | 8064          |\n",
      "| value_loss         | 0.48924878    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.455859e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0165       |\n",
      "| fps                | 80            |\n",
      "| n_updates          | 64            |\n",
      "| policy_entropy     | 0.01659312    |\n",
      "| policy_loss        | -0.0007865586 |\n",
      "| serial_timesteps   | 8192          |\n",
      "| time_elapsed       | 106           |\n",
      "| total_timesteps    | 8192          |\n",
      "| value_loss         | 0.44876188    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.02855005e-08 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0198        |\n",
      "| fps                | 59             |\n",
      "| n_updates          | 65             |\n",
      "| policy_entropy     | 0.014808449    |\n",
      "| policy_loss        | -2.2835447e-06 |\n",
      "| serial_timesteps   | 8320           |\n",
      "| time_elapsed       | 107            |\n",
      "| total_timesteps    | 8320           |\n",
      "| value_loss         | 0.4593773      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.9677657e-10 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00292      |\n",
      "| fps                | 69            |\n",
      "| n_updates          | 66            |\n",
      "| policy_entropy     | 0.014187702   |\n",
      "| policy_loss        | 3.083842e-07  |\n",
      "| serial_timesteps   | 8448          |\n",
      "| time_elapsed       | 109           |\n",
      "| total_timesteps    | 8448          |\n",
      "| value_loss         | 0.48079023    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.7558393e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.00528       |\n",
      "| fps                | 77             |\n",
      "| n_updates          | 67             |\n",
      "| policy_entropy     | 0.012910098    |\n",
      "| policy_loss        | -0.00052767305 |\n",
      "| serial_timesteps   | 8576           |\n",
      "| time_elapsed       | 111            |\n",
      "| total_timesteps    | 8576           |\n",
      "| value_loss         | 0.48418963     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.346182e-09  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0133       |\n",
      "| fps                | 78            |\n",
      "| n_updates          | 68            |\n",
      "| policy_entropy     | 0.0115709165  |\n",
      "| policy_loss        | 1.3062963e-06 |\n",
      "| serial_timesteps   | 8704          |\n",
      "| time_elapsed       | 113           |\n",
      "| total_timesteps    | 8704          |\n",
      "| value_loss         | 0.4896788     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.05849086e-10 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0423        |\n",
      "| fps                | 90             |\n",
      "| n_updates          | 69             |\n",
      "| policy_entropy     | 0.011104485    |\n",
      "| policy_loss        | -2.1979213e-07 |\n",
      "| serial_timesteps   | 8832           |\n",
      "| time_elapsed       | 115            |\n",
      "| total_timesteps    | 8832           |\n",
      "| value_loss         | 0.46915558     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.2831285e-13 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0122        |\n",
      "| fps                | 87            |\n",
      "| n_updates          | 70            |\n",
      "| policy_entropy     | 0.011094449   |\n",
      "| policy_loss        | 6.0535967e-09 |\n",
      "| serial_timesteps   | 8960          |\n",
      "| time_elapsed       | 116           |\n",
      "| total_timesteps    | 8960          |\n",
      "| value_loss         | 0.46705553    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.1580394e-12 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0017        |\n",
      "| fps                | 89            |\n",
      "| n_updates          | 71            |\n",
      "| policy_entropy     | 0.011123863   |\n",
      "| policy_loss        | 6.100163e-08  |\n",
      "| serial_timesteps   | 9088          |\n",
      "| time_elapsed       | 117           |\n",
      "| total_timesteps    | 9088          |\n",
      "| value_loss         | 0.49792537    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.4937219e-12  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0288        |\n",
      "| fps                | 72             |\n",
      "| n_updates          | 72             |\n",
      "| policy_entropy     | 0.01108229     |\n",
      "| policy_loss        | -3.1199306e-08 |\n",
      "| serial_timesteps   | 9216           |\n",
      "| time_elapsed       | 119            |\n",
      "| total_timesteps    | 9216           |\n",
      "| value_loss         | 0.49409366     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.2858737e-12 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0118        |\n",
      "| fps                | 92            |\n",
      "| n_updates          | 73            |\n",
      "| policy_entropy     | 0.011164085   |\n",
      "| policy_loss        | -3.282912e-08 |\n",
      "| serial_timesteps   | 9344          |\n",
      "| time_elapsed       | 121           |\n",
      "| total_timesteps    | 9344          |\n",
      "| value_loss         | 0.46377936    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.7454719e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0656        |\n",
      "| fps                | 80             |\n",
      "| n_updates          | 74             |\n",
      "| policy_entropy     | 0.011790504    |\n",
      "| policy_loss        | -0.00030638324 |\n",
      "| serial_timesteps   | 9472           |\n",
      "| time_elapsed       | 122            |\n",
      "| total_timesteps    | 9472           |\n",
      "| value_loss         | 0.45640674     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.5542246e-09 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00157      |\n",
      "| fps                | 68            |\n",
      "| n_updates          | 75            |\n",
      "| policy_entropy     | 0.012529329   |\n",
      "| policy_loss        | 7.939525e-07  |\n",
      "| serial_timesteps   | 9600          |\n",
      "| time_elapsed       | 124           |\n",
      "| total_timesteps    | 9600          |\n",
      "| value_loss         | 0.4643289     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 2.3400976e-10 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0138        |\n",
      "| fps                | 58            |\n",
      "| n_updates          | 76            |\n",
      "| policy_entropy     | 0.013143256   |\n",
      "| policy_loss        | 1.5413389e-07 |\n",
      "| serial_timesteps   | 9728          |\n",
      "| time_elapsed       | 125           |\n",
      "| total_timesteps    | 9728          |\n",
      "| value_loss         | 0.43870324    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.7441637e-11 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0684       |\n",
      "| fps                | 72            |\n",
      "| n_updates          | 77            |\n",
      "| policy_entropy     | 0.013770604   |\n",
      "| policy_loss        | -4.452304e-07 |\n",
      "| serial_timesteps   | 9856          |\n",
      "| time_elapsed       | 128           |\n",
      "| total_timesteps    | 9856          |\n",
      "| value_loss         | 0.4782222     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.5313544e-11 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00245      |\n",
      "| fps                | 66            |\n",
      "| n_updates          | 78            |\n",
      "| policy_entropy     | 0.013796035   |\n",
      "| policy_loss        | -3.198511e-07 |\n",
      "| serial_timesteps   | 9984          |\n",
      "| time_elapsed       | 129           |\n",
      "| total_timesteps    | 9984          |\n",
      "| value_loss         | 0.44186556    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7f0788d83710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = DummyVecEnv([lambda: env])\n",
    "PPO2model = PPO2(MlpPolicy, env, verbose=1)\n",
    "PPO2model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO2model.save('PPO2-qcoin-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running AC3 agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:312: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:312: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/a2c/a2c.py:159: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "| explained_variance | -0.162   |\n",
      "| fps                | 23       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 1.12     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.191    |\n",
      "| fps                | 82       |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 0.837    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.114    |\n",
      "| fps                | 83       |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 0.692    |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 0.913    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.0526   |\n",
      "| fps                | 85       |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 0.691    |\n",
      "| total_timesteps    | 1500     |\n",
      "| value_loss         | 0.913    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.0463   |\n",
      "| fps                | 82       |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 0.683    |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.98     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.0285   |\n",
      "| fps                | 80       |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 0.674    |\n",
      "| total_timesteps    | 2500     |\n",
      "| value_loss         | 0.954    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 81       |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 0.648    |\n",
      "| total_timesteps    | 3000     |\n",
      "| value_loss         | 1.12     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0422  |\n",
      "| fps                | 80       |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 0.635    |\n",
      "| total_timesteps    | 3500     |\n",
      "| value_loss         | 0.984    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.0278   |\n",
      "| fps                | 79       |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 0.523    |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 1.07     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0378  |\n",
      "| fps                | 79       |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 0.38     |\n",
      "| total_timesteps    | 4500     |\n",
      "| value_loss         | 1.15     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 0.258    |\n",
      "| total_timesteps    | 5000     |\n",
      "| value_loss         | 0.424    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 0.156    |\n",
      "| total_timesteps    | 5500     |\n",
      "| value_loss         | 0.47     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.179   |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 0.0965   |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 1.36     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0106  |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 1300     |\n",
      "| policy_entropy     | 0.11     |\n",
      "| total_timesteps    | 6500     |\n",
      "| value_loss         | 0.979    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.152    |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 1400     |\n",
      "| policy_entropy     | 0.0615   |\n",
      "| total_timesteps    | 7000     |\n",
      "| value_loss         | 1.5      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0652  |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 1500     |\n",
      "| policy_entropy     | 0.105    |\n",
      "| total_timesteps    | 7500     |\n",
      "| value_loss         | 1.03     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 1600     |\n",
      "| policy_entropy     | 0.146    |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.39     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.108   |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 1700     |\n",
      "| policy_entropy     | 0.13     |\n",
      "| total_timesteps    | 8500     |\n",
      "| value_loss         | 1.27     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.27    |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 1800     |\n",
      "| policy_entropy     | 0.141    |\n",
      "| total_timesteps    | 9000     |\n",
      "| value_loss         | 0.954    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.378   |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 1900     |\n",
      "| policy_entropy     | 0.0881   |\n",
      "| total_timesteps    | 9500     |\n",
      "| value_loss         | 1.12     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | nan      |\n",
      "| fps                | 78       |\n",
      "| nupdates           | 2000     |\n",
      "| policy_entropy     | 0.0582   |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.464    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.a2c.a2c.A2C at 0x7f0788d83450>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2Cmodel = A2C(MlpPolicy, env, verbose=1)\n",
    "A2Cmodel.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2Cmodel.save('A2C-qcoin-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import ACER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/common/distributions.py:324: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/acer/acer_simple.py:363: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/acer/acer_simple.py:389: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/fmzennaro/miniconda2_1/envs/quantumgymstable/lib/python3.7/site-packages/stable_baselines/acer/acer_simple.py:414: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.199    |\n",
      "| avg_norm_g          | 2        |\n",
      "| avg_norm_grads_f    | 1.83     |\n",
      "| avg_norm_k          | 1.41     |\n",
      "| avg_norm_k_dot_g    | 2        |\n",
      "| entropy             | 14.6     |\n",
      "| explained_variance  | 0.00269  |\n",
      "| fps                 | 0        |\n",
      "| loss                | 0.244    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.14     |\n",
      "| loss_policy         | 0.14     |\n",
      "| loss_q              | 0.499    |\n",
      "| mean_episode_length | 1        |\n",
      "| mean_episode_reward | 0.2      |\n",
      "| norm_grads          | 0.626    |\n",
      "| norm_grads_policy   | 0.516    |\n",
      "| norm_grads_q        | 0.355    |\n",
      "| total_timesteps     | 0        |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.17     |\n",
      "| avg_norm_g          | 2.01     |\n",
      "| avg_norm_grads_f    | 1.86     |\n",
      "| avg_norm_k          | 1.43     |\n",
      "| avg_norm_k_dot_g    | 2.04     |\n",
      "| entropy             | 14.3     |\n",
      "| explained_variance  | -0.0168  |\n",
      "| fps                 | 48       |\n",
      "| loss                | 0.325    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.215    |\n",
      "| loss_policy         | 0.215    |\n",
      "| loss_q              | 0.506    |\n",
      "| mean_episode_length | 1        |\n",
      "| mean_episode_reward | 0.3      |\n",
      "| norm_grads          | 0.788    |\n",
      "| norm_grads_policy   | 0.676    |\n",
      "| norm_grads_q        | 0.405    |\n",
      "| total_timesteps     | 2000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.892    |\n",
      "| avg_norm_g          | 3.42     |\n",
      "| avg_norm_grads_f    | 2.5      |\n",
      "| avg_norm_k          | 1.76     |\n",
      "| avg_norm_k_dot_g    | 4.72     |\n",
      "| entropy             | 7.52     |\n",
      "| explained_variance  | 0.0851   |\n",
      "| fps                 | 47       |\n",
      "| loss                | -0.165   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.316   |\n",
      "| loss_policy         | -0.316   |\n",
      "| loss_q              | 0.453    |\n",
      "| mean_episode_length | 1        |\n",
      "| mean_episode_reward | 0.2      |\n",
      "| norm_grads          | 0.755    |\n",
      "| norm_grads_policy   | 0.644    |\n",
      "| norm_grads_q        | 0.393    |\n",
      "| total_timesteps     | 4000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 2.4      |\n",
      "| avg_norm_g          | 8.24     |\n",
      "| avg_norm_grads_f    | 6.22     |\n",
      "| avg_norm_k          | 1.73     |\n",
      "| avg_norm_k_dot_g    | 11.1     |\n",
      "| entropy             | 1.56     |\n",
      "| explained_variance  | -0.00785 |\n",
      "| fps                 | 47       |\n",
      "| loss                | 0.0958   |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.13    |\n",
      "| loss_policy         | -0.13    |\n",
      "| loss_q              | 0.484    |\n",
      "| mean_episode_length | 1        |\n",
      "| mean_episode_reward | 0.15     |\n",
      "| norm_grads          | 0.471    |\n",
      "| norm_grads_policy   | 0.396    |\n",
      "| norm_grads_q        | 0.255    |\n",
      "| total_timesteps     | 6000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0236   |\n",
      "| avg_norm_g          | 0.834    |\n",
      "| avg_norm_grads_f    | 0.812    |\n",
      "| avg_norm_k          | 1.51     |\n",
      "| avg_norm_k_dot_g    | 0.834    |\n",
      "| entropy             | 0.549    |\n",
      "| explained_variance  | 0.012    |\n",
      "| fps                 | 47       |\n",
      "| loss                | 0.18     |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.00114  |\n",
      "| loss_policy         | 0.00114  |\n",
      "| loss_q              | 0.369    |\n",
      "| mean_episode_length | 1        |\n",
      "| mean_episode_reward | 0.3      |\n",
      "| norm_grads          | 0.44     |\n",
      "| norm_grads_policy   | 0.0073   |\n",
      "| norm_grads_q        | 0.44     |\n",
      "| total_timesteps     | 8000     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.acer.acer_simple.ACER at 0x7f025443b390>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = DummyVecEnv([lambda: env])\n",
    "ACERmodel = ACER(MlpPolicy, env, verbose=1)\n",
    "ACERmodel.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACERmodel.save('ACER-qcoin-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing random agent and learned agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.2 ; Games: 1001\n"
     ]
    }
   ],
   "source": [
    "mean_reward, n_episode_rewards = ev.evaluate_model(PPO2model, env, num_steps=1000)\n",
    "print('Mean reward: {0} ; Games: {1}'.format(mean_reward, n_episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.2 ; Games: 1001\n"
     ]
    }
   ],
   "source": [
    "mean_reward, n_episode_rewards = ev.evaluate_model(A2Cmodel, env, num_steps=1000)\n",
    "print('Mean reward: {0} ; Games: {1}'.format(mean_reward, n_episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.3 ; Games: 1001\n"
     ]
    }
   ],
   "source": [
    "mean_reward, n_episode_rewards = ev.evaluate_model(ACERmodel, env, num_steps=1000)\n",
    "print('Mean reward: {0} ; Games: {1}'.format(mean_reward, n_episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.1 ; Games: 1001\n"
     ]
    }
   ],
   "source": [
    "mean_reward, n_episode_rewards = ev.evaluate_random(gym.make('qcoin-v0'), num_steps=1000)\n",
    "print('Mean reward: {0} ; Games: {1}'.format(mean_reward, n_episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
